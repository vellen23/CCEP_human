{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 02 - Paths, centralities, and community structure\n",
    "\n",
    "In this week's assignment we explore some of the key network analytic concepts introduced in lecture 02 in practice. We will calculate path-based network characteristics for empirical data sets and we develop a simple approach to detect community structures based on the heuristic optimisation of modularity. We finally calculate and visualise the degree distribution of real networks. We will use the following five empirical data sets:\n",
    "\n",
    "1) the collaboration network of the OpenSource software community `kde`  \n",
    "2) the collaboration network of the OpenSource software community `gentoo`  \n",
    "3) the power grid of the western states of the USA  \n",
    "4) the contact network of students in a highschool  \n",
    "5) an information sharing network of physicians in the United States  \n",
    "\n",
    "All of these data are available in a single SQLite database file, which you can find in Moodle.\n",
    "\n",
    "## Task 1: Paths, diameter, and components\n",
    "\n",
    "### 1.1 Connected components\n",
    "\n",
    "Implement Tarjan's algorithm for the calculation of connected components for an instance of `pathpy.Network` (see e.g. [Hopcroft and Tarjan 1973](https://dl.acm.org/citation.cfm?doid=362248.362272). Test your algorithm in the small toy example from lecture 2 (slide 14). Define a function that returns the relative size of the largest connected component (lcc) for a given network.\n",
    "\n",
    "Compare your results with the implementation given in pathpy, using the function `reduce_to_gcc` in `pathpy.algorithms.components`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "A graph or network that can be directed, undirected, unweighted or weighted\n",
      "and whose edges can contain arbitrary attributes. This is the base class for\n",
      "HigherOrderNetwork\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "\n",
      "nodes : list\n",
      "    A list of (string) nodes.\n",
      "edges : dictionary\n",
      "    A dictionary containing edges (as tuple-valued keys) and their attributes (as value)\n",
      "\u001b[0;31mInit docstring:\u001b[0m Generates an empty network.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/anaconda3/lib/python3.7/site-packages/pathpy/classes/network.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     DAG, HigherOrderNetwork\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pathpy as pp\n",
    "\n",
    "# TODO: Implement functions\n",
    "\n",
    "pp.Network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_to_gcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Reduces the network to the largest connected component.\n",
      "Connected components are calculated using Tarjan's algorithm.\n",
      "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/lib/python3.7/site-packages/pathpy/algorithms/components.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "pp.algorithms.components.reduce_to_gcc?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Connected components in empirical data\n",
    "\n",
    "Read the five data sets from the SQLite database as *undirected* networks and compute the sizes of connected components. Would you say that these networks contain a *giant* connected component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect('data/01_networks.db')\n",
    "con.row_factory = sqlite3.Row\n",
    "\n",
    "# TODO: Read data as introduced in exercise 01 and apply your algorithm to these data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Diameter and average path length\n",
    "\n",
    "Use the functions `diameter` and `avg_path_length` in `shortest_paths` in `pathpy.algorithms.shortest_paths` to compute the diameter and the average shortest path length of the (largest connected component in the) `physicians`, `highschool`, and `gentoo` data. Interpret the differences while considering the different sizes of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate diamater and average shortest path lengths using functions in pathpy\n",
    "pp.algorithms.shortest_paths.diameter(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Modularity-based community detection\n",
    "\n",
    "### 2.1 Partition quality\n",
    "\n",
    "Implement the partition quality function $Q(n, C)$ for a given network `n` and a non-overlapping partitioning `C` of nodes into communities as introduced in lecture 2 on slide 22. Test your method in the toy example and partitioning depicted on slide 26 and check whether you obtain the same value for the partition quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(network, C):\n",
    "    # TODO: implement function \n",
    "    # Hint: Assume that the partitioning is given as a dictionary where C[v] is the community of node v\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pp.Network()\n",
    "n.add_edge('a', 'b')\n",
    "n.add_edge('b', 'c')\n",
    "n.add_edge('a', 'c')\n",
    "n.add_edge('b', 'd')\n",
    "n.add_edge('d', 'f')\n",
    "n.add_edge('d', 'g')\n",
    "n.add_edge('d', 'e')\n",
    "n.add_edge('e', 'f')\n",
    "n.add_edge('f', 'g')\n",
    "\n",
    "# Apply the method to the toy example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Modularity optimisation\n",
    "\n",
    "Implement a simple heuristic optimisation algorithm to calculate the optimal modularity $Q_{opt}$ across all partitions. The idea of this algorithm is as follows: \n",
    "\n",
    "1) Start with a partitioning where you place each node in a separate community   \n",
    "2) Draw two communities uniformly at random and merge them to a single community iff this merge increases partition quality   \n",
    "3) Repeat the second step for a given number of iterations and output the final partitioning and partition quality  \n",
    "\n",
    "Use your method to calculate $Q_{opt}$ for the toy example and plot the detected communities by coloring the nodes appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_communities(network, iterations=100):\n",
    "    # TODO: implement method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this task a bit simpler, I provide you with the following method, which generates a community-based node-color mapping that you can use to color nodes according to (a maximum of 20) communities (hint: use the `node_color` parameter of the `pathpy.visualisation.plot` function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_colors(n, communities):\n",
    "    colors = ['red', 'green', 'blue', 'orange', 'yellow', 'cyan', 'blueviolet', \\\n",
    "              'chocolate', 'magenta', 'navy', 'plum', 'thistle', 'wheat', 'turquoise', \\\n",
    "              'steelblue', 'grey', 'powderblue', 'orchid', 'mintcream', 'maroon']\n",
    "    node_colors = {}\n",
    "    community_color_map = {}\n",
    "    i = 0\n",
    "    for v in n.nodes:\n",
    "        if communities[v] not in community_color_map:\n",
    "            community_color_map[communities[v]] = i%len(colors)\n",
    "            i += 1\n",
    "        node_colors[v] = colors[community_color_map[communities[v]]]\n",
    "    return node_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Detect communities in toy example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Synthetic network generation\n",
    "\n",
    "Create a simple *synthetic network* with a strong (and known) community structure as follows: \n",
    "\n",
    "1) Generate two networks $c1$ and $c2$ with $50$ nodes each and add $200$ links at random to each of the networks. For this, you can use the `numpy.random.choice` function introduced in exercise 02.  \n",
    "2) Use `pathpy`'s $+$-operator to combine the two networks to a single network with two connected components.   \n",
    "3) Add $5$ links that randomly interconnect nodes across the two components $c1$ and $c2$, thus generating a connected network.\n",
    "\n",
    "Visualise the network generated by this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate synthetic network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Heuristic optimisation vs. the global optimum\n",
    "\n",
    "Define a community partitioning that corresponds to the \"ground truth\" communities in the network from 2.3 and calculate the partition quality $Q$ for this optimal partitioning. Use your method from Task 2.2 to find the partitioning with maximal modularity. Compare this value to the ground truth and visualise the corresponding community structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate global and heuristic optimum for synthetic network and visualise detected communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Community assortativity coefficient\n",
    "\n",
    "Using the definition from lecture 2, slide 29, implement a function that computes the theoretical maximum modularity $Q_{max}$ fora given network and partition. Test your function for the toy example and try to reproduce the *community assortativity coefficient* reported on slide 29. Calculate the community assortativity coefficient for the synthetic example from Task 3.4 and compare it to the modularity of this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Qmax(network, C):\n",
    "    # TODO: Implement function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate theoretical maximum for toy example and calculate community assortativity coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Communities in empirical networks\n",
    "\n",
    "Use your functions from Task 2.2 and 2.5 to compute the community assortativity coefficient and the number of detected communities for the `highschool` and `physicians` data. Visualise the optimal community structure found by your optimisation method. How does the number of detected communities depend on the number of iterations for your optimisation algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect and visualise communities in empirical networks and calculate community assortativity coefficient"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
