{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "blocked-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy\n",
    "import re\n",
    "\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "grave-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_groups = np.array([[0,15],[15,30],[30,5000]])\n",
    "dist_labels = ['local (<15 mm)', 'short (<30mm)', 'long']\n",
    "\n",
    "Fs             = 500\n",
    "dur            = np.zeros((1,2), dtype=np.int32)\n",
    "t0 = 1\n",
    "dur[0,0] =  -t0\n",
    "dur[0,1] =  3\n",
    "\n",
    "#dur[0,:]       = np.int32(np.sum(abs(dur)))\n",
    "x_ax           = np.arange(dur[0,0],dur[0,1],(1/Fs))\n",
    "color_elab      = np.zeros((4,3))\n",
    "color_elab[0,:] = np.array([31, 78, 121])/255\n",
    "color_elab[1,:] = np.array([189, 215, 238])/255\n",
    "color_elab[2,:] = np.array([0.256, 0.574, 0.431])\n",
    "color_elab[3,:] = np.array([1, 0.574, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-particular",
   "metadata": {},
   "source": [
    "labels_region[labels_region=='HIPP'] = 'Mesiotemporal'\n",
    "labels_region[labels_region=='HIPP '] = 'Mesiotemporal'\n",
    "labels_region[labels_region=='ENT'] = 'Basotemporal'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "maritime-booth",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "applied-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'BrainMapping'\n",
    "cond_folder = 'CR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "announced-monthly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subj</th>\n",
       "      <th>StimA</th>\n",
       "      <th>ChanA</th>\n",
       "      <th>StimR</th>\n",
       "      <th>ChanR</th>\n",
       "      <th>Stim</th>\n",
       "      <th>Chan</th>\n",
       "      <th>Sig</th>\n",
       "      <th>H</th>\n",
       "      <th>LL_sig</th>\n",
       "      <th>Dir_index</th>\n",
       "      <th>Dir_B</th>\n",
       "      <th>t_resp</th>\n",
       "      <th>d</th>\n",
       "      <th>Dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EL010</td>\n",
       "      <td>HIPP</td>\n",
       "      <td>OTS_med</td>\n",
       "      <td>Mesiotemporal</td>\n",
       "      <td>Basotemporal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.664564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.00</td>\n",
       "      <td>local (&lt;15 mm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EL010</td>\n",
       "      <td>HIPP</td>\n",
       "      <td>ITS</td>\n",
       "      <td>Mesiotemporal</td>\n",
       "      <td>Laterotemporal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.00</td>\n",
       "      <td>short (&lt;30mm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EL010</td>\n",
       "      <td>HIPP</td>\n",
       "      <td>ITS</td>\n",
       "      <td>Mesiotemporal</td>\n",
       "      <td>Laterotemporal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0</td>\n",
       "      <td>2.751050</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.018</td>\n",
       "      <td>24.50</td>\n",
       "      <td>short (&lt;30mm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EL010</td>\n",
       "      <td>HIPP</td>\n",
       "      <td>ITS</td>\n",
       "      <td>Mesiotemporal</td>\n",
       "      <td>Laterotemporal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>28.00</td>\n",
       "      <td>short (&lt;30mm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EL010</td>\n",
       "      <td>HIPP</td>\n",
       "      <td>PlanTGpole</td>\n",
       "      <td>Mesiotemporal</td>\n",
       "      <td>Superotemporal</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.529343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>55.76</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20480</th>\n",
       "      <td>EL017</td>\n",
       "      <td>SFS</td>\n",
       "      <td>IFGopc</td>\n",
       "      <td>Dorsofrontal</td>\n",
       "      <td>Dorsofrontal</td>\n",
       "      <td>576.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052</td>\n",
       "      <td>52.41</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20481</th>\n",
       "      <td>EL017</td>\n",
       "      <td>SFS</td>\n",
       "      <td>IFS</td>\n",
       "      <td>Dorsofrontal</td>\n",
       "      <td>Dorsofrontal</td>\n",
       "      <td>576.0</td>\n",
       "      <td>570.0</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0</td>\n",
       "      <td>2.629726</td>\n",
       "      <td>-0.091912</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>21.00</td>\n",
       "      <td>short (&lt;30mm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20482</th>\n",
       "      <td>EL017</td>\n",
       "      <td>SFS</td>\n",
       "      <td>IFS</td>\n",
       "      <td>Dorsofrontal</td>\n",
       "      <td>Dorsofrontal</td>\n",
       "      <td>576.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>17.50</td>\n",
       "      <td>short (&lt;30mm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20483</th>\n",
       "      <td>EL017</td>\n",
       "      <td>SFS</td>\n",
       "      <td>IFS</td>\n",
       "      <td>Dorsofrontal</td>\n",
       "      <td>Dorsofrontal</td>\n",
       "      <td>576.0</td>\n",
       "      <td>572.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>4.248322</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>14.00</td>\n",
       "      <td>local (&lt;15 mm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20484</th>\n",
       "      <td>EL017</td>\n",
       "      <td>SFS</td>\n",
       "      <td>SFS</td>\n",
       "      <td>Dorsofrontal</td>\n",
       "      <td>Dorsofrontal</td>\n",
       "      <td>576.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.450292</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.00</td>\n",
       "      <td>local (&lt;15 mm)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20485 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Subj StimA       ChanA          StimR           ChanR   Stim   Chan  \\\n",
       "0      EL010  HIPP     OTS_med  Mesiotemporal    Basotemporal    1.0    3.0   \n",
       "1      EL010  HIPP         ITS  Mesiotemporal  Laterotemporal    1.0    7.0   \n",
       "2      EL010  HIPP         ITS  Mesiotemporal  Laterotemporal    1.0    8.0   \n",
       "3      EL010  HIPP         ITS  Mesiotemporal  Laterotemporal    1.0    9.0   \n",
       "4      EL010  HIPP  PlanTGpole  Mesiotemporal  Superotemporal    1.0   10.0   \n",
       "...      ...   ...         ...            ...             ...    ...    ...   \n",
       "20480  EL017   SFS      IFGopc   Dorsofrontal    Dorsofrontal  576.0  566.0   \n",
       "20481  EL017   SFS         IFS   Dorsofrontal    Dorsofrontal  576.0  570.0   \n",
       "20482  EL017   SFS         IFS   Dorsofrontal    Dorsofrontal  576.0  571.0   \n",
       "20483  EL017   SFS         IFS   Dorsofrontal    Dorsofrontal  576.0  572.0   \n",
       "20484  EL017   SFS         SFS   Dorsofrontal    Dorsofrontal  576.0  574.0   \n",
       "\n",
       "            Sig  H    LL_sig  Dir_index  Dir_B  t_resp      d            Dist  \n",
       "0      1.000000  0  8.664564   0.000000    2.0   0.000   7.00  local (<15 mm)  \n",
       "1      0.000000  0       NaN  -1.000000    0.0   0.000  21.00   short (<30mm)  \n",
       "2      0.688525  0  2.751050   0.000052    2.0   0.018  24.50   short (<30mm)  \n",
       "3      0.000000  0       NaN        NaN    0.0   0.000  28.00   short (<30mm)  \n",
       "4      0.750000  0  2.529343        NaN    1.0   0.000  55.76            long  \n",
       "...         ... ..       ...        ...    ...     ...    ...             ...  \n",
       "20480  0.000000  0       NaN  -1.000000    0.0   0.052  52.41            long  \n",
       "20481  0.647059  0  2.629726  -0.091912    2.0   0.000  21.00   short (<30mm)  \n",
       "20482  0.000000  0       NaN  -1.000000    0.0   0.000  17.50   short (<30mm)  \n",
       "20483  1.000000  0  4.248322  -0.000000    2.0   0.000  14.00  local (<15 mm)  \n",
       "20484  1.000000  0  8.450292   0.013841    2.0   0.000   7.00  local (<15 mm)  \n",
       "\n",
       "[20485 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "streaming-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_con_file = 'Y:\\eLab\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\Across\\BrainMapping\\General\\data\\\\data_con_all.csv'\n",
    "if os.path.exists(data_con_file):\n",
    "    data_con = pd.read_csv(data_con_file)\n",
    "else:\n",
    "    chan_n_max = 0\n",
    "    for i in range(len(subjs)):\n",
    "        print('loading -- ' + subjs[i], end='\\r')\n",
    "        subj = subjs[i]\n",
    "        path_gen = os.path.join('y:\\\\eLab\\Patients\\\\' + subj)\n",
    "        if not os.path.exists(path_gen):\n",
    "            path_gen = 'T:\\\\EL_experiment\\\\Patients\\\\' + subj\n",
    "        path_patient = path_gen + '\\Data\\EL_experiment'\n",
    "        path_infos = os.path.join(path_patient, 'infos')\n",
    "        if not os.path.exists(path_infos):\n",
    "            path_infos = path_gen + '\\\\infos'\n",
    "        path_patient_analysis = 'y:\\eLab\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\\\' + subj\n",
    "\n",
    "        file_con = path_patient_analysis + '\\\\' +folder + '\\\\' + cond_folder + '\\\\data\\\\summary_general.csv'\n",
    "        data_A = pd.read_csv(file_con)\n",
    "\n",
    "        lbls = pd.read_excel(os.path.join(path_infos, subj + \"_labels.xlsx\"), header=0, sheet_name='BP')\n",
    "        labels_all = lbls.label.values\n",
    "        labels_clinic = lbls.Clinic.values\n",
    "        labels_region = lbls.Region.values\n",
    "        labels_region[labels_region == 'HIPP'] = 'Mesiotemporal'\n",
    "        labels_region[labels_region == 'HIPP '] = 'Mesiotemporal'\n",
    "        labels_region[labels_region == 'ENT'] = 'Basotemporal'\n",
    "        bad_region = np.where((labels_region == 'WM') | (labels_region == 'OUT') | (labels_region == 'Putamen'))[0]\n",
    "\n",
    "        StimChanIx = np.unique(data_A.Stim)\n",
    "        bad_chans = pd.read_csv(path_patient_analysis + '/BrainMapping/data/badchan.csv')\n",
    "        bad_chans = np.unique(np.array(np.where(bad_chans.values[:, 1:] == 1))[0, :])\n",
    "        non_stim = np.arange(len(labels_all))\n",
    "        non_stim = np.delete(non_stim, StimChanIx.astype('int'), 0)\n",
    "        WM_chans = np.where(labels_region == 'WM')[0]\n",
    "        bad_all = np.unique(np.concatenate([WM_chans, bad_region, bad_chans, non_stim])).astype('int')\n",
    "\n",
    "        # data_A = data_A[~np.isin(data_A.Chan,bad_all)&~np.isin(data_A.Stim,bad_all)]\n",
    "        data_A.reset_index(drop=True)\n",
    "        data_A.insert(0, 'Subj', subjs[i])\n",
    "        data_A.insert(1, 'StimR', '0')\n",
    "        data_A.insert(2, 'ChanR', '0')\n",
    "        data_A.insert(1, 'StimA', '0')\n",
    "        data_A.insert(2, 'ChanA', '0')\n",
    "        data_A.insert(8, 'H', 0)\n",
    "        for c in np.unique(data_A[['Chan', 'Stim']]).astype('int'):\n",
    "            data_A.loc[data_A.Chan == c, 'ChanR'] = labels_region[c]\n",
    "            data_A.loc[data_A.Stim == c, 'StimR'] = labels_region[c]\n",
    "            data_A.loc[data_A.Chan == c, 'ChanA'] = \" \".join(re.findall(\"[a-zA-Z_]+\", labels_all[c]))\n",
    "            data_A.loc[data_A.Stim == c, 'StimA'] = \" \".join(re.findall(\"[a-zA-Z_]+\", labels_all[c]))\n",
    "            chans = data_A.loc[data_A.Stim == c, 'Chan'].values.astype('int')\n",
    "            data_A.loc[data_A.Stim == c, 'H'] = np.array(lbls.Hemisphere[chans] != lbls.Hemisphere[c]) * 1\n",
    "        #data_A = data_A[~np.isnan(data_A.N1.values)]\n",
    "        data_A.Stim = data_A.Stim + chan_n_max + 1\n",
    "        data_A.Chan = data_A.Chan + chan_n_max + 1\n",
    "\n",
    "        if i == 0:\n",
    "            data_con = data_A\n",
    "        else:\n",
    "            data_con = pd.concat([data_con, data_A])\n",
    "            data_con = data_con.reset_index(drop=True)\n",
    "        chan_n_max = np.max(data_con[['Chan', 'Stim']].values)\n",
    "    data_con = data_con[(data_con.ChanA != 'Necrosis') & (data_con.StimA != 'Necrosis')]\n",
    "\n",
    "    data_con.to_csv(data_con_file,\n",
    "        header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "greenhouse-binding",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-03d3a813a938>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "start "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-residence",
   "metadata": {},
   "source": [
    "## NXVIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nxviz\n",
    "from nxviz.plots_cust import CircosPlot, MatrixPlot, ArcPlot, BasePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot  = data_con[data_con.Sig >0]\n",
    "chan_ID = np.unique(np.concatenate([data_plot.Stim, data_plot.Chan])).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.empty_graph(len(chan_ID))\n",
    "for i in range(len(chan_ID)):\n",
    "    if len(data_plot.loc[data_plot.Stim == chan_ID[i], 'Subj'].values) > 0:\n",
    "        G.nodes[i][\"subj\"] = data_plot.loc[data_plot.Stim == chan_ID[i], 'Subj'].values[0]\n",
    "        G.nodes[i][\"area\"] = data_plot.loc[data_plot.Stim == chan_ID[i], 'StimA'].values[0]\n",
    "        G.nodes[i][\"region\"] = data_plot.loc[data_plot.Stim == chan_ID[i], 'StimR'].values[0]\n",
    "        G.nodes[i][\"label\"] = data_plot.loc[data_plot.Stim == chan_ID[i], 'StimA'].values[0]+'_'+str(i)\n",
    "    else:\n",
    "        G.nodes[i][\"subj\"] = data_plot.loc[data_plot.Chan == chan_ID[i], 'Subj'].values[0]\n",
    "        G.nodes[i][\"area\"] = data_plot.loc[data_plot.Chan == chan_ID[i], 'ChanA'].values[0]\n",
    "        G.nodes[i][\"region\"] = data_plot.loc[data_plot.Chan == chan_ID[i], 'ChanR'].values[0]\n",
    "        G.nodes[i][\"label\"] = data_plot.loc[data_plot.Chan == chan_ID[i], 'ChanA'].values[0]+'_'+str(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-insider",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjs = np.unique(data_con.Subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "## edges\n",
    "G.remove_edges_from(G.edges())\n",
    "df_2_edges = data_plot[(data_plot.Dir_index >= 0)&(data_plot.Dir_index > 0.5)& (data_plot.d > 15)& (data_plot.d < 30)]\n",
    "for i in range(len(df_2_edges)): # \n",
    "    c = 'b'\n",
    "    di = np.random.choice([0,1])\n",
    "    G.add_edge(np.where(chan_ID == df_2_edges.Stim.values[i].astype('int'))[0][0],\n",
    "               np.where(chan_ID == df_2_edges.Chan.values[i].astype('int'))[0][0],\n",
    "               weight=df_2_edges.Dir_index.values[i].astype('int'), color=c, direction = di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CircosPlot(\n",
    "    G,\n",
    "    node_grouping=\"region\",\n",
    "    node_subgrouping=[\"area\",\"subj\"],\n",
    "    node_color=\"subj\",\n",
    "    node_labels= True,\n",
    "    node_label= 'label',\n",
    "    group_label_position=\"middle\",\n",
    "    group_label_color=True,\n",
    "    group_label_offset=65,\n",
    "    figsize=(25,25), \n",
    "    fontsize=15\n",
    ")\n",
    "c.draw()\n",
    "plt.title('Uni-directional, short connections')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-cyprus",
   "metadata": {},
   "source": [
    "###  circos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = data_con.copy()\n",
    "df_2 = df_2[(~np.isnan(df_2.Dir_index))&(df_2.Sig>0)&(df_2.H==0)&(df_2.Dir_index>=0)]\n",
    "for i in range(len(subjs)):\n",
    "    df_2.loc[(df_2.Subj == subjs[i]), 'Stim'] = df_2.loc[(df_2.Subj == subjs[i]), 'Stim']+i*200\n",
    "    df_2.loc[(df_2.Subj == subjs[i]), 'Chan'] = df_2.loc[(df_2.Subj == subjs[i]), 'Chan']+i*200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_ID = np.unique(np.concatenate([df_2.Stim,df_2.Chan])).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "lobe = df_2.loc[df_2.Stim==chan_ID[i], 'StimR'].values[0]\n",
    "par = df_2.loc[df_2.Stim==chan_ID[i], 'StimA'].values[0]+'_'+str(chan_ID[i])\n",
    "z1 = str(float(df_2.loc[df_2.Stim==chan_ID[i], 'Subj'].values[0][-2:])/100)\n",
    "Map = pd.DataFrame([[lobe, par, '0','0','0',z1,z1,z1,z1]], columns=['region', 'parcelation', 'r','g','b','z1','z2','z3','z4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-mobility",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,len(chan_ID)):\n",
    "    if len(df_2.loc[df_2.Stim==chan_ID[i], 'Subj'].values)>0:\n",
    "        lobe = df_2.loc[df_2.Stim==chan_ID[i], 'StimR'].values[0]\n",
    "        par = df_2.loc[df_2.Stim==chan_ID[i], 'StimA'].values[0]+'_'+str(chan_ID[i])\n",
    "        z1 = float(df_2.loc[df_2.Stim==chan_ID[i], 'Subj'].values[0][-2:])/100\n",
    "    else:\n",
    "        lobe = df_2.loc[df_2.Chan==chan_ID[i], 'ChanR'].values[0]\n",
    "        par = df_2.loc[df_2.Chan==chan_ID[i], 'ChanA'].values[0]+'_'+str(chan_ID[i])\n",
    "        z1 = str(float(df_2.loc[df_2.Chan==chan_ID[i], 'Subj'].values[0][-2:])/100)\n",
    "    Map_row = pd.DataFrame([[lobe, par, '0','0','0',z1,z1,z1,z1]], columns=['region', 'parcelation', 'r','g','b','z1','z2','z3','z4'])\n",
    "\n",
    "    Map = pd.concat([Map, Map_row])\n",
    "Map = Map.reset_index(drop=True)\n",
    "Map = Map.sort_values(by=\"region\")\n",
    "Map = Map.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "lobes = np.unique(Map.region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_order = [\"Orbitofrontal\", \"Dorsofrontal\", \"Central\", ' Cingular','Insula','Superotemporal' ,'Laterotemporal','Basotemporal','Mesiotemporal', 'Sylvian','Parietal','Occipital']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-sullivan",
   "metadata": {},
   "outputs": [],
   "source": [
    "start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-ethernet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-estonia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "stainless-whale",
   "metadata": {},
   "source": [
    "## Circos plot preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map['region'] = pd.Categorical(Map['region'], r_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "Map = Map.sort_values(\"region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_map = '/Users/ellenvanmaren/Desktop/Insel/EL_experiment/connectogram/Map_DIR/raw/map.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_map, 'a') as f:\n",
    "    dfAsString = Map.to_string(header=False, index=False)\n",
    "    f.write(dfAsString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_links = '/Users/ellenvanmaren/Desktop/Insel/EL_experiment/connectogram/Map_DIR/raw/map.links.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "p1 = df_2.StimA.values[i]+'_'+str(int(df_2.Stim.values[i]))\n",
    "p2 =df_2.ChanA.values[i]+'_'+str(int(df_2.Chan.values[i]))\n",
    "score = df_2.Dir_index.values[i]\n",
    "t = 0\n",
    "if score >0.5:\n",
    "    t = 1\n",
    "    \n",
    "M_links = pd.DataFrame([['l', p1, 'l', p2, str(t), str(score)]], columns=['h1', 'p1', 'h2','p2','type','score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,len(df_2)):\n",
    "    p1 = df_2.StimA.values[i]+'_'+str(int(df_2.Stim.values[i]))\n",
    "    p2 =df_2.ChanA.values[i]+'_'+str(int(df_2.Chan.values[i]))\n",
    "    score = abs(df_2.Dir_index.values[i])\n",
    "    t = 0\n",
    "    h = 'l'\n",
    "    if score >0.5:\n",
    "        t = 1\n",
    "        h ='r'\n",
    "    M_links_new = pd.DataFrame([[h, p1, h, p2, str(t), str(score)]], columns=['h1', 'p1', 'h2','p2','type','score'])\n",
    "    M_links = pd.concat([M_links, M_links_new])\n",
    "M_links = M_links.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_links, 'a') as f:\n",
    "    dfAsString = M_links.to_string(header=False, index=False)\n",
    "    f.write(dfAsString)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-footage",
   "metadata": {},
   "source": [
    "#### DiGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "for i in range(len(chan_ID)):\n",
    "    if len(df_2.loc[df_2.Stim==chan_ID[i], 'Subj'].values)>0:\n",
    "        G.add_node(chan_ID[i], subj = df_2.loc[df_2.Stim==chan_ID[i], 'Subj'].values[0], area = df_2.loc[df_2.Stim==chan_ID[i], 'StimA'].values[0], region = df_2.loc[df_2.Stim==chan_ID[i], 'StimR'].values[0])\n",
    "    else:\n",
    "        G.add_node(chan_ID[i], subj = df_2.loc[df_2.Chan==chan_ID[i], 'Subj'].values[0], area = df_2.loc[df_2.Chan==chan_ID[i], 'ChanA'].values[0], region = df_2.loc[df_2.Chan==chan_ID[i], 'StimA'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "widespread-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_2)):\n",
    "    G.add_edge(df_2.Stim.values[i].astype('int'), df_2.Chan.values[i].astype('int'), weight=df_2.Dir_index.values[i].astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-collectible",
   "metadata": {},
   "source": [
    "#### complete GRaph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.empty_graph(len(chan_ID))\n",
    "for i in range(len(chan_ID)):\n",
    "    if len(df_2.loc[df_2.Stim==chan_ID[i], 'Subj'].values)>0:\n",
    "        G.nodes[i][\"subj\"] = df_2.loc[df_2.Stim==chan_ID[i], 'Subj'].values[0]\n",
    "        G.nodes[i][\"area\"] =  df_2.loc[df_2.Stim==chan_ID[i], 'StimA'].values[0]\n",
    "        G.nodes[i][\"region\"] = df_2.loc[df_2.Stim==chan_ID[i], 'StimR'].values[0]\n",
    "    else:\n",
    "        G.nodes[i][\"subj\"] = df_2.loc[df_2.Chan==chan_ID[i], 'Subj'].values[0]\n",
    "        G.nodes[i][\"area\"] =  df_2.loc[df_2.Chan==chan_ID[i], 'ChanA'].values[0]\n",
    "        G.nodes[i][\"region\"] = df_2.loc[df_2.Chan==chan_ID[i], 'ChanR'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_2)):\n",
    "    c= 'b'\n",
    "    if df_2.Dir_index.values[i].astype('int')>0.5:\n",
    "        c = 'r'\n",
    "    G.add_edge(np.where(chan_ID==df_2.Stim.values[i].astype('int'))[0][0], np.where(chan_ID==df_2.Chan.values[i].astype('int'))[0][0], weight=df_2.Dir_index.values[i].astype('int'), color=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-sound",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The required libraries and packages ###\n",
    "import networkx as nx\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nxviz\n",
    "from nxviz.plots import CircosPlot, MatrixPlot, ArcPlot, BasePlot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-rebecca",
   "metadata": {},
   "source": [
    "G = nx.complete_graph(5)\n",
    "pos = nx.circular_layout(G)\n",
    "nx.draw(G, pos=pos)  # Draw the original graph\n",
    "# Draw a subgraph, reusing the same node positions\n",
    "nx.draw(G.subgraph([0, 1, 2]), pos=pos, node_color=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c = CircosPlot(\n",
    "    G,\n",
    "    node_grouping=\"region\",\n",
    "    node_color=\"area\",\n",
    "    node_order=\"region\",\n",
    "    node_labels=True,\n",
    "    group_label_position=\"middle\",\n",
    "    group_label_color=True,\n",
    "    group_label_offset=2,\n",
    "    edge_color='weight',\n",
    "    edge_cmap='seismic',\n",
    "    figsize=(20,20)\n",
    ")\n",
    "c.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(nodes_df, edges_df):\n",
    "    # make graph from nodes and edges\n",
    "    g = nx.DiGraph()\n",
    "    for i, row in nodes_df.iterrows():\n",
    "        keys = row.index.tolist()\n",
    "\n",
    "        values = row.values\n",
    "\n",
    "        # The dict contains all attributes\n",
    "\n",
    "        g.add_node(row['ID'], **dict(zip(keys, values)))\n",
    "\n",
    "    for i, row in edges_df.iterrows():\n",
    "        keys = row.index.tolist()\n",
    "\n",
    "        values = row.values\n",
    "\n",
    "        g.add_edge(row['source'], row['target'], weight=row['LL_peak'], **dict(zip(keys, values)))\n",
    "\n",
    "    return g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
