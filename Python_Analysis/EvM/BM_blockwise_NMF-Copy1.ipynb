{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "legendary-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import imageio\n",
    "import h5py\n",
    "# import scipy.fftpack\n",
    "import matplotlib\n",
    "import pywt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "# from scipy import signal\n",
    "from matplotlib.colors import ListedColormap\n",
    "import time\n",
    "import seaborn as sns\n",
    "# import scipy.io as sio\n",
    "# from scipy.integrate import simps\n",
    "import pandas as pd\n",
    "# from scipy import fft\n",
    "import matplotlib.mlab as mlab\n",
    "import sys\n",
    "import matplotlib as mpl\n",
    "sys.path.append('T:\\EL_experiment\\Codes\\CCEP_human\\Python_Analysis\\py_functions')\n",
    "import NMF_funcs as NMFf\n",
    "\n",
    "from scipy.stats import norm\n",
    "import LL_funcs\n",
    "from scipy.stats import norm\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "import ntpath\n",
    "\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "import math\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import pylab\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import squareform\n",
    "import platform\n",
    "from glob import glob\n",
    "from scipy.io import savemat\n",
    "import scipy.cluster.hierarchy as spc\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "import h5py\n",
    "import basic_func as bf\n",
    "from scipy.integrate import simps\n",
    "from numpy import trapz\n",
    "#import IO_func as IOF\n",
    "#import BM_func as BMf\n",
    "import tqdm\n",
    "from matplotlib.patches import Rectangle\n",
    "from pathlib import Path\n",
    "sub_path  ='X:\\\\4 e-Lab\\\\' # y:\\\\eLab\n",
    "import BM_plots as BMp\n",
    "import freq_funcs as ff\n",
    "import CCEP_plot\n",
    "regions = pd.read_excel(\"T:\\EL_experiment\\Patients\\\\\" + 'all' + \"\\elab_labels.xlsx\", sheet_name='regions', header=0)\n",
    "color_regions = regions.color.values\n",
    "regions = regions.label.values\n",
    "\n",
    "CR_color = pd.read_excel(\"T:\\EL_experiment\\Patients\\\\\" + 'all' + \"\\Analysis\\BrainMapping\\CR_color.xlsx\", header=0)\n",
    "CR_color_a = CR_color.a.values\n",
    "CR_color = CR_color.c.values\n",
    "CR_color = np.zeros((24, 3))\n",
    "CR_color[6:18, :] = np.array([253, 184, 19]) / 255\n",
    "\n",
    "dist_groups = np.array([[0, 30], [30, 60], [60, 120]])\n",
    "dist_labels = ['local (<30 mm)', 'short (<60mm)', 'long']\n",
    "Fs = 500\n",
    "dur = np.zeros((1, 2), dtype=np.int32)\n",
    "t0 = 1\n",
    "dur[0, 0] = -t0\n",
    "dur[0, 1] = 3\n",
    "\n",
    "folder = 'BrainMapping'\n",
    "# dur[0,:]       = np.int32(np.sum(abs(dur)))\n",
    "x_ax = np.arange(dur[0, 0], dur[0, 1], (1 / Fs))\n",
    "color_elab = np.zeros((3, 3))\n",
    "color_elab[0, :] = np.array([31, 78, 121]) / 255\n",
    "color_elab[1, :] = np.array([189, 215, 238]) / 255\n",
    "color_elab[2, :] = np.array([0.256, 0.574, 0.431])\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "promotional-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_sleep = ['#808080', '#145da0', '#ff1919']\n",
    "label_sleep = ['Wake', 'NREM', 'REM']\n",
    "color_dist = ['0000FF','#0076C4','#00DD91']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "relevant-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_folder = 'CR'  # Condition = 'Hour', 'Condition', 'Ph'\n",
    "if cond_folder == 'Ph':\n",
    "    cond_vals = np.arange(4)\n",
    "    cond_labels = ['BM', 'BL', 'Fuma', 'BZD']\n",
    "    cond_colors = ['#494159', '#594157', \"#F1BF98\", \"#8FB996\"]\n",
    "    cond1 = 'Condition'  # 'condition', 'h'\n",
    "    cond_folder = 'Ph'  # 'Ph', 'Sleep', 'CR'\n",
    "    Condition = 'Condition'\n",
    "if cond_folder == 'CR':\n",
    "    Condition = 'Hour'  # Condition = 'Hour'\n",
    "    cond1 = 'h'  # h (as stored in stimlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-employer",
   "metadata": {},
   "source": [
    "## Cluster to Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sitting-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_distributions(dist1, dist2):\n",
    "    \"\"\"\n",
    "    Compare two distributions using Wilcoxon signed-rank test.\n",
    "    Return +1 if the median of dist2 is significantly greater than that of dist1,\n",
    "    -1 if it's significantly smaller, 0 otherwise.\n",
    "    \"\"\"\n",
    "    stat, p = scipy.stats.kruskal(dist1, dist2)\n",
    "    #print(p)\n",
    "    if p < 0.001:\n",
    "        \n",
    "        return 1 if np.median(dist2) > np.median(dist1) else -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "documented-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sleep_effect(con_trial, con_summary, metric = 'LL_norm'):\n",
    "    clusters = con_trial['Cluster'].unique()\n",
    "        # Iterate over clusters\n",
    "    for cluster in clusters:\n",
    "        # Get unique Stim and Chan combinations for the current cluster\n",
    "        data_cluster = con_trial.loc[con_trial['Cluster'] == cluster]\n",
    "        #print(cluster)\n",
    "        # Compare distributions of LL_onset_norm between Wake and NREM\n",
    "        nrem = compare_distributions(data_cluster[data_cluster.SleepState == 'Wake'][metric].values, data_cluster[data_cluster.SleepState == 'NREM'][metric].values)\n",
    "        # Compare distributions of LL_onset_norm between Wake and REM\n",
    "        rem = compare_distributions(data_cluster[data_cluster.SleepState == 'Wake'][metric].values, data_cluster[data_cluster.SleepState == 'REM'][metric].values)\n",
    "\n",
    "        con_summary.loc[con_summary['Cluster'] == cluster, 'NREM_Effect'] = nrem\n",
    "        con_summary.loc[con_summary['Cluster'] == cluster, 'REM_Effect'] = rem\n",
    "    return con_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b53be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_gen_base = sub_path + '\\Patients'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04e0715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = \"EL027\"\n",
    "path_patient_analysis = os.path.join(sub_path, 'EvM', 'Projects', 'EL_experiment', 'Analysis', 'Patients', subj)\n",
    "\n",
    "path_gen = os.path.join(sub_path+'\\Patients\\\\' + subj)\n",
    "if not os.path.exists(path_gen):\n",
    "    path_gen = 'T:\\\\EL_experiment\\\\Patients\\\\' + subj\n",
    "path_patient = path_gen + '\\Data\\EL_experiment'  # os.path.dirname(os.path.dirname(cwd))+'/Patients/'+subj\n",
    "path_infos = os.path.join(path_gen, 'Electrodes')\n",
    "# labels\n",
    "files_list = glob(path_patient_analysis + '\\\\' + folder + '/data/Stim_list_*')\n",
    "i = 0\n",
    "stimlist_file = path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\stimlist_' + cond_folder + '.csv'\n",
    "stimlist = pd.read_csv(stimlist_file)\n",
    "lbls = pd.read_excel(os.path.join(path_infos, subj + \"_labels.xlsx\"), header=0, sheet_name='BP')\n",
    "if \"type\" in lbls.columns:\n",
    "    lbls = lbls[lbls.type=='SEEG']\n",
    "    lbls = lbls.reset_index(drop=True)\n",
    "labels_all, labels_region, labels_clinic, coord_all, StimChans, StimChanSM, StimChansC, StimChanIx, stimlist = bf.get_Stim_chans(\n",
    "    stimlist,\n",
    "    lbls)\n",
    "stimlist_sleep = pd.read_csv(os.path.join(path_patient_analysis, 'stimlist_hypnogram.csv'))\n",
    "file_con = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "con_trial = pd.read_csv(file_con)\n",
    "badchans = pd.read_csv(path_patient_analysis + '/BrainMapping/data/badchan.csv')\n",
    "bad_chans = np.unique(np.array(np.where(badchans.values[:, 1:] == 1))[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6eb6076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading h5\n",
      "(112, 32402, 2000)\n",
      "32402\n",
      "32402\n"
     ]
    }
   ],
   "source": [
    "h5_file = path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\EEG_' + cond_folder + '.h5'\n",
    "if os.path.isfile(h5_file):\n",
    "    print('loading h5')\n",
    "    EEG_resp = h5py.File(h5_file)\n",
    "    EEG_resp = EEG_resp['EEG_resp']\n",
    "print(EEG_resp.shape)\n",
    "print(len(stimlist))\n",
    "print(np.max(con_trial.Num)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8747a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial = bf.add_sleepstate(con_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69958c06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "axes = CCEP_plot.plot_Sig(0,111, EEG_resp, con_trial[con_trial.Artefact<1], labels_all)\n",
    "axes[0].set_ylim([-700,700])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ce758b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading h5\n",
      "(112, 32402, 2000)\n",
      "32402\n",
      "32402\n"
     ]
    }
   ],
   "source": [
    "parameters=['Sig', 'd', 'delay']\n",
    "cluster_method = 'similarity'\n",
    "file_CC_summ = path_patient_analysis + '\\\\' + folder + '\\\\data\\\\CC_summ_' + cluster_method + '.csv'\n",
    "\n",
    "CC_summ = pd.read_csv(file_CC_summ)\n",
    "CC_summ = CC_summ[(CC_summ.sig >0.5)]\n",
    "CC_summ = CC_summ.groupby(['Stim', 'Chan'], as_index=False)[['t_WOI']].mean()\n",
    "file_CC_summ = path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\summ_general.csv'  # summary_genera\n",
    "con_summary_all = pd.read_csv(file_CC_summ)\n",
    "\n",
    "con_summary = con_summary_all[(con_summary_all.Sig > 0)].reset_index(drop=True)\n",
    "con_summary_short = con_summary[(np.isin(con_summary.Stim, np.unique(con_summary.Chan)))&(np.isin(con_summary.Chan, np.unique(con_summary.Stim)))].reset_index(drop=True)\n",
    "con_summary_short = con_summary_short.groupby(['Stim', 'Chan'], as_index=False)[parameters].mean().reset_index(drop=True)\n",
    "\n",
    "print(EEG_resp.shape)\n",
    "print(len(stimlist))\n",
    "print(np.max(con_trial.Num)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e371e7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_summary = con_summary_all[(con_summary_all.Sig > 0)].reset_index(drop=True)\n",
    "con_summary_short = con_summary[(np.isin(con_summary.Stim, np.unique(con_summary.Chan)))&(np.isin(con_summary.Chan, np.unique(con_summary.Stim)))].reset_index(drop=True)\n",
    "con_summary_short = con_summary_short.groupby(['Stim', 'Chan'], as_index=False)[parameters].mean().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc98e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a90a98",
   "metadata": {},
   "source": [
    "# NMF on subset of connections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aace500",
   "metadata": {},
   "source": [
    "## Hard clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843bb31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NMF_funcs as nmf\n",
    "import sklearn\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1be3ff",
   "metadata": {},
   "source": [
    "### distance & delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ec755",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial.insert(0,'Con_ID',con_trial.groupby(['Stim', 'Chan']).ngroup())\n",
    "con_trial['LL_sig'] = con_trial['LL']*con_trial['Sig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6325a87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_summary.insert(0, 'Con_group', 'local')\n",
    "con_summary.loc[(con_summary.d>20)&(con_summary.delay>0.02), 'Con_group'] = 'indirect'\n",
    "con_summary.loc[(con_summary.d>20)&(con_summary.delay<0.02), 'Con_group'] = 'direct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb29b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial_grouped = con_trial.merge(con_summary[['Stim', 'Chan', 'Con_group', 'StimR', 'ChanR']], on = ['Stim', 'Chan'], how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial_grouped = con_trial_grouped[~np.isin(con_trial_grouped.Chan, bad_chans)&(con_trial_grouped.Ictal==0)&(con_trial_grouped.LL<50)&(con_trial_grouped.P2P<6000)&(con_trial_grouped.Artefact<1)&(con_trial_grouped.Sig>-1)].reset_index(drop=True)\n",
    "\n",
    "#con_trial['LL_ratio'] = con_trial['LL']/con_trial['LL_pre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b07b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(path_patient_analysis, 'BrainMapping', 'CR', 'NMF','subnetwork_features')\n",
    "cond_folder = 'CR'\n",
    "os.makedirs(exp_dir, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dcee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = 'LL_sig' #m+'_BL'\n",
    "data_plot = con_trial_grouped.groupby(['Con_ID','Con_group', 'Stim', 'Chan','StimR', 'ChanR', 'Block'], as_index=False)[[m, 'Sig']].mean().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abff55",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sel = 'direct'\n",
    "title = group_sel +' connections'\n",
    "df_pivot = data_plot[data_plot.Con_group == group_sel].pivot(index='Con_ID', columns='Block', values=m)\n",
    "df_pivot = df_pivot.apply(lambda row: row.fillna(row.mean()), axis=1) \n",
    "df_pivot = df_pivot.fillna(df_pivot.median(axis=0)) \n",
    "V = df_pivot.values\n",
    "V = sklearn.preprocessing.normalize(V,axis = 1)\n",
    "plt.pcolormesh(V)\n",
    "plt.ylabel(group_sel +' connections')\n",
    "plt.xlabel('Stimulation Block')\n",
    "plt.title('NMF Input LL value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8edb71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nmf.parallel_nmf_consensus_clustering(V.T, [1,4], 50, experiment_dir=exp_dir, target_clusters=None)\n",
    "\n",
    "metric = pd.read_csv(os.path.join(exp_dir, 'metrics.csv'))\n",
    "k = metric.loc[(metric['Instability index'] == np.min(metric['Instability index'])), 'Rank'].values[0]\n",
    "H = pd.read_csv(os.path.join(exp_dir, 'k=' + str(k), 'H_best.csv'), header=None).values\n",
    "W = pd.read_csv(os.path.join(exp_dir, 'k=' + str(k), 'W_best.csv'), header=None).values\n",
    "plot_H_hypnogram(H, con_trial, stimlist_sleep)\n",
    "plt.suptitle(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4778ea",
   "metadata": {},
   "source": [
    "### ANATOMY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f7ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim = 'Temporal'\n",
    "resp = 'Insula'\n",
    "group_sel = stim + '-'+resp\n",
    "title = group_sel +' connections'\n",
    "df_pivot = data_plot[(data_plot.StimR == stim)&(data_plot.ChanR == resp)].pivot(index='Con_ID', columns='Block', values=m)\n",
    "df_pivot = df_pivot.apply(lambda row: row.fillna(row.mean()), axis=1) \n",
    "df_pivot = df_pivot.fillna(df_pivot.median(axis=0)) \n",
    "V = df_pivot.values\n",
    "V = sklearn.preprocessing.normalize(V,axis = 1)\n",
    "plt.pcolormesh(V)\n",
    "plt.ylabel(title)\n",
    "plt.xlabel('Stimulation Block')\n",
    "plt.title('NMF Input LL value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edd6bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf.parallel_nmf_consensus_clustering(V.T, [2,3], 50, experiment_dir=exp_dir, target_clusters=None)\n",
    "\n",
    "metric = pd.read_csv(os.path.join(exp_dir, 'metrics.csv'))\n",
    "k = metric.loc[(metric['Instability index'] == np.min(metric['Instability index'])), 'Rank'].values[0]\n",
    "H = pd.read_csv(os.path.join(exp_dir, 'k=' + str(k), 'H_best.csv'), header=None).values\n",
    "W = pd.read_csv(os.path.join(exp_dir, 'k=' + str(k), 'W_best.csv'), header=None).values\n",
    "plot_H_hypnogram(H, con_trial, stimlist_sleep)\n",
    "plt.suptitle(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc68ab",
   "metadata": {},
   "source": [
    "## NMF clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0529fb7a",
   "metadata": {},
   "source": [
    "### Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe8271",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_summary[con_summary.Sig >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cbfc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = con_summary[(np.isin(con_summary.Stim, np.unique(con_summary.Chan)))&(np.isin(con_summary.Chan, np.unique(con_summary.Stim)))].groupby(['Stim', 'Chan'], as_index=False)[m_cluster].mean()\n",
    "nodes_important = np.unique(df_pivot.Stim)\n",
    "df_pivot[m_cluster] = 1/df_pivot[m_cluster]\n",
    "df_pivot = df_pivot.pivot(index='Stim', columns='Chan', values=m_cluster)\n",
    "df_pivot = df_pivot.fillna(0) \n",
    "V = df_pivot.values\n",
    "plt.pcolormesh(V)\n",
    "plt.title('NMF Input LL value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10222d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node_total = len(labels_all)\n",
    "M_V = np.zeros((n_node_total, n_node_total))\n",
    "# Explicitly select the submatrix\n",
    "rows_idx = nodes_important[:, np.newaxis]\n",
    "cols_idx = nodes_important\n",
    "\n",
    "M_V[rows_idx, cols_idx] = V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2da57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "BMp.plot_BM(M_V, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap='hot', vlim=None, sort=1)\n",
    "plt.title('BM based on 1/d (closeness)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e017e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node_total = len(labels_all)\n",
    "n_cluster = W.shape[1]\n",
    "nodes_important = np.unique(con_summary.Stim).astype('int')\n",
    "\n",
    "# Initialize matrices\n",
    "M_W = np.zeros((n_node_total, n_cluster))\n",
    "M_H = np.zeros((n_cluster, n_node_total))\n",
    "M_V = np.zeros((n_node_total, n_node_total))\n",
    "\n",
    "# Assign values\n",
    "M_W[nodes_important, :] = W\n",
    "M_H[:, nodes_important] = H\n",
    "# Explicitly select the submatrix\n",
    "rows_idx = nodes_important[:, np.newaxis]\n",
    "cols_idx = nodes_important\n",
    "\n",
    "M_V[rows_idx, cols_idx] = V\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "BMp.plot_BM(M_V, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap='hot', vlim=None, sort=1)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 10))\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "BMp.plot_BM_coeff(M_W, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap='hot', vlim=None, sort=1, orientation =0)\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "BMp.plot_BM_coeff(M_H, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap='hot', vlim=None, sort=1, orientation =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0667484",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_sel = 'direct'\n",
    "title = group_sel +' connections'\n",
    "df_pivot = data_plot[data_plot.Con_group == group_sel].pivot(index='Con_ID', columns='Block', values=m)\n",
    "df_pivot = df_pivot.apply(lambda row: row.fillna(row.mean()), axis=1) \n",
    "df_pivot = df_pivot.fillna(df_pivot.median(axis=0)) \n",
    "V = df_pivot.values\n",
    "V = sklearn.preprocessing.normalize(V,axis = 1)\n",
    "plt.pcolormesh(V)\n",
    "plt.ylabel(group_sel +' connections')\n",
    "plt.xlabel('Stimulation Block')\n",
    "plt.title('NMF Input LL value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd5e374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ad8c553",
   "metadata": {},
   "source": [
    "# Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ced2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wake_trials(sc, rc, con_trial):\n",
    "    lists = con_trial[(con_trial['Chan'] == rc) & (con_trial['Stim'] == sc)]\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    sns.set(style='white')\n",
    "    plt.title(labels_all[sc] + ' -- ' + labels_all[rc], fontsize=30)\n",
    "    ylim = 300\n",
    "\n",
    "        #fig.add_subplot(gs[0, sig])\n",
    "    #gs = fig.add_gridspec(1,2)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "    for sig, sig_lab in zip([0,1,2],['Wake', 'NREM', 'REM']):\n",
    "        stimnum = lists.loc[(lists.SleepState==sig_lab),'Num'].values.astype('int')\n",
    "        #fig.add_subplot(gs[0, sig])\n",
    "        # for i in range(len(stimnum)):\n",
    "        #    plt.plot(x_ax, EEG_CR[rc, stimnum[i],:], color=color_elab[0], alpha=0.5)\n",
    "        mn = ff.lp_filter(np.mean(EEG_resp[rc, stimnum,:],0),30,Fs)\n",
    "        # st= np.std(EEG_resp[rc, stimnum,:],0)\n",
    "        plt.plot(x_ax, mn, color=color_elab[sig], linewidth=5, alpha=0.7, label=sig_lab+', n: '+str(len(stimnum)))\n",
    "        # st= np.std(ff.lp_filter(trials,30,Fs),0)\n",
    "        # plt.fill_between(x_ax,mn-st, mn+st,color=color_elab[sig*2], alpha=0.2 )\n",
    "    plt.xticks([-0.5, 0,0., 1], fontsize=20)\n",
    "    # plt.yticks([-400, 0, 400], fontsize=20)\n",
    "    plt.xlabel('time [s]', fontsize=25)\n",
    "    plt.ylabel('[uV]', fontsize=25)\n",
    "    plt.legend( fontsize=20)\n",
    "    plt.axvline(0, color=[0,0,0], label='stim')\n",
    "        # plt.text(-0.3, 500, 'n: '+str(len(stimnum)), fontsize=20)\n",
    "        #plt.title('Mean Across All Trials', fontsize=25)\n",
    "    plt.xlim([-0.5, 1])\n",
    "    plt.ylim([-ylim,ylim])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5584cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'SleepState' in con_trial:\n",
    "    con_trial.insert(6, 'SleepState', 'Wake')\n",
    "con_trial.loc[(con_trial.SleepState == 'W'), 'SleepState'] = 'Wake'\n",
    "con_trial.loc[(con_trial.Sleep == 0), 'SleepState'] = 'Wake'\n",
    "con_trial.loc[(con_trial.Sleep > 1) & (con_trial.Sleep < 4), 'SleepState'] = 'NREM'\n",
    "con_trial.loc[(con_trial.Sleep == 1), 'SleepState'] = 'NREM1'\n",
    "con_trial.loc[(con_trial.Sleep == 6), 'SleepState'] = 'SZ'\n",
    "con_trial.loc[(con_trial.Sleep == 4), 'SleepState'] = 'REM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a767a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = 18\n",
    "rc = 0\n",
    "plot_wake_trials(sc, rc, con_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704541c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 0\n",
    "if norm:\n",
    "    m = 'LL'\n",
    "    con_trial[m+'_BL'] = con_trial.groupby('Chan').apply(\n",
    "            lambda x: x[m] / x['LL_pre'].median()).reset_index(0, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca7a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial.insert(5, 'zLL', con_trial.groupby(['Con_ID', 'Sleep'])['LL'].transform(lambda x: (x - x.mean()) / x.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892dd1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial.loc[(con_trial.Artefact <1)&(con_trial.P2P>10000), 'Artefact'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3f55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "art_table = con_trial[(con_trial.Artefact <1)&(con_trial.zLL>10)].reset_index(drop=True)# con_trial[(con_trial.Artefact<1)&(con_trial.zLL>5)].reset_index(drop=True)\n",
    "k = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e84caa8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k = k+1\n",
    "sc = art_table.Stim.values[k].astype('int')\n",
    "rc = art_table.Chan.values[k].astype('int')\n",
    "num = art_table.Num.values[k].astype('int')\n",
    "plt.title(str(np.round(art_table.zLL.values[k],2)))\n",
    "plt.plot(x_ax, EEG_resp[rc, num, :])\n",
    "print(np.round(art_table.LL_pre.values[k],2))\n",
    "print(np.round(art_table.P2P.values[k],2))\n",
    "print(np.round(art_table.Artefact.values[k],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'LL_sig' #m+'_BL'\n",
    "data_plot = con_trial[(con_trial.Artefact<1)&(con_trial.Sig>-1)].groupby(['Con_ID','Stim', 'Chan', 'Block'], as_index=False)[[m, 'Sig']].mean().reset_index(drop=True)\n",
    "\n",
    "sig_con = data_plot.groupby(['Con_ID'], as_index=False)['Sig'].mean()\n",
    "sig_con = sig_con.loc[(sig_con.Sig>0), 'Con_ID'].values\n",
    "data_plot = data_plot[np.isin(data_plot.Con_ID, sig_con)].reset_index(drop=True)\n",
    "con_IDs = np.unique(data_plot.Con_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d25fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'LL_sig' #m+'_BL'\n",
    "data_plot = con_trial[(con_trial.Artefact<1)&(con_trial.Sig>-1)].groupby(['Con_ID','Stim', 'Chan', 'Block'], as_index=False)[[m, 'Sig']].mean().reset_index(drop=True)\n",
    "\n",
    "sig_con = data_plot.groupby(['Con_ID'], as_index=False)['Sig'].mean()\n",
    "sig_con = sig_con.loc[(sig_con.Sig>0), 'Con_ID'].values\n",
    "data_plot = data_plot[np.isin(data_plot.Con_ID, sig_con)].reset_index(drop=True)\n",
    "con_IDs = np.unique(data_plot.Con_ID)\n",
    "\n",
    "df_pivot = data_plot.pivot(index='Con_ID', columns='Block', values=m)\n",
    "df_pivot = df_pivot.apply(lambda row: row.fillna(row.mean()), axis=1) \n",
    "df_pivot = df_pivot.fillna(df_pivot.median(axis=0)) \n",
    "V = df_pivot.values\n",
    "if L2:\n",
    "    V = sklearn.preprocessing.normalize(V,axis = 1)\n",
    "    title = m+' (L2 norm)'\n",
    "plt.pcolormesh(V)\n",
    "plt.ylabel('Connection')\n",
    "plt.ylabel('Stimulation Block')\n",
    "plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b0483d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(path_patient_analysis, 'BrainMapping', 'CR', 'NMF','subnetwork')\n",
    "nmf.parallel_nmf_consensus_clustering(V.T, [4,4], 50, experiment_dir=exp_dir, target_clusters=None)\n",
    "\n",
    "metric = pd.read_csv(os.path.join(exp_dir, 'metrics.csv'))\n",
    "k = metric.loc[(metric['Instability index'] == np.min(metric['Instability index'])), 'Rank'].values[0]\n",
    "H = pd.read_csv(os.path.join(exp_dir, 'k=' + str(k), 'H_best.csv'), header=None).values\n",
    "W = pd.read_csv(os.path.join(exp_dir, 'k=' + str(k), 'W_best.csv'), header=None).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdaf208",
   "metadata": {},
   "source": [
    "### Plot W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a549c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assgin_cluster(V, H):\n",
    "    # Compute the correlation between each row in V and each row in H\n",
    "    # Reshape V and H for broadcasting\n",
    "    V_reshaped = V[:, :, None]\n",
    "    H_reshaped = H.T[None, :, :]\n",
    "\n",
    "    # Compute the dot products and the norms\n",
    "    dot_products = np.sum(V_reshaped * H_reshaped, axis=1)\n",
    "    V_norms = np.linalg.norm(V, axis=1)[:, None]\n",
    "    H_norms = np.linalg.norm(H, axis=1)\n",
    "\n",
    "    # Compute the correlation coefficients\n",
    "    correlations = dot_products / (V_norms * H_norms)\n",
    "\n",
    "    # Find the index of the row in H with which each row in V is most similar\n",
    "    most_similar_rows = np.argmax(correlations, axis=1)\n",
    "\n",
    "    return most_similar_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a88992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed70ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wmax =assgin_cluster(V, H)# np.argmax(W,1) \n",
    "BM_W = np.zeros((len(labels_all),len(labels_all)))-1\n",
    "for w_ix in range(H.shape[0]):\n",
    "    for con_ix, con in enumerate(con_IDs):\n",
    "        if Wmax[con_ix] == w_ix:\n",
    "            #  coeff = W[con_ix, w_ix]\n",
    "            sc = data_plot.loc[data_plot.Con_ID == con, 'Stim'].values[0].astype('int')\n",
    "            rc = data_plot.loc[data_plot.Con_ID == con, 'Chan'].values[0].astype('int')\n",
    "            BM_W[sc, rc] = w_ix\n",
    "print(np.unique(BM_W))\n",
    "# mask some 'bad' data, in your case you would have: data == 0\n",
    "BM_W = np.ma.masked_where(BM_W ==-1, BM_W)\n",
    "\n",
    "# cmap = plt.cm.OrRd\n",
    "\n",
    "# for mpl 3.3 and higher use\n",
    "cmap = matplotlib.colormaps[\"Dark2\"] #mpl.cm.get_cmap(\"Dark2\").copy()\n",
    "cmap.set_bad(color='black')\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.suptitle('Clusters - Highest Pearson')\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "axmatrix.pcolormesh(BM_W)\n",
    "# BMp.plot_BM(BM_W, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap=cmap, vlim=[0, H.shape[0]], sort=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bb888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(W, vmin = np.percentile(W,20), vmax = np.percentile(W,95))\n",
    "plt.xticks([0.5, 1.5, 2.5], ['W1', 'W2', 'W3'])\n",
    "#plt.xticks([0.5, 1.5, 2.5, 3.5], ['W1', 'W2', 'W3', 'W4'])\n",
    "plt.ylabel('Connections')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aecf43",
   "metadata": {},
   "source": [
    "##### coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9abde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BM_W = np.zeros((len(labels_all),len(labels_all)))\n",
    "w_ix = 0\n",
    "for con_ix, con in enumerate(con_IDs):\n",
    "    coeff = W[con_ix, w_ix]\n",
    "    sc = data_plot.loc[data_plot.Con_ID == con, 'Stim'].values[0].astype('int')\n",
    "    rc = data_plot.loc[data_plot.Con_ID == con, 'Chan'].values[0].astype('int')\n",
    "    BM_W[sc, rc] = coeff\n",
    "vlim  = [np.percentile(BM_W[0],80),np.percentile(BM_W[0],99)]\n",
    "\n",
    "# mask some 'bad' data, in your case you would have: data == 0\n",
    "BM_W = np.ma.masked_where(BM_W ==0, BM_W)\n",
    "\n",
    "# cmap = plt.cm.OrRd\n",
    "\n",
    "# for mpl 3.3 and higher use\n",
    "cmap = mpl.cm.get_cmap(\"seismic\").copy()\n",
    "cmap.set_bad(color='black')\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.suptitle('W coefficients of Cluster '+str(w_ix+1))\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "BMp.plot_BM(BM_W, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap=cmap, vlim=vlim, sort=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f23bf5",
   "metadata": {},
   "source": [
    "### Plot H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab6d69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_H_hypnogram(H, con_trial, stimlist_sleep, cmap)\n",
    "plt.suptitle(title)\n",
    "# plt.ylim([0.12, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff605b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_H_hypnogram(H, con_trial, stimlist_sleep):\n",
    "    def format_time_hour(x, pos):\n",
    "        while x > 24:\n",
    "            x -= 24\n",
    "        return f'{int(x):02d}:00'\n",
    "    \n",
    "    from matplotlib.ticker import FuncFormatter\n",
    "    path_output = os.path.join(path_patient_analysis, 'BrainMapping', 'CR', 'NMF', 'figures')\n",
    "    os.makedirs(path_output, exist_ok=True)  # Create directories if they don't exist\n",
    "    # adding \"ic_chron\" which adds +24h if there is a new day to keep it chronological\n",
    "    for d in range(len(np.unique(stimlist_sleep.date))):\n",
    "        stimlist_sleep.loc[stimlist_sleep.date == np.unique(stimlist_sleep.date)[d], 'ix_chron'] = \\\n",
    "            stimlist_sleep.loc[\n",
    "                stimlist_sleep.date == np.unique(stimlist_sleep.date)[d], 'ix_h'] + d * 24\n",
    "    stimlist_hypno =stimlist_sleep\n",
    "    stimlist_hypno.loc[stimlist_hypno.sleep > 4, 'sleep'] = 0  # everythin that's greter than 4 is also wake\n",
    "    # some calculations to have the same x time axis for both plots\n",
    "\n",
    "    rk = H.shape[0]\n",
    "    n_block = H.shape[1]\n",
    "    blocks_all = np.unique(con_trial.Block)\n",
    "    # Generating x-axis values\n",
    "    x_ax_block = np.arange(0, n_block).astype('float')\n",
    "    for ix_b, b in enumerate(np.unique(con_trial.Block)):\n",
    "        x_ax_block[ix_b] = np.mean(stimlist_sleep.loc[stimlist_sleep.stim_block == b, 'ix_chron'])\n",
    "    # x_ticks_h = np.arange(0, np.max(blocks_all) + 1, step=5)\n",
    "    # labels_hour = [f'{int(h):02d}:00' for h in np.floor(self.stimlist_sleep.ix_h[x_ticks_h])]\n",
    "    timeline = np.ceil(np.max(stimlist_sleep.ix_chron) - np.min(stimlist_sleep.ix_chron)).astype('int')\n",
    "    # Create figure and subplots\n",
    "    fig, (ax_h, ax) = plt.subplots(2, 1, figsize=(timeline / 3.5, 7))\n",
    "\n",
    "    # Plot hypnogram\n",
    "    ax_h.plot(stimlist_sleep.ix_chron, stimlist_sleep.sleep, c='black', linewidth=2)\n",
    "    ax_h.axhspan(-1, 0.2, color=color_elab[0, :])\n",
    "    ax_h.fill_between(stimlist_sleep.ix_chron,stimlist_sleep.sleep, -1, color=color_elab[0, :])\n",
    "    ax_h.set_yticks([0, 1, 2, 3, 4])\n",
    "    ax_h.set_yticklabels(['Wake', 'N1', 'N2', 'N3', 'REM'])\n",
    "    ax_h.set_ylim([-1, 5])\n",
    "    ax_h.invert_yaxis()\n",
    "    ax_h.set_xticks([])\n",
    "    ax_h.set_ylabel('Score', fontsize=15)\n",
    "\n",
    "    # Plot H coefficients\n",
    "    for i in range(rk):\n",
    "        ax.plot(x_ax_block,H[i], linewidth=4, label=f'H{i + 1}')\n",
    "\n",
    "    # ax.set_xticks(x_ticks_h)\n",
    "    # ax.set_xticklabels(labels_hour, fontsize=12)\n",
    "    ax.set_ylabel('H Coefficients', fontsize=15)\n",
    "    ax.set_xlabel('Time', fontsize=15)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.xaxis.set_major_formatter(FuncFormatter(format_time_hour))\n",
    "    # same xlim as ax_h to be perfectly aligned\n",
    "    ax.set_xlim(ax_h.get_xlim())\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5f1ad7",
   "metadata": {},
   "source": [
    "### First cluster subnetworks based on P values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489df3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial.loc[(con_trial.Sig==-1)&(con_trial.d<7.1), 'Sig'] = 1\n",
    "con_trial = con_trial[con_trial.Sig>-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf34c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial_clean = con_trial[(con_trial.Sig>-1)& (con_trial.Artefact<1)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6312d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_p = con_trial_clean.groupby(['Stim', 'Chan'], as_index=False)[['Sig', 'd']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1777651",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_p =M_p[np.isin(M_p.Chan, np.unique(M_p.Stim))].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e38c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = M_p.pivot(index='Stim', columns='Chan', values='Sig')\n",
    "df_pivot.fillna(0, inplace=True)\n",
    "V = df_pivot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6070b1bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c2c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(path_patient_analysis, 'BrainMapping', 'CR', 'NMF','subnetwork')\n",
    "nmf.parallel_nmf_consensus_clustering(V.T, [3,10], 10, experiment_dir=exp_dir, target_clusters=None)\n",
    "\n",
    "metric = pd.read_csv(os.path.join(exp_dir, 'metrics.csv'))\n",
    "k = metric.loc[(metric['Instability index'] == np.min(metric['Instability index'])), 'Rank'].values[0]\n",
    "H = pd.read_csv(os.path.join(exp_dir, 'k=' + str(k), 'H_best.csv'), header=None).values\n",
    "W = pd.read_csv(os.path.join(exp_dir, 'k=' + str(k), 'W_best.csv'), header=None).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b16185",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_node_total = len(labels_all)\n",
    "n_cluster = W.shape[1]\n",
    "nodes_important = np.unique(M_p.Stim).astype('int')\n",
    "\n",
    "# Initialize matrices\n",
    "M_W = np.zeros((n_node_total, n_cluster))\n",
    "M_H = np.zeros((n_cluster, n_node_total))\n",
    "M_V = np.zeros((n_node_total, n_node_total))\n",
    "\n",
    "# Assign values\n",
    "M_W[nodes_important, :] = W\n",
    "M_H[:, nodes_important] = H\n",
    "# Explicitly select the submatrix\n",
    "rows_idx = nodes_important[:, np.newaxis]\n",
    "cols_idx = nodes_important\n",
    "\n",
    "M_V[rows_idx, cols_idx] = V\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "BMp.plot_BM(M_V, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap='hot', vlim=None, sort=1)\n",
    "\n",
    "fig = plt.figure(figsize=(4, 10))\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "BMp.plot_BM_coeff(M_W, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap='hot', vlim=None, sort=1, orientation =0)\n",
    "\n",
    "fig = plt.figure(figsize=(10,4))\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "BMp.plot_BM_coeff(M_H, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap='hot', vlim=None, sort=1, orientation =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a73b5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "BMp.plot_BM(M_V, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap='hot', vlim=None, sort=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a8f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,4))\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "BMp.plot_BM_coeff(M_H, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap='hot', vlim=None, sort=1, orientation =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6909b4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 10))\n",
    "axmatrix = fig.add_axes([0.15, 0.15, 0.7, 0.7])\n",
    "BMp.plot_BM_coeff(M_W, labels_all, lbls.Hemisphere.values, axmatrix, axcolor=None, cmap='hot', vlim=None, sort=1, orientation =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a8146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = np.unique(con_trial.Block)\n",
    "n_blocks = len(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88263afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 'LL_sig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e04907",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1\n",
    "\n",
    "thr = np.percentile(M_W[:,c],90)\n",
    "stim_chans = np.where(M_W[:,c]>thr)[0]\n",
    "thr = np.percentile(M_H[c,:],90)\n",
    "resp_chans = np.where(M_H[c,:]>thr)[0]\n",
    "data_plot = con_trial_clean.loc[np.isin(con_trial_clean.Stim, stim_chans)&np.isin(con_trial_clean.Chan, resp_chans)] \n",
    "    \n",
    "df_pivot = data_plot.pivot(index='Chan', columns='Num', values=m)\n",
    "df_pivot.fillna(0, inplace=True)\n",
    "V = df_pivot.values\n",
    "if L2:\n",
    "    V = sklearn.preprocessing.normalize(V,axis = 1)\n",
    "    title = 'Subnetwork '+ str(c+1)+', '+m+' (L2 norm)'\n",
    "    \n",
    "plt.pcolormesh(V)\n",
    "plt.ylabel('REsponse channels (part of Cluster)')\n",
    "plt.xlabel('Stimulation trials (only from selected stim channels)')\n",
    "plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c378b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_H_hypnogram(H, con_trial, stimlist_sleep)\n",
    "plt.suptitle(title)\n",
    "# plt.ylim([0.12, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69efe15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir = os.path.join(path_patient_analysis, 'BrainMapping', 'CR', 'NMF','subnetwork')\n",
    "nmf.parallel_nmf_consensus_clustering(V.T, [3,3], 2, experiment_dir=exp_dir, target_clusters=None)\n",
    "\n",
    "metric = pd.read_csv(os.path.join(exp_dir, 'metrics.csv'))\n",
    "k = metric.loc[(metric['Instability index'] == np.min(metric['Instability index'])), 'Rank'].values[0]\n",
    "H = pd.read_csv(os.path.join(exp_dir, 'k=' + str(k), 'H_best.csv'), header=None).values\n",
    "W = pd.read_csv(os.path.join(exp_dir, 'k=' + str(k), 'W_best.csv'), header=None).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4759f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_2 = np.zeros((n_cluster,n_blocks))\n",
    "# find stim / response nodes for each cluster\n",
    "for c in range(n_cluster):\n",
    "    thr = np.percentile(M_W[:,c],90)\n",
    "    stim_chans = np.where(M_W[:,c]>thr)[0]\n",
    "    thr = np.percentile(M_H[c,:],90)\n",
    "    resp_chans = np.where(M_H[c,:]>thr)[0]\n",
    "    data_plot = con_trial_clean.loc[np.isin(con_trial_clean.Stim, stim_chans)&np.isin(con_trial_clean.Chan, resp_chans)]\n",
    "    V_2[c,:] = data_plot.groupby(['Block'])['LL'].median().values\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12fd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(V_2)\n",
    "plt.ylabel('Subnetworks')\n",
    "plt.xlabel('Block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a5f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dir2 = os.path.join(path_patient_analysis, 'BrainMapping', 'CR', 'NMF','subnetwork','k=' + str(k),'temporal_cluster')\n",
    "nmf.parallel_nmf_consensus_clustering(V_2.T, [3,6], 10, experiment_dir=exp_dir2, target_clusters=None)\n",
    "\n",
    "metric = pd.read_csv(os.path.join(exp_dir2, 'metrics.csv'))\n",
    "k = metric.loc[(metric['Instability index'] == np.min(metric['Instability index'])), 'Rank'].values[0]\n",
    "H = pd.read_csv(os.path.join(exp_dir2, 'k=' + str(k), 'H_best.csv'), header=None).values\n",
    "W = pd.read_csv(os.path.join(exp_dir2, 'k=' + str(k), 'W_best.csv'), header=None).values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae4662e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b516414",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(W, cmap = 'hot')\n",
    "plt.ylabel('Subnetworks')\n",
    "plt.xlabel('Temporal Cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(H.shape[0]):\n",
    "    plt.plot(H[h], label = 'H'+str(h))\n",
    "plt.legend()\n",
    "plt.xlabel('BLock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_correlation_condition(con_trial, metric='LL', condition='Block'):\n",
    "    # Clean table\n",
    "    con_trial_cleaned = con_trial[con_trial.Artefact < 1].copy()\n",
    "    con_trial_cleaned.loc[con_trial_cleaned.Sig < 0, 'Sig'] = np.nan\n",
    "\n",
    "    # Calculate mean for significant trials\n",
    "    con_trial_cleaned['m_sig'] = np.nan\n",
    "    con_trial_cleaned.loc[con_trial_cleaned.Sig == 1, 'm_sig'] = con_trial_cleaned.loc[\n",
    "        con_trial_cleaned.Sig == 1, metric]\n",
    "    con_trial_cleaned['Prob'] = con_trial_cleaned.Sig\n",
    "\n",
    "    # Create a pivot table\n",
    "    con_pivot = con_trial_cleaned.pivot_table(index=['Stim', 'Chan'], columns=condition, values=['m_sig', 'Prob'],\n",
    "                                              aggfunc='mean')\n",
    "\n",
    "    # Fill missing values with global mean\n",
    "    con_pivot_filled = con_pivot.fillna(con_trial_cleaned['m_sig'].mean())\n",
    "\n",
    "    V = con_pivot_filled['m_sig'].values\n",
    "\n",
    "    # Calculate the Pearson correlation matrix\n",
    "    correlation_matrix = np.corrcoef(V, rowvar=False)\n",
    "\n",
    "    return correlation_matrix, np.unique(con_trial_cleaned[condition])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f6a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a595033",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mp, _ = cal_correlation_condition(con_trial, metric='LL', condition='Block')\n",
    "label = np.unique(con_trial.Block)\n",
    "M = pd.read_csv(os.path.join(exp_dir2, 'k=' + str(k), 'consensus_matrix.csv'), header=None).values\n",
    "hypnogram = np.zeros((len(label),))\n",
    "for ix, l in enumerate(label):\n",
    "    hypnogram[ix] = np.bincount(con_trial.loc[con_trial.Block == l, 'Sleep']).argmax()\n",
    "x_ax = np.arange(len(label))\n",
    "\n",
    "# Create figure and subplots using gridspec\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "gs = GridSpec(2, 2, width_ratios=[5, 0.5], height_ratios=[1, 5], wspace=0.2, hspace=0.2)\n",
    "\n",
    "# Subplot for the correlation matrix\n",
    "ax = plt.subplot(gs[1, 0])\n",
    "# ax.set_aspect('equal')\n",
    "ax_h = plt.subplot(gs[0, 0], sharex=ax)\n",
    "ax_cbar = plt.subplot(gs[1, 1])\n",
    "\n",
    "ax_h.plot(x_ax, hypnogram, c='black', linewidth=2)\n",
    "ax_h.axhspan(-1, 0.2, color=color_elab[0, :])  # Using color map for color\n",
    "ax_h.fill_between(x_ax, hypnogram, -1, color=color_elab[0, :])  # Using color map for color\n",
    "ax_h.set_yticks([0, 1, 2, 3, 4])\n",
    "ax_h.set_yticklabels(['Wake', 'N1', 'N2', 'N3', 'REM'])\n",
    "ax_h.set_ylim([-1, 5])\n",
    "ax_h.invert_yaxis()\n",
    "ax_h.set_xticks([])\n",
    "ax_h.set_ylabel('Score', fontsize=10)\n",
    "ax_h.set_xlim(x_ax[0], x_ax[-1])\n",
    "\n",
    "# Plot Pearson correlation matrix (M)\n",
    "im = ax.pcolormesh(M, cmap='pink', vmin=np.percentile(M, 10), vmax=np.percentile(M, 90))\n",
    "ax.set_ylabel('Block Number', fontsize=10)\n",
    "ax.set_xlabel('Block Number', fontsize=10)\n",
    "ax.set_xlim(x_ax[0], x_ax[-1])\n",
    "\n",
    "# Add a colorbar to the last subplot\n",
    "cbar = fig.colorbar(im, cax=ax_cbar)\n",
    "cbar.ax.set_ylabel('Probability of shared membership (100 runs)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(path_file, 'Block_consensus_hypnogram.jpg'), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa939c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp_chans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e148542",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f2a2b",
   "metadata": {},
   "source": [
    "## OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_gen = os.path.join(path_gen_base, subj)\n",
    "\n",
    "if not os.path.exists(path_gen):\n",
    "    path_gen = os.path.join('T:', 'EL_experiment', 'Patients', subj)\n",
    "\n",
    "path_patient = os.path.join(path_gen, 'Data', 'EL_experiment')\n",
    "path_infos = os.path.join(path_gen, 'Electrodes')\n",
    "# labels\n",
    "lbls = pd.read_excel(os.path.join(path_infos, subj + \"_labels.xlsx\"), header=0, sheet_name='BP')\n",
    "if type in lbls:\n",
    "    lbls = lbls[lbls.type=='SEEG']\n",
    "    lbls = lbls.reset_index(drop=True)\n",
    "\n",
    "# cluster information\n",
    "file_con_cluster = os.path.join('X:', '4 e-Lab', 'EvM', 'Projects', 'EL_experiment', 'Analysis', 'Patients', 'Data_Cluster', 'BM_CR', 'NMF_output', subj + '_con_trial_cluster.csv')\n",
    "con_trial_cluster = pd.read_csv(file_con_cluster)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b76b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_con_summary = os.path.join(path_patient_analysis, folder, cond_folder, 'data', 'summ_general.csv')\n",
    "con_summary = pd.read_csv(file_con_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial_cluster['SleepState'] = 'Wake'\n",
    "con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 0) | (con_trial_cluster['SleepState'] == 'W'), 'SleepState'] = 'Wake'\n",
    "con_trial_cluster.loc[(con_trial_cluster['Sleep'] > 1) & (con_trial_cluster['Sleep'] < 4), 'SleepState'] = 'NREM'\n",
    "con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 1), 'SleepState'] = 'NREM1'\n",
    "con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 6), 'SleepState'] = 'SZ'\n",
    "con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 4), 'SleepState'] = 'REM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_sig = con_summary[con_summary['Sig'] > 0].reset_index(drop=True)\n",
    "con_sig['P'] = con_sig['Sig']\n",
    "for c in range(len(lbls)):\n",
    "    con_sig.loc[(con_sig.Stim ==c), \"StimA\"]   = lbls.Area.values[c]\n",
    "    con_sig.loc[(con_sig.Chan ==c), \"ChanA\"]   = lbls.Area.values[c]\n",
    "\n",
    "con_sig = con_sig.merge(con_trial_cluster[['Chan', 'Stim', 'Cluster']], on=['Chan', 'Stim'], how='left').drop_duplicates().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_sig[(con_sig.Stim==19)&(con_sig.Chan==65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_sig = get_sleep_effect(con_trial_cluster, con_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_list = ['EL010', 'EL011', 'EL012', 'EL013', 'EL015', 'EL014', 'EL016', 'EL017', \"EL019\", \"EL020\", \"EL021\", \"EL022\", \"EL025\"]\n",
    "path_gen_base = sub_path + '\\Patients'\n",
    "\n",
    "con_sig_across = None\n",
    "\n",
    "for subj in subject_list:\n",
    "    print(subj)\n",
    "    path_patient_analysis = os.path.join(sub_path, 'EvM', 'Projects', 'EL_experiment', 'Analysis', 'Patients', subj)\n",
    "    path_gen = os.path.join(path_gen_base, subj)\n",
    "\n",
    "    if not os.path.exists(path_gen):\n",
    "        path_gen = os.path.join('T:', 'EL_experiment', 'Patients', subj)\n",
    "\n",
    "    path_patient = os.path.join(path_gen, 'Data', 'EL_experiment')\n",
    "    path_infos = os.path.join(path_gen, 'Electrodes')\n",
    "    # labels\n",
    "    lbls = pd.read_excel(os.path.join(path_infos, subj + \"_labels.xlsx\"), header=0, sheet_name='BP')\n",
    "    if type in lbls:\n",
    "        lbls = lbls[lbls.type=='SEEG']\n",
    "        lbls = lbls.reset_index(drop=True)\n",
    "    \n",
    "    # cluster information (trial)\n",
    "    file_con_cluster = os.path.join('X:', '4 e-Lab', 'EvM', 'Projects', 'EL_experiment', 'Analysis', 'Patients', 'Data_Cluster', 'BM_CR', 'NMF_output', subj + '_con_trial_cluster.csv')\n",
    "    con_trial_cluster = pd.read_csv(file_con_cluster)\n",
    "    con_trial_cluster['SleepState'] = 'Wake'\n",
    "    con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 0) | (con_trial_cluster['SleepState'] == 'W'), 'SleepState'] = 'Wake'\n",
    "    con_trial_cluster.loc[(con_trial_cluster['Sleep'] > 1) & (con_trial_cluster['Sleep'] < 4), 'SleepState'] = 'NREM'\n",
    "    con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 1), 'SleepState'] = 'NREM1'\n",
    "    con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 6), 'SleepState'] = 'SZ'\n",
    "    con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 4), 'SleepState'] = 'REM'\n",
    "\n",
    "    # load connection summary and add cluster information \n",
    "    file_con_summary = os.path.join(path_patient_analysis, folder, cond_folder, 'data', 'summ_general.csv')\n",
    "    con_summary = pd.read_csv(file_con_summary)\n",
    "\n",
    "    con_sig = con_summary[con_summary['Sig'] > 0].reset_index(drop=True)\n",
    "    con_sig['P'] = con_sig['Sig']\n",
    "    for c in range(len(lbls)):\n",
    "        con_sig.loc[(con_sig.Stim ==c), \"StimA\"]   = lbls.Area.values[c].replace(\" \", \"\")\n",
    "        con_sig.loc[(con_sig.Chan ==c), \"ChanA\"]   = lbls.Area.values[c].replace(\" \", \"\")\n",
    "    \n",
    "    con_sig = con_sig.merge(con_trial_cluster[['Chan', 'Stim', 'Cluster']], on=['Chan', 'Stim'], how='left').drop_duplicates().reset_index(drop=True)\n",
    "    # add sleep effect\n",
    "    con_sig = get_sleep_effect(con_trial_cluster, con_sig)\n",
    "    con_sig.insert(0, 'Subj', subj)\n",
    "\n",
    "    if con_sig_across is None:\n",
    "        con_sig_across = con_sig\n",
    "    else:\n",
    "        con_sig_across = pd.concat([con_sig_across, con_sig], axis=0)\n",
    "        \n",
    "con_sig_across = con_sig_across.reset_index(drop=True)\n",
    "con_sig_across.insert(5, 'H',0)\n",
    "con_sig_across = con_sig_across[con_sig_across['ChanA']!='U']\n",
    "con_sig_across = con_sig_across[con_sig_across['StimA']!='U']\n",
    "con_sig_across = con_sig_across.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'})\n",
    "sns.catplot(x='Cluster', y='LL_norm', hue='SleepState', data = con_trial_cluster[con_trial_cluster.Sleep!=1], kind = 'box', hue_order = label_sleep, palette = color_sleep)\n",
    "plt.ylim([0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "subj = subject_list[k]\n",
    "print(subj)\n",
    "path_patient_analysis = os.path.join(sub_path, 'EvM', 'Projects', 'EL_experiment', 'Analysis', 'Patients', subj)\n",
    "path_gen = os.path.join(path_gen_base, subj)\n",
    "\n",
    "if not os.path.exists(path_gen):\n",
    "    path_gen = os.path.join('T:', 'EL_experiment', 'Patients', subj)\n",
    "\n",
    "path_patient = os.path.join(path_gen, 'Data', 'EL_experiment')\n",
    "path_infos = os.path.join(path_gen, 'Electrodes')\n",
    "# labels\n",
    "lbls = pd.read_excel(os.path.join(path_infos, subj + \"_labels.xlsx\"), header=0, sheet_name='BP')\n",
    "if type in lbls:\n",
    "    lbls = lbls[lbls.type=='SEEG']\n",
    "    lbls = lbls.reset_index(drop=True)\n",
    "\n",
    "# cluster information (trial)\n",
    "file_con_cluster = os.path.join('X:', '4 e-Lab', 'EvM', 'Projects', 'EL_experiment', 'Analysis', 'Patients', 'Data_Cluster', 'BM_CR', 'NMF_output', subj + '_con_trial_cluster.csv')\n",
    "con_trial_cluster = pd.read_csv(file_con_cluster)\n",
    "con_trial_cluster['SleepState'] = 'Wake'\n",
    "con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 0) | (con_trial_cluster['SleepState'] == 'W'), 'SleepState'] = 'Wake'\n",
    "con_trial_cluster.loc[(con_trial_cluster['Sleep'] > 1) & (con_trial_cluster['Sleep'] < 4), 'SleepState'] = 'NREM'\n",
    "con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 1), 'SleepState'] = 'NREM1'\n",
    "con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 6), 'SleepState'] = 'SZ'\n",
    "con_trial_cluster.loc[(con_trial_cluster['Sleep'] == 4), 'SleepState'] = 'REM'\n",
    "\n",
    "# load connection summary and add cluster information \n",
    "file_con_summary = os.path.join(path_patient_analysis, folder, cond_folder, 'data', 'summ_general.csv')\n",
    "con_summary = pd.read_csv(file_con_summary)\n",
    "\n",
    "con_sig = con_summary[con_summary['Sig'] > 0].reset_index(drop=True)\n",
    "con_sig['P'] = con_sig['Sig']\n",
    "for c in range(len(lbls)):\n",
    "    con_sig.loc[(con_sig.Stim ==c), \"StimA\"]   = lbls.Area.values[c].replace(\" \", \"\")\n",
    "    con_sig.loc[(con_sig.Chan ==c), \"ChanA\"]   = lbls.Area.values[c].replace(\" \", \"\")\n",
    "\n",
    "con_sig = con_sig.merge(con_trial_cluster[['Chan', 'Stim', 'Cluster']], on=['Chan', 'Stim'], how='left').drop_duplicates().reset_index(drop=True)\n",
    "# add sleep effect\n",
    "con_sig = get_sleep_effect(con_trial_cluster, con_sig)\n",
    "con_sig.insert(0, 'Subj', subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Cluster', hue='Dist',data = con_sig, palette=color_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'})\n",
    "sns.catplot(x='Cluster', y='LL_norm', hue='SleepState', data = con_trial_cluster[con_trial_cluster.Sleep!=1], kind = 'box', hue_order = label_sleep, palette = color_sleep)\n",
    "plt.ylim([0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_sleep = ['#808080', '#145da0', '#ff1919']\n",
    "label_sleep = ['Wake', 'NREM', 'REM']\n",
    "color_dist = ['#0000FF','#0076C4','#00DD91']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_sig_across[(con_sig_across.Subj =='EL011')&(con_sig_across.Stim ==19)&(con_sig_across.Chan==65)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_NREM_in = con_sig_across[con_sig_across.NREM_Effect==1]\n",
    "con_NREM_in = con_NREM_in.reset_index(drop=True)\n",
    "\n",
    "con_NREM_de = con_sig_across[con_sig_across.NREM_Effect==-1]\n",
    "con_NREM_de = con_NREM_de.reset_index(drop=True)\n",
    "con_NREM_de.to_csv('X:\\\\4 e-Lab\\\\EvM\\\\Projects\\\\EL_experiment\\\\Analysis\\\\Patients\\\\Data_Cluster\\\\BM_CR\\\\NMF_output\\\\NREM_de.csv', header =True, index =False)\n",
    "con_NREM_in.to_csv('X:\\\\4 e-Lab\\\\EvM\\\\Projects\\\\EL_experiment\\\\Analysis\\\\Patients\\\\Data_Cluster\\\\BM_CR\\\\NMF_output\\\\NREM_in.csv', header =True, index =False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-cooling",
   "metadata": {},
   "source": [
    "## RAw to Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = 'EL011'\n",
    "path_patient_analysis = sub_path+'\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\\\' + subj\n",
    "path_gen = os.path.join(sub_path+'\\Patients\\\\' + subj)\n",
    "if not os.path.exists(path_gen):\n",
    "    path_gen = 'T:\\\\EL_experiment\\\\Patients\\\\' + subj\n",
    "path_patient = path_gen + '\\Data\\EL_experiment'  # os.path.dirname(os.path.dirname(cwd))+'/Patients/'+subj\n",
    "path_infos = os.path.join(path_gen, 'Electrodes')\n",
    "# labels\n",
    "files_list = glob(path_patient_analysis + '\\\\' + folder + '/data/Stim_list_*')\n",
    "i = 0\n",
    "stimlist = pd.read_csv(files_list[i])\n",
    "lbls = pd.read_excel(os.path.join(path_infos, subj + \"_labels.xlsx\"), header=0, sheet_name='BP')\n",
    "if type in lbls:\n",
    "    lbls = lbls[lbls.type=='SEEG']\n",
    "    lbls = lbls.reset_index(drop=True)\n",
    "labels_all, labels_region, labels_clinic, coord_all, StimChans, StimChanSM, StimChansC, StimChanIx, stimlist = bf.get_Stim_chans(\n",
    "    stimlist,\n",
    "    lbls)\n",
    "\n",
    "\n",
    "# trials\n",
    "file_con = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "con_trial = pd.read_csv(file_con)\n",
    "# summary\n",
    "file_con = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/summ_general.csv'\n",
    "con_summary = pd.read_csv(file_con) \n",
    "# only signifact connections\n",
    "con_sig = con_summary[con_summary.Sig >0]\n",
    "con_sig = con_sig.reset_index(drop=True)\n",
    "con_sig.insert(4, 'P', con_sig.Sig)\n",
    "con_trial_sig = con_trial.merge(con_sig[['Stim', 'Chan', 'P']], on =['Stim', 'Chan'])\n",
    "\n",
    "\n",
    "con_trial_sig = con_trial_sig.drop(columns=['P2P', 'LL_WOI', 'Hour', 'Num_block', 'Date'])\n",
    "con_trial_sig = con_trial_sig[con_trial_sig.Artefact<2]\n",
    "con_trial_sig.reset_index(drop=True)\n",
    "# con_trial_sig.to_csv('X:\\\\4 e-Lab\\\\EvM\\\\Projects\\\\EL_experiment\\\\Analysis\\\\Patients\\\\Data_Cluster\\\\BM_CR\\\\'+subj+'_con_trial.csv', header =True, index =False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pivot(con_trial):\n",
    "    con_trial = con_trial[(con_trial.Sig >-1)&(con_trial.Artefact < 2)]\n",
    "    con_trial = con_trial.reset_index(drop=True)\n",
    "    ## 1. Add unique connection label for each StimxChan combination: Con_ID\n",
    "    con_trial['Con_ID'] = con_trial.groupby(['Stim', 'Chan']).ngroup()\n",
    "    con_trial.insert(5, 'LL_sig', con_trial.LL *con_trial.Sig)\n",
    "    ## normalize LL based on the mean of LL_pre per Chan\n",
    "    con_trial['LL_norm'] = con_trial.groupby('Chan').apply(lambda x: x['LL_sig'] / x['LL_pre'].mean()).reset_index(0, drop=True)\n",
    "    ## fill nan with mean of specifc Con_ID\n",
    "    con_trial['LL_norm'].fillna(con_trial.groupby('Con_ID')['LL_norm'].transform('mean'), inplace=True)\n",
    "    con_trial_block  = con_trial.groupby(['Con_ID','Stim', 'Chan', 'Block'])['LL_norm'].mean().reset_index()\n",
    "    df_pivot = con_trial_block.pivot(index='Con_ID', columns='Block', values='LL_norm')\n",
    "    # If there are still missing values after pivot, you might want to fill them with the global mean\n",
    "    df_pivot.fillna(con_trial['LL_norm'].mean(), inplace=True)\n",
    "    return df_pivot, con_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-employee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot, con_trial_sig2 = get_pivot(con_trial_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nnmf(X, rank, init='nndsvda',it=2000):\n",
    "    from sklearn.decomposition import NMF\n",
    "    \"\"\"Non-negative matrix factorization, remove zero rows before computation.\"\"\"\n",
    "    W = np.zeros((X.shape[0], rank))\n",
    "    zero_rows = np.where(X.mean(axis=1) == 0)[0]\n",
    "    nonzero_rows = np.where(X.mean(axis=1) > 0)[0]\n",
    "    X0 = np.delete(X, zero_rows, 0)\n",
    "\n",
    "    model = NMF(n_components=rank, init=init, max_iter=it)\n",
    "    W0 = model.fit_transform(X0)\n",
    "    H = model.components_\n",
    "    W[nonzero_rows, :] = W0\n",
    "\n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = df_pivot.values\n",
    "k = 3\n",
    "W, H = get_nnmf(V, rank=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = np.argmax(W, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-century",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial_sig2['Cluster'] = con_trial_sig2['Con_ID'].map(cluster_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-update",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial_sig2[con_trial_sig2.Con_ID==499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters[499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-falls",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {i: cluster for i, cluster in enumerate(clusters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-prison",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in ['EL010', 'EL011', 'EL012', 'EL013', 'EL015', 'EL014','EL016', 'EL017', \"EL019\",\"EL020\", \"EL021\", \"EL022\", \"EL025\"]:\n",
    "    print(subj)\n",
    "    path_patient_analysis = sub_path+'\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\\\' + subj\n",
    "    path_gen = os.path.join(sub_path+'\\Patients\\\\' + subj)\n",
    "    if not os.path.exists(path_gen):\n",
    "        path_gen = 'T:\\\\EL_experiment\\\\Patients\\\\' + subj\n",
    "    path_patient = path_gen + '\\Data\\EL_experiment'  # os.path.dirname(os.path.dirname(cwd))+'/Patients/'+subj\n",
    "    path_infos = os.path.join(path_gen, 'Electrodes')\n",
    "    # labels\n",
    "    files_list = glob(path_patient_analysis + '\\\\' + folder + '/data/Stim_list_*')\n",
    "    i = 0\n",
    "    stimlist = pd.read_csv(files_list[i])\n",
    "    lbls = pd.read_excel(os.path.join(path_infos, subj + \"_labels.xlsx\"), header=0, sheet_name='BP')\n",
    "    if type in lbls:\n",
    "        lbls = lbls[lbls.type=='SEEG']\n",
    "        lbls = lbls.reset_index(drop=True)\n",
    "    labels_all, labels_region, labels_clinic, coord_all, StimChans, StimChanSM, StimChansC, StimChanIx, stimlist = bf.get_Stim_chans(\n",
    "        stimlist,\n",
    "        lbls)\n",
    "    \n",
    "    \n",
    "    # trials\n",
    "    file_con = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "    con_trial = pd.read_csv(file_con)\n",
    "    # summary\n",
    "    file_con = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/summ_general.csv'\n",
    "    con_summary = pd.read_csv(file_con) \n",
    "    # only signifact connections\n",
    "    con_sig = con_summary[con_summary.Sig >0]\n",
    "    con_sig = con_sig.reset_index(drop=True)\n",
    "    con_sig.insert(4, 'P', con_sig.Sig)\n",
    "    con_trial_sig = con_trial.merge(con_sig[['Stim', 'Chan', 'P']], on =['Stim', 'Chan'])\n",
    "\n",
    "    \n",
    "    con_trial_sig = con_trial_sig.drop(columns=['P2P', 'LL_WOI', 'Hour', 'Num_block', 'Date'])\n",
    "    con_trial_sig = con_trial_sig[con_trial_sig.Artefact<2]\n",
    "    con_trial_sig.reset_index(drop=True)\n",
    "    con_trial_sig.to_csv('X:\\\\4 e-Lab\\\\EvM\\\\Projects\\\\EL_experiment\\\\Analysis\\\\Patients\\\\Data_Cluster\\\\BM_CR\\\\'+subj+'_con_trial.csv', header =True, index =False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_con = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "con_trial = pd.read_csv(file_con) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'SleepState' in con_trial:\n",
    "    con_trial.insert(6, 'SleepState', 'Wake')\n",
    "con_trial.loc[(con_trial.SleepState == 'W'), 'SleepState'] = 'Wake'\n",
    "con_trial.loc[(con_trial.Sleep == 0), 'SleepState'] = 'Wake'\n",
    "con_trial.loc[(con_trial.Sleep > 1) & (con_trial.Sleep < 4), 'SleepState'] = 'NREM'\n",
    "con_trial.loc[(con_trial.Sleep == 1), 'SleepState'] = 'NREM1'\n",
    "con_trial.loc[(con_trial.Sleep == 6), 'SleepState'] = 'SZ'\n",
    "con_trial.loc[(con_trial.Sleep == 4), 'SleepState'] = 'REM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-compatibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-chassis",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 0\n",
    "data_cluster = con_trial.loc[con_trial['Cluster'] == cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-monitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Cluster', y = 'LL_norm', hue='SleepState', data=con_trial, kind='box')\n",
    "plt.ylim([0,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distributions of LL_onset_norm between Wake and NREM\n",
    "nrem = compare_distributions(data_cluster[data_cluster.SleepState == 'Wake']['LL_norm'].values, data_cluster[data_cluster.SleepState == 'NREM']['LL_norm'].values)\n",
    "# Compare distributions of LL_onset_norm between Wake and REM\n",
    "rem = compare_distributions(data_cluster[data_cluster.SleepState == 'Wake']['LL_norm'].values, data_cluster[data_cluster.SleepState == 'REM']['LL_norm'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get unique clusters\n",
    "clusters = con_trial['Cluster'].unique()\n",
    "\n",
    "# Iterate over clusters\n",
    "for cluster in clusters:\n",
    "    # Get unique Stim and Chan combinations for the current cluster\n",
    "    data_cluster = con_trial.loc[con_trial['Cluster'] == cluster]\n",
    "\n",
    "    # Compare distributions of LL_onset_norm between Wake and NREM\n",
    "    nrem = compare_distributions(data_cluster[data_cluster.SleepState == 'Wake']['LL_onset_norm'].values, data_cluster[data_cluster.SleepState == 'NREM']['LL_onset_norm'].values)\n",
    "    # Compare distributions of LL_onset_norm between Wake and REM\n",
    "    rem = compare_distributions(data_cluster[data_cluster.SleepState == 'Wake']['LL_onset_norm'].values, data_cluster[data_cluster.SleepState == 'REM']['LL_onset_norm'].values)\n",
    "\n",
    "    group_df.loc[group_df['Cluster'] == cluster, 'NREM_Effect'] = nrem\n",
    "    group_df.loc[group_df['Cluster'] == cluster, 'REM_Effect'] = rem\n",
    "\n",
    "group_df.to_csv(os.path.join(output_folder, 'summary_'+filename), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial = pd.read_csv(file_con) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-running",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in [\"EL025\"]:\n",
    "    path_patient_analysis = sub_path+'\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\\\' + subj\n",
    "    path_gen = os.path.join(sub_path+'\\Patients\\\\' + subj)\n",
    "    if not os.path.exists(path_gen):\n",
    "        path_gen = 'T:\\\\EL_experiment\\\\Patients\\\\' + subj\n",
    "    path_patient = path_gen + '\\Data\\EL_experiment'  # os.path.dirname(os.path.dirname(cwd))+'/Patients/'+subj\n",
    "    path_infos = os.path.join(path_gen, 'Electrodes')\n",
    "    file_con_all = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "    file_con = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "    con_trial = pd.read_csv(file_con)\n",
    "    con_trial = con_trial.drop(columns=['P2P', 'LL_WOI', 'Hour', 'Sleep', 'Num_block', 'Date'])\n",
    "    con_trial = con_trial[con_trial.Artefact<2]\n",
    "    con_trial.reset_index(drop=True)\n",
    "    con_trial.to_csv('X:\\\\4 e-Lab\\\\EvM\\\\Projects\\\\EL_experiment\\\\Analysis\\\\Patients\\\\Data_Cluster\\\\BM_CR\\\\'+subj+'_con_trial.csv', header =True, index =False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-reserve",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in ['EL010', 'EL011', 'EL012', 'EL013', 'EL015', 'EL014','EL016', 'EL017', \"EL019\",\"EL020\", \"EL021\", \"EL022\"]:\n",
    "    path_patient_analysis = sub_path+'\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\\\' + subj\n",
    "    path_gen = os.path.join(sub_path+'\\Patients\\\\' + subj)\n",
    "    if not os.path.exists(path_gen):\n",
    "        path_gen = 'T:\\\\EL_experiment\\\\Patients\\\\' + subj\n",
    "    path_patient = path_gen + '\\Data\\EL_experiment'  # os.path.dirname(os.path.dirname(cwd))+'/Patients/'+subj\n",
    "    path_infos = os.path.join(path_gen, 'Electrodes')\n",
    "    file_con_all = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "    file_con = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "    con_trial = pd.read_csv(file_con)\n",
    "    con_trial = con_trial.drop(columns=['P2P', 'LL_WOI', 'Hour', 'Sleep', 'Num_block', 'Date'])\n",
    "    con_trial = con_trial[con_trial.Artefact<2]\n",
    "    con_trial.reset_index(drop=True)\n",
    "    con_trial.to_csv('X:\\\\4 e-Lab\\\\EvM\\\\Projects\\\\EL_experiment\\\\Analysis\\\\Patients\\\\Data_Cluster\\\\BM_CR\\\\'+subj+'_con_trial.csv', header =True, index =False)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con_trial[(con_trial.Sig>-1)&(con_trial.Artefact<2)]\n",
    "v = df.drop(columns=['P2P', 'LL_WOI', 'Num_block', 'Artefact', 'Date'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming df is your DataFrame\n",
    "df['LL_onset_norm'] = df.groupby('Chan').apply(lambda x: x['LL_onset'] / x['LL_pre'].mean()).reset_index(0, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chan = int(np.max(df.Stim)+1)\n",
    "n_blocks = int(np.max(df.Block)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean LL_onset_norm for each block\n",
    "df_grouped = df.groupby(['Chan', 'Stim', 'Block'])['LL_onset_norm'].mean().reset_index()\n",
    "\n",
    "M = np.full((n_chan, n_chan, n_blocks), np.nan)\n",
    "\n",
    "for _, row in df_grouped.iterrows():\n",
    "    M[row['Chan'].astype('int'), row['Stim'].astype('int'), row['Block'].astype('int')] = row['LL_onset_norm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing NaN with the connection mean\n",
    "V = M.reshape(-1, n_blocks)\n",
    "\n",
    "nan_mask = np.isnan(V)\n",
    "column_means = np.nanmean(V, axis=0)\n",
    "row_means = np.nanmean(V, axis=1)\n",
    "V[nan_mask] = np.take(row_means, np.nonzero(nan_mask)[0])\n",
    "\n",
    "nan_mask = np.isnan(V)\n",
    "V[nan_mask] = np.nanpercentile(V,90)\n",
    "V = V[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "n_clusters = 30  # Set the number of clusters as per your requirement\n",
    "model = NMF(n_clusters)\n",
    "\n",
    "# Normalize data before applying NMF for stability\n",
    "V_norm = normalize(V, axis=1)\n",
    "W = model.fit_transform(V_norm)\n",
    "H = model.components_\n",
    "\n",
    "# Assigning the clusters to each connection\n",
    "clusters = np.argmax(W, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vector = pd.DataFrame(V, columns=[f'block_{i}' for i in range(1, n_blocks)])\n",
    "df_vector['cluster'] = clusters\n",
    "\n",
    "\n",
    "# Merging the cluster information back to the original dataframe\n",
    "df['connection_id'] = df['Chan'] * n_chan + df['Stim']  # unique id for each connection\n",
    "# Create a dictionary with connection_id as keys and cluster as values\n",
    "cluster_dict = {i: cluster for i, cluster in enumerate(clusters)}\n",
    "\n",
    "# Add the 'Cluster' column to the DataFrame\n",
    "df['Cluster'] = df['connection_id'].map(cluster_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = 16\n",
    "df_cluster = df[df['Cluster'] == cluster]\n",
    "plt.figure(figsize=(8, 3))\n",
    "sns.scatterplot(x='d', y='LL_onset', hue = 'SleepState', data=df_cluster)\n",
    "plt.title(f'Cluster {cluster}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for cluster in df['Cluster'].unique():\n",
    "    df_cluster = df[df['Cluster'] == cluster]\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    sns.boxplot(x='SleepState', y='LL_onset_norm', data=df_cluster)\n",
    "    plt.title(f'Cluster {cluster}')\n",
    "    plt.ylim([0,5])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if not 'SleepState' in con_trial:\n",
    "    con_trial.insert(6, 'SleepState', 'Wake')\n",
    "con_trial.loc[(con_trial.SleepState == 'W'), 'SleepState'] = 'Wake'\n",
    "con_trial.loc[(con_trial.Sleep == 0), 'SleepState'] = 'Wake'\n",
    "con_trial.loc[(con_trial.Sleep > 1) & (con_trial.Sleep < 4), 'SleepState'] = 'NREM'\n",
    "con_trial.loc[(con_trial.Sleep == 1), 'SleepState'] = 'NREM1'\n",
    "con_trial.loc[(con_trial.Sleep == 6), 'SleepState'] = 'SZ'\n",
    "con_trial.loc[(con_trial.Sleep == 4), 'SleepState'] = 'REM'\n",
    "# Input data\n",
    "if not \"LL_sig\"in con_trial:\n",
    "    con_trial.insert(6, 'LL_sig', con_trial.LL_WOI*con_trial.Sig)\n",
    "M_times = []\n",
    "M_SleepState = []\n",
    "i = 0\n",
    "for b in np.unique(con_trial.Block):\n",
    "    for ss_ix, ss in enumerate(['Wake', 'NREM', 'REM']):\n",
    "        summ = con_trial[(con_trial.Sig>-1)&(con_trial.Block==b)&(con_trial.SleepState==ss)]\n",
    "        if len(np.unique(summ.Stim))>0:\n",
    "            summ = summ.groupby(['Stim', 'Chan'], as_index=False)['LL_sig'].mean()#summ[summ.Sig_block>3]\n",
    "            t = np.bincount(con_trial.loc[con_trial.Block==b, 'Hour']).argmax()\n",
    "            M = np.zeros((len(labels_all),len(labels_all)))\n",
    "            M[:,:] = np.nan\n",
    "            for sc in np.unique(summ.Stim).astype('int'):\n",
    "                chan =summ.loc[summ.Stim==sc, 'Chan'].values.astype('int')\n",
    "                LL =summ.loc[summ.Stim==sc, 'LL_sig'].values\n",
    "                M[sc,chan] = LL\n",
    "            M       = np.delete(np.delete(M, bad_all, 0), bad_all, 1)\n",
    "\n",
    "\n",
    "            if i==0:\n",
    "                M_all = M\n",
    "                i = 1\n",
    "                arr_sleepstate = np.array([ss_ix])\n",
    "            elif i==1:\n",
    "                M_all = np.stack([M_all, M],0)\n",
    "                i = 2\n",
    "                arr_sleepstate = np.concatenate([arr_sleepstate,np.array([ss_ix])])\n",
    "            else:\n",
    "                M_all = np.concatenate([M_all,np.expand_dims(M,0)],0)\n",
    "                arr_sleepstate =  np.concatenate([arr_sleepstate,np.array([ss_ix])])\n",
    "            M_times.append(str(t).zfill(2)+':00')\n",
    "            M_SleepState.append(ss)\n",
    "\n",
    "# Normalize \n",
    "V = M_all.reshape(len(M_all), -1)\n",
    "V = V.T\n",
    "mu = np.nanmean(V,1)\n",
    "sigma = np.nanstd(V,1)\n",
    "\n",
    "V = np.delete(V,np.where(np.isnan(mu) |( mu==0)) [0], 0)\n",
    "mu = np.nanmean(V,1)\n",
    "sigma = np.nanstd(V,1)\n",
    "\n",
    "k = 0\n",
    "for i in np.unique(np.where(np.isnan(V))[0]):\n",
    "    n_nan = len(np.where(np.isnan(V[i,:])==1)[0])\n",
    "    # find better way to impute nan data\n",
    "    if n_nan < V.shape[1]:\n",
    "        V[i,np.isnan(V[i,:])] = np.random.normal(mu[i], sigma[i]/1000, (n_nan,))\n",
    "        k +=1\n",
    "####NMF\n",
    "Vn = V / np.percentile(V,95,1)[:,None]\n",
    "Vn[Vn>1] = 1\n",
    "rk = 3\n",
    "W, W0, H = NMFf.get_nnmf_Epi(Vn, rk, it=2000) \n",
    "\n",
    "## KMEANS\n",
    "kmeans = KMeans(n_clusters=3).fit(Vn)\n",
    "CC = kmeans.cluster_centers_\n",
    "##Plots\n",
    "Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF').mkdir(parents=True, exist_ok=True)\n",
    "Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(3, 10))\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.pcolormesh(np.expand_dims(kmeans.labels_,1), cmap='seismic')\n",
    "plt.ylabel('Conenction Number', fontsize=20)\n",
    "plt.title(subj+' -- KMEANS cluster assignment')\n",
    "plt.xticks([])\n",
    "plt.savefig(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures\\\\kmeans_labels.jpg')\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.suptitle(subj+' -- KMEANS CC', fontsize=25)\n",
    "gs       = fig.add_gridspec(rk+1,1)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "plt.plot(arr_sleepstate, c=color_elab[0,:], linewidth=2)\n",
    "plt.plot(arr_sleepstate, 'o', c=color_elab[0,:], )\n",
    "plt.yticks([0,1,2], ['Wake','NREM','REM'], fontsize=25)\n",
    "plt.ylim([-1,4])\n",
    "plt.gca().invert_yaxis()\n",
    "## hypnogram\n",
    "for i in range(rk):\n",
    "    ax = fig.add_subplot(gs[i+1, 0])\n",
    "    ax.plot(CC[i], c=color_elab[2,:], linewidth=2)\n",
    "    ax.plot(CC[i], 'o', c=color_elab[2,:])\n",
    "    # ax.set_ylim([0.10,1])\n",
    "    plt.ylabel('CC'+str(i+1), fontsize=25)\n",
    "plt.xlabel('Block x sleep state unique number', fontsize=20)\n",
    "plt.savefig(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures\\\\kmeans_activation.jpg')\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(5, 10))\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.pcolormesh(W, cmap ='Reds')\n",
    "plt.ylabel('Conenction Number', fontsize=20)\n",
    "plt.title(subj+' -- NMF Basis function')\n",
    "plt.xticks(np.arange(3)+0.5, ['W1', 'W2', 'W3'])\n",
    "plt.savefig(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures\\\\NMF_labels.jpg')\n",
    "plt.close()\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.pcolormesh(Vn, cmap = 'hot', vmin= 0.1, vmax= 0.9)\n",
    "plt.ylabel('Conenction Number', fontsize=20)\n",
    "plt.title(subj+' -- Input (mean LL per connection ane block/sleep state)', fontsize=20)\n",
    "plt.savefig(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures\\\\V_input_normalized.jpg')\n",
    "plt.close()\n",
    "\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.suptitle(subj+' -- NMF H function', fontsize=25)\n",
    "gs       = fig.add_gridspec(rk+1,1)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "plt.plot(arr_sleepstate, c=color_elab[0,:], linewidth=2)\n",
    "plt.plot(arr_sleepstate, 'o', c=color_elab[0,:], )\n",
    "plt.yticks([0,1,2], ['Wake','NREM','REM'], fontsize=25)\n",
    "plt.ylim([-1,4])\n",
    "plt.gca().invert_yaxis()\n",
    "## hypnogram\n",
    "for i in range(rk):\n",
    "    ax = fig.add_subplot(gs[i+1, 0])\n",
    "    ax.plot(H[i], c=color_elab[2,:], linewidth=2)\n",
    "    ax.plot(H[i], 'o', c=color_elab[2,:])\n",
    "    # ax.set_ylim([-0.10,4])\n",
    "    plt.ylabel('H'+str(i+1), fontsize=25)\n",
    "plt.xlabel('Block x sleep state unique number', fontsize=20)\n",
    "plt.savefig(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures\\\\NMF_activation.jpg')\n",
    "plt.close()\n",
    "print(subj+' ---- DONE ----- ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in ['EL010', 'EL011', 'EL012', 'EL013', 'EL015', 'EL014','EL016', 'EL017', \"EL019\",\"EL020\", \"EL021\", \"EL022\"]:\n",
    "\n",
    "\n",
    "\n",
    "    path_patient_analysis = sub_path+'\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\\\' + subj\n",
    "    path_gen = os.path.join(sub_path+'\\Patients\\\\' + subj)\n",
    "    if not os.path.exists(path_gen):\n",
    "        path_gen = 'T:\\\\EL_experiment\\\\Patients\\\\' + subj\n",
    "    path_patient = path_gen + '\\Data\\EL_experiment'  # os.path.dirname(os.path.dirname(cwd))+'/Patients/'+subj\n",
    "    path_infos = os.path.join(path_gen, 'Electrodes')\n",
    "    if not os.path.exists(os.path.join(path_infos, subj + \"_labels.xlsx\")):\n",
    "        path_infos = os.path.join(path_gen, 'infos')\n",
    "    if not os.path.exists(path_infos):\n",
    "        path_infos = path_gen + '\\\\infos'\n",
    "\n",
    "    sep = ';'\n",
    "    Fs = 500\n",
    "    Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data').mkdir(parents=True, exist_ok=True)\n",
    "    Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/BM_plot_trial').mkdir(parents=True, exist_ok=True)\n",
    "    Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/figures/single_con').mkdir(parents=True,\n",
    "                                                                                                  exist_ok=True)\n",
    "    Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/figures/Pipeline').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # get labels\n",
    "    if cond_folder == 'Ph':\n",
    "        files_list = glob(path_patient_analysis + '\\\\' + folder + '/data/Stim_list_*Ph*')\n",
    "    else:\n",
    "        files_list = glob(path_patient_analysis + '\\\\' + folder + '/data/Stim_list_*')\n",
    "    i = 0\n",
    "    stimlist = pd.read_csv(files_list[i])\n",
    "    EEG_resp = np.load(path_patient_analysis + '\\\\' + folder + '/data/ALL_resps_'+files_list[i][-11:-4]+'.npy')\n",
    "\n",
    "    lbls = pd.read_excel(os.path.join(path_infos, subj + \"_labels.xlsx\"), header=0, sheet_name='BP')\n",
    "    if type in lbls:\n",
    "        lbls = lbls[lbls.type=='SEEG']\n",
    "        lbls = lbls.reset_index(drop=True)\n",
    "    labels_all, labels_region, labels_clinic, coord_all, StimChans, StimChanSM, StimChansC, StimChanIx, stimlist = bf.get_Stim_chans(\n",
    "        stimlist,\n",
    "        lbls)\n",
    "\n",
    "    labels_h = lbls.Hemisphere + '_' + labels_all\n",
    "\n",
    "    badchans = pd.read_csv(path_patient_analysis + '\\\\' + folder + '/data/badchan.csv')\n",
    "    bad_chans = np.unique(np.array(np.where(badchans.values[:, 1] == 1))[0, :])\n",
    "\n",
    "    bad_region = np.where((labels_region == 'WM') | (labels_region == 'OUT') | (labels_region == 'Putamen'))[0]\n",
    "\n",
    "    file_con_all = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "    file_con = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "    ######### Load data\n",
    "    data_all = 1\n",
    "    rerun = 0\n",
    "    if os.path.isfile(file_con):\n",
    "        # con_trial\n",
    "        con_trial = pd.read_csv(file_con)\n",
    "    else:\n",
    "        file_con = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_01_CR01.csv'\n",
    "        con_trial = pd.read_csv(file_con)\n",
    "        data_all = 0\n",
    "\n",
    "    non_stim = np.arange(len(labels_all))\n",
    "    non_stim = np.delete(non_stim, np.array(StimChanIx).astype('int'), 0)\n",
    "    bad_all = np.unique(np.concatenate([bad_region, bad_chans, non_stim])).astype('int')\n",
    "\n",
    "    if data_all:\n",
    "        h5_file = path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\EEG_' + cond_folder + '.h5'\n",
    "        if os.path.isfile(h5_file):\n",
    "            print('loading h5')\n",
    "            EEG_resp = h5py.File(h5_file)\n",
    "            EEG_resp = EEG_resp['EEG_resp']\n",
    "\n",
    "\n",
    "    if not 'SleepState' in con_trial:\n",
    "        con_trial.insert(6, 'SleepState', 'Wake')\n",
    "    con_trial.loc[(con_trial.SleepState == 'W'), 'SleepState'] = 'Wake'\n",
    "    con_trial.loc[(con_trial.Sleep == 0), 'SleepState'] = 'Wake'\n",
    "    con_trial.loc[(con_trial.Sleep > 1) & (con_trial.Sleep < 4), 'SleepState'] = 'NREM'\n",
    "    con_trial.loc[(con_trial.Sleep == 1), 'SleepState'] = 'NREM1'\n",
    "    con_trial.loc[(con_trial.Sleep == 6), 'SleepState'] = 'SZ'\n",
    "    con_trial.loc[(con_trial.Sleep == 4), 'SleepState'] = 'REM'\n",
    "    # Input data\n",
    "    if not \"LL_sig\"in con_trial:\n",
    "        con_trial.insert(6, 'LL_sig', con_trial.LL_WOI*con_trial.Sig)\n",
    "    M_times = []\n",
    "    M_SleepState = []\n",
    "    i = 0\n",
    "    for b in np.unique(con_trial.Block):\n",
    "        for ss_ix, ss in enumerate(['Wake', 'NREM', 'REM']):\n",
    "            summ = con_trial[(con_trial.Sig>-1)&(con_trial.Block==b)&(con_trial.SleepState==ss)]\n",
    "            if len(np.unique(summ.Stim))>0:\n",
    "                summ = summ.groupby(['Stim', 'Chan'], as_index=False)['LL_sig'].mean()#summ[summ.Sig_block>3]\n",
    "                t = np.bincount(con_trial.loc[con_trial.Block==b, 'Hour']).argmax()\n",
    "                M = np.zeros((len(labels_all),len(labels_all)))\n",
    "                M[:,:] = np.nan\n",
    "                for sc in np.unique(summ.Stim).astype('int'):\n",
    "                    chan =summ.loc[summ.Stim==sc, 'Chan'].values.astype('int')\n",
    "                    LL =summ.loc[summ.Stim==sc, 'LL_sig'].values\n",
    "                    M[sc,chan] = LL\n",
    "                M       = np.delete(np.delete(M, bad_all, 0), bad_all, 1)\n",
    "\n",
    "\n",
    "                if i==0:\n",
    "                    M_all = M\n",
    "                    i = 1\n",
    "                    arr_sleepstate = np.array([ss_ix])\n",
    "                elif i==1:\n",
    "                    M_all = np.stack([M_all, M],0)\n",
    "                    i = 2\n",
    "                    arr_sleepstate = np.concatenate([arr_sleepstate,np.array([ss_ix])])\n",
    "                else:\n",
    "                    M_all = np.concatenate([M_all,np.expand_dims(M,0)],0)\n",
    "                    arr_sleepstate =  np.concatenate([arr_sleepstate,np.array([ss_ix])])\n",
    "                M_times.append(str(t).zfill(2)+':00')\n",
    "                M_SleepState.append(ss)\n",
    "\n",
    "    # Normalize \n",
    "    V = M_all.reshape(len(M_all), -1)\n",
    "    V = V.T\n",
    "    mu = np.nanmean(V,1)\n",
    "    sigma = np.nanstd(V,1)\n",
    "\n",
    "    V = np.delete(V,np.where(np.isnan(mu) |( mu==0)) [0], 0)\n",
    "    mu = np.nanmean(V,1)\n",
    "    sigma = np.nanstd(V,1)\n",
    "\n",
    "    k = 0\n",
    "    for i in np.unique(np.where(np.isnan(V))[0]):\n",
    "        n_nan = len(np.where(np.isnan(V[i,:])==1)[0])\n",
    "        # find better way to impute nan data\n",
    "        if n_nan < V.shape[1]:\n",
    "            V[i,np.isnan(V[i,:])] = np.random.normal(mu[i], sigma[i]/1000, (n_nan,))\n",
    "            k +=1\n",
    "    ####NMF\n",
    "    Vn = V / np.percentile(V,95,1)[:,None]\n",
    "    Vn[Vn>1] = 1\n",
    "    rk = 3\n",
    "    W, W0, H = NMFf.get_nnmf_Epi(Vn, rk, it=2000) \n",
    "\n",
    "    ## KMEANS\n",
    "    kmeans = KMeans(n_clusters=3).fit(Vn)\n",
    "    CC = kmeans.cluster_centers_\n",
    "    ##Plots\n",
    "    Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF').mkdir(parents=True, exist_ok=True)\n",
    "    Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(3, 10))\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    plt.pcolormesh(np.expand_dims(kmeans.labels_,1), cmap='seismic')\n",
    "    plt.ylabel('Conenction Number', fontsize=20)\n",
    "    plt.title(subj+' -- KMEANS cluster assignment')\n",
    "    plt.xticks([])\n",
    "    plt.savefig(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures\\\\kmeans_labels.jpg')\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(25, 10))\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    plt.suptitle(subj+' -- KMEANS CC', fontsize=25)\n",
    "    gs       = fig.add_gridspec(rk+1,1)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    plt.plot(arr_sleepstate, c=color_elab[0,:], linewidth=2)\n",
    "    plt.plot(arr_sleepstate, 'o', c=color_elab[0,:], )\n",
    "    plt.yticks([0,1,2], ['Wake','NREM','REM'], fontsize=25)\n",
    "    plt.ylim([-1,4])\n",
    "    plt.gca().invert_yaxis()\n",
    "    ## hypnogram\n",
    "    for i in range(rk):\n",
    "        ax = fig.add_subplot(gs[i+1, 0])\n",
    "        ax.plot(CC[i], c=color_elab[2,:], linewidth=2)\n",
    "        ax.plot(CC[i], 'o', c=color_elab[2,:])\n",
    "        # ax.set_ylim([0.10,1])\n",
    "        plt.ylabel('CC'+str(i+1), fontsize=25)\n",
    "    plt.xlabel('Block x sleep state unique number', fontsize=20)\n",
    "    plt.savefig(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures\\\\kmeans_activation.jpg')\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 10))\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    plt.pcolormesh(W, cmap ='Reds')\n",
    "    plt.ylabel('Conenction Number', fontsize=20)\n",
    "    plt.title(subj+' -- NMF Basis function')\n",
    "    plt.xticks(np.arange(3)+0.5, ['W1', 'W2', 'W3'])\n",
    "    plt.savefig(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures\\\\NMF_labels.jpg')\n",
    "    plt.close()\n",
    "    fig = plt.figure(figsize=(25, 10))\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    plt.pcolormesh(Vn, cmap = 'hot', vmin= 0.1, vmax= 0.9)\n",
    "    plt.ylabel('Conenction Number', fontsize=20)\n",
    "    plt.title(subj+' -- Input (mean LL per connection ane block/sleep state)', fontsize=20)\n",
    "    plt.savefig(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures\\\\V_input_normalized.jpg')\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.figure(figsize=(25, 10))\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    plt.suptitle(subj+' -- NMF H function', fontsize=25)\n",
    "    gs       = fig.add_gridspec(rk+1,1)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    plt.plot(arr_sleepstate, c=color_elab[0,:], linewidth=2)\n",
    "    plt.plot(arr_sleepstate, 'o', c=color_elab[0,:], )\n",
    "    plt.yticks([0,1,2], ['Wake','NREM','REM'], fontsize=25)\n",
    "    plt.ylim([-1,4])\n",
    "    plt.gca().invert_yaxis()\n",
    "    ## hypnogram\n",
    "    for i in range(rk):\n",
    "        ax = fig.add_subplot(gs[i+1, 0])\n",
    "        ax.plot(H[i], c=color_elab[2,:], linewidth=2)\n",
    "        ax.plot(H[i], 'o', c=color_elab[2,:])\n",
    "        # ax.set_ylim([-0.10,4])\n",
    "        plt.ylabel('H'+str(i+1), fontsize=25)\n",
    "    plt.xlabel('Block x sleep state unique number', fontsize=20)\n",
    "    plt.savefig(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '\\\\NMF\\\\figures\\\\NMF_activation.jpg')\n",
    "    plt.close()\n",
    "    print(subj+' ---- DONE ----- ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-article",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-trauma",
   "metadata": {},
   "source": [
    "#### cluster block of specific sleep states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'SleepState' in con_trial:\n",
    "    con_trial.insert(6, 'SleepState', 'Wake')\n",
    "con_trial.loc[(con_trial.SleepState == 'W'), 'SleepState'] = 'Wake'\n",
    "con_trial.loc[(con_trial.Sleep == 0), 'SleepState'] = 'Wake'\n",
    "con_trial.loc[(con_trial.Sleep > 1) & (con_trial.Sleep < 4), 'SleepState'] = 'NREM'\n",
    "con_trial.loc[(con_trial.Sleep == 1), 'SleepState'] = 'NREM1'\n",
    "con_trial.loc[(con_trial.Sleep == 6), 'SleepState'] = 'SZ'\n",
    "con_trial.loc[(con_trial.Sleep == 4), 'SleepState'] = 'REM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"LL_sig\"in con_trial:\n",
    "    con_trial.insert(6, 'LL_sig', con_trial.LL_WOI*con_trial.Sig)\n",
    "M_times = []\n",
    "M_SleepState = []\n",
    "i = 0\n",
    "for b in np.unique(con_trial.Block):\n",
    "    for ss_ix, ss in enumerate(['Wake', 'NREM', 'REM']):\n",
    "        summ = con_trial[(con_trial.LL>0)&(con_trial.Block==b)&(con_trial.SleepState==ss)]\n",
    "        if len(np.unique(summ.Stim))>0.75*len(np.unique(con_trial.Stim)):\n",
    "            summ = summ.groupby(['Stim', 'Chan'], as_index=False)['LL_sig'].mean()#summ[summ.Sig_block>3]\n",
    "            t = np.bincount(con_trial.loc[con_trial.Block==b, 'Hour']).argmax()\n",
    "            M = np.zeros((len(labels_all),len(labels_all)))\n",
    "            M[:,:] =np.nan\n",
    "            for sc in np.unique(summ.Stim).astype('int'):\n",
    "                chan =summ.loc[summ.Stim==sc, 'Chan'].values.astype('int')\n",
    "                LL =summ.loc[summ.Stim==sc, 'LL_sig'].values\n",
    "                M[sc,chan] = LL\n",
    "            M       = np.delete(np.delete(M, bad_all, 0), bad_all, 1)\n",
    "\n",
    "        \n",
    "            if i==0:\n",
    "                M_all = M\n",
    "                i = 1\n",
    "                arr_sleepstate = np.array([ss_ix])\n",
    "            elif i==1:\n",
    "                M_all = np.stack([M_all, M],0)\n",
    "                i = 2\n",
    "                arr_sleepstate = np.concatenate([arr_sleepstate,np.array([ss_ix])])\n",
    "            else:\n",
    "                M_all = np.concatenate([M_all,np.expand_dims(M,0)],0)\n",
    "                arr_sleepstate =  np.concatenate([arr_sleepstate,np.array([ss_ix])])\n",
    "            M_times.append(str(t).zfill(2)+':00')\n",
    "            M_SleepState.append(ss)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_B_nmf = M_all.reshape(len(M_all), -1)\n",
    "mu = np.nanmean(M_B_nmf,0)\n",
    "sigma = np.nanstd(M_B_nmf,0)\n",
    "for i in np.where(np.isnan(M_B_nmf))[1]:\n",
    "    n = len(np.where(np.isnan(M_B_nmf[:,i])==1))\n",
    "    M_B_nmf[np.isnan(M_B_nmf[:,i]),i] = np.random.normal(mu[i], sigma[i], (n,))\n",
    "M_B_nmf = M_B_nmf.T\n",
    "M_B_nmf[np.isnan(M_B_nmf)] = 0\n",
    "M_B_nmf[M_B_nmf < 0] = 0\n",
    "# run NMF with rk = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-bridge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,15))\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "plt.pcolormesh(W, vmax = np.percentile(W,90))\n",
    "plt.xticks(np.arange(3)+0.5, ['W1', 'W2', 'W3'])\n",
    "plt.ylabel('Connections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-sunday",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rk = 3\n",
    "W, W0, H = NMFf.get_nnmf_Epi(M_B_nmf, rk, it=2000) \n",
    "#### PLOT\n",
    "ix = np.linspace(0, len(M_all)-1,10).astype('int')\n",
    "x_ticks  = [M_times[i] for i in ix]\n",
    "\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "fig.patch.set_facecolor('xkcd:white')\n",
    "gs       = fig.add_gridspec(2,1, height_ratios=[1,2])  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "## hypnogram\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "plt.plot(arr_sleepstate, c=color_elab[0,:], linewidth=2)\n",
    "plt.yticks([0,1,2], ['Wake','NREM','REM'], fontsize=25)\n",
    "plt.ylim([-1,4])\n",
    "plt.gca().invert_yaxis()\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "for i in range(rk):\n",
    "    plt.plot(H[i], label='H'+str(i+1))\n",
    "plt.xticks(ix, x_ticks, fontsize=25)\n",
    "plt.legend(fontsize=25)\n",
    "plt.ylabel('H Coefficients', fontsize=25)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-floating",
   "metadata": {},
   "source": [
    "## Plot single conenction example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-associate",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_con(3,5, con_trial,EEG_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_con(sc, rc, LL_CCEP,EEG_resp):\n",
    "    t_0 = 1\n",
    "    lists  = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)&(LL_CCEP['Block']==1)]\n",
    "    fig   = plt.figure(figsize=(10,15) )\n",
    "    gs       = fig.add_gridspec(2,1)\n",
    "    #plt.title(labels_all[Stim_chs]+' -- '+labels_clinic[rc])\n",
    "    plt.suptitle(labels_all[sc]+' -- '+labels_all[rc]+', Dist: '+str(np.round(lists.d.values[0]))+'mm',fontsize=25)\n",
    "    \n",
    "\n",
    "    #stim_spec                = stimlist[(stimlist.condition>0)&(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "    stimNum_all                  = lists.Num.values.astype('int')\n",
    "    fig.add_subplot(gs[0, 0])\n",
    "    plt.title('Raw',fontsize=20)\n",
    "    plt.ylim([-np.max([np.max(EEG_resp[rc,stimNum_all,:])*1.1,300]),np.max([np.max(EEG_resp[rc,stimNum_all,:])*1.1,300])])\n",
    "    plt.xlim([-0.5,1])\n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    plt.xticks([])\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.ylabel('[\\u03BCV]', fontsize=20)\n",
    "    resps = EEG_resp[:,stimNum_all,:]\n",
    "    LL_all = LL_funcs.get_LL_all(resps[[rc],:,:], Fs,0.25, 1, 0)\n",
    "    for i in range(len(stimNum_all)):\n",
    "        plt.plot(x_ax,ff.lp_filter(EEG_resp[rc,stimNum_all[i],:],45,Fs), c=color_elab[0], linewidth=1)\n",
    "    \n",
    "    plt.plot(x_ax,ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs), c=[0,0,0], linewidth=3)\n",
    "    #plt.axvspan(t_0+w_r-1, t_0-1+w_LL, alpha=0.3, color=color_elab[0])\n",
    "    #plt.axvspan(t_0+0.015-1, t_0+w_r-1, alpha=0.8, color=color_elab[1])\n",
    "    #plt.axvspan(t_0+0.015-1-0.2, t_0+w_r-1-0.2, alpha=0.8, color=color_elab[1])\n",
    "    fig.add_subplot(gs[1, 0])\n",
    "    plt.title('LL (250ms window)',fontsize=20)\n",
    "    plt.xlim([-0.5,1])\n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    plt.xticks([-0.5,0, 0.5, 1],fontsize=20)\n",
    "    plt.xlabel('time [s]',fontsize=20)\n",
    "    plt.ylim([0,np.max(LL_all[0,:,:])*1.3])\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.ylabel('[\\u0394 \\u03BCV/ms]', fontsize=20)\n",
    "    for i in range(len(stimNum_all)):\n",
    "        plt.plot(x_ax,ff.lp_filter(LL_all[0,i,:],45,Fs), c=color_elab[0], linewidth=1)\n",
    "    \n",
    "    plt.plot(x_ax,ff.lp_filter(np.mean(LL_all[0,:,:],0),45,Fs), c=[0,0,0], linewidth=3)\n",
    "    plt.savefig('T:\\EL_experiment\\Patients\\\\all\\\\Analysis\\LL\\\\'+subj+'_'+labels_all[sc]+'_'+labels_all[rc]+'.jpg')\n",
    "    plt.savefig('T:\\EL_experiment\\Patients\\\\all\\\\Analysis\\LL\\\\'+subj+'_'+labels_all[sc]+'_'+labels_all[rc]+'.svg')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_art(con_trial, EEG_resp):\n",
    "    # remove LL that are much higher than the mean\n",
    "    # remove trials that have artefacts (high voltage values)\n",
    "    chan, trial = np.where(np.max(abs(EEG_resp), 2) > 3000)\n",
    "    for i in range(len(trial)):\n",
    "        con_trial.loc[(con_trial.Chan == chan[i]) & (con_trial.Num == trial[i]), 'LL'] = np.nan\n",
    "        \n",
    "    \n",
    "    resp_BL  = abs(ff.lp_filter(EEG_resp, 2,Fs))\n",
    "    resp_BL = resp_BL[:,:,0:int(Fs)]\n",
    "    resp_BL[resp_BL<100] = 0\n",
    "    AUC_BL = np.trapz(resp_BL, dx=1)\n",
    "    chan, trial = np.where(AUC_BL>20000)\n",
    "    for i in range(len(trial)):\n",
    "        con_trial.loc[(con_trial.Chan == chan[i]) & (con_trial.Num == trial[i]), 'LL'] = np.nan\n",
    "\n",
    "    # remove unrealistic high LL\n",
    "    con_trial.loc[con_trial.LL > 20, 'LL'] = np.nan\n",
    "\n",
    "    return con_trial\n",
    "\n",
    "def plot_correleation_BM(M, binary=0):\n",
    "    if binary:\n",
    "        M[np.where(M>0)] = 1 \n",
    "        M[np.where(M<=0)] = 0\n",
    "        title = subj+'-- Correlation of connectivity (binary)'\n",
    "        file = 'BM_corr_CR_binary'\n",
    "    else:\n",
    "        title = subj+'-- Correlation of connectivity (LL)'\n",
    "        file = 'BM_corr_CR'\n",
    "        \n",
    "    df = pd.DataFrame(M.T)\n",
    "    corrMatrix = df.corr().values\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(corrMatrix, cmap=plt.cm.jet, vmin=np.percentile(corrMatrix,20), vmax=np.percentile(corrMatrix,90))\n",
    "    plt.ylabel('Block Number')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(extend='both')\n",
    "    plt.xticks(x_block,x_hour , rotation=45)\n",
    "    plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/'+file+'.svg')\n",
    "    plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/'+file+'.jpg')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_BM_cond(M, labels,areas, label, t):\n",
    "    time        = str(t).zfill(2)+':00'\n",
    "    fig      = plt.figure(figsize=(15,15))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, aspect='auto', origin='lower',cmap='hot', vmin=0, vmax= 20)\n",
    "    plt.xlim([-1.5, len(labels)-0.5])\n",
    "    plt.ylim([-0.5, len(labels)+0.5])\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90);\n",
    "    plt.yticks(range(len(labels)), labels);\n",
    "    for i in range(len(labels)):\n",
    "        r         = areas[i]\n",
    "        axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "        axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.04,0.85,0.08,0.08]) # x, y, x_len, y_len\n",
    "    circle1 = plt.Circle((0.5,0.5), 0.4, color = CR_color[t], alpha = CR_color_a[t])\n",
    "    plt.text(0.3,0.3, time)\n",
    "    plt.axis('off')\n",
    "    axcolor.add_patch(circle1)\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(label+', '+time+ '-- LL z-score')\n",
    "    #plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/BM_plot/BM_'+label+'.svg')\n",
    "    Path(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot/GIF').mkdir(parents=True, exist_ok=True)\n",
    "    #plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/BM_'+label+'.jpg')\n",
    "    plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot/BM_'+label+'.jpg')\n",
    "    plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot/GIF/BM_'+label+'.jpg')\n",
    "    plt.close(fig)\n",
    "    \n",
    "def plot_BM_CR_trial_sig(M, labels,areas, label, t):\n",
    "    time        = str(t).zfill(2)+':00'\n",
    "    fig      = plt.figure(figsize=(15,15))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, aspect='auto', origin='lower',cmap='hot', vmin=1, vmax= 8)\n",
    "    plt.xlim([-1.5, len(labels)-0.5])\n",
    "    plt.ylim([-0.5, len(labels)+0.5])\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90);\n",
    "    plt.yticks(range(len(labels)), labels);\n",
    "    for i in range(len(labels)):\n",
    "        r         = areas[i]\n",
    "        axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "        axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.04,0.85,0.08,0.08]) # x, y, x_len, y_len\n",
    "    circle1 = plt.Circle((0.5,0.5), 0.4, color = CR_color[t], alpha = CR_color_a[t])\n",
    "    plt.text(0.3,0.3, time)\n",
    "    plt.axis('off')\n",
    "    axcolor.add_patch(circle1)\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(label+', '+time+ '-- mean LL')\n",
    "    #plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/BM_plot/BM_'+label+'.svg')\n",
    "    Path(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/GIF/').mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/BM_'+label+'.jpg')\n",
    "    plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/GIF/BM_'+label+'.jpg')\n",
    "    plt.close(fig) #plt.show()#\n",
    "    \n",
    "def plot_BM_CR_trial(M, labels,areas, label, t):\n",
    "    time        = str(t).zfill(2)+':00'\n",
    "    fig      = plt.figure(figsize=(15,15))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, aspect='auto', origin='lower',cmap='hot', vmin=2, vmax= 15)\n",
    "    plt.xlim([-1.5, len(labels)-0.5])\n",
    "    plt.ylim([-0.5, len(labels)+0.5])\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90);\n",
    "    plt.yticks(range(len(labels)), labels);\n",
    "    for i in range(len(labels)):\n",
    "        r         = areas[i]\n",
    "        axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "        axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.04,0.85,0.08,0.08]) # x, y, x_len, y_len\n",
    "    circle1 = plt.Circle((0.5,0.5), 0.4, color = CR_color[t], alpha = CR_color_a[t])\n",
    "    plt.text(0.3,0.3, time)\n",
    "    plt.axis('off')\n",
    "    axcolor.add_patch(circle1)\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(label+', '+time+ '-- mean LL')\n",
    "    #plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/BM_plot/BM_'+label+'.svg')\n",
    "    Path(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial/GIF').mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial/BM_'+label+'.jpg')\n",
    "    plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial/GIF/BM_'+label+'.jpg')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-kidney",
   "metadata": {},
   "source": [
    "## Plot some sleep states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-basis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = 19\n",
    "rc = 65\n",
    "plot_mean_sleep(sc, rc,EEG_resp,  con_trial, lbls.Hemisphere.values+'_'+labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_labels = ['W', 'N1', 'N2', 'N3', 'REM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_sleep(sc, rc,EEG_resp,  con_trial, labels_chan):\n",
    "    data = con_trial[((con_trial.Hour >20)|(con_trial.Hour <9))&(con_trial.Stim ==sc) &(con_trial.Chan == rc) &(con_trial.LL >0) ]\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(50,10))\n",
    "    plt.suptitle(labels_chan[sc]+ ' -- '+labels_chan[rc]+', d:'+str(data.d.values[0])+'mm', fontsize=35)\n",
    "    gs       = fig.add_gridspec(1,5)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "    for ss in range(5):\n",
    "        # data\n",
    "        data_ss = data[data.Sleep == ss]\n",
    "        StimNum = data_ss.Num.values.astype('int')\n",
    "        resp_mean = ff.lp_filter(np.mean(EEG_resp[rc, StimNum,:], 0),40,Fs)\n",
    "        resp_std = np.std(EEG_resp[rc, StimNum,:], 0)\n",
    "        # plot\n",
    "        fig.add_subplot(gs[0, ss])\n",
    "        plt.title(sleep_labels[ss], fontsize=30)\n",
    "        for i in range(len(StimNum)):\n",
    "            plt.plot(x_ax, ff.lp_filter(EEG_resp[rc, StimNum[i],:],40,Fs), c=[0,0,0], linewidth=1)\n",
    "        plt.plot(x_ax, resp_mean, c=color_elab[0,:], linewidth=5)\n",
    "    \n",
    "        plt.fill_between(x_ax,resp_mean-resp_std,resp_mean+resp_std, color=color_elab[0,:], alpha = 0.1)\n",
    "        #plt.xticks([])\n",
    "        plt.tick_params(axis=\"y\", labelsize=18)\n",
    "        plt.tick_params(axis=\"x\", labelsize=18)\n",
    "        plt.axvline(0, linewidth=2, color=[1,0,0])\n",
    "        plt.ylim([-500,500])\n",
    "        plt.xlim([-0.5,1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-vegetable",
   "metadata": {},
   "source": [
    "\n",
    "pdist = spc.distance.pdist(corr)\n",
    "linkage = spc.linkage(pdist, method='complete')\n",
    "idx = spc.fcluster(linkage, 0.5 * pdist.max(), 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stim = np.arange(len(labels_all))\n",
    "non_stim = np.delete(non_stim, StimChanIx, 0)\n",
    "bad_all = np.unique(np.concatenate([bad_region, bad_chans, non_stim])).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_region_L = lbls.Hemisphere.values+'_'+labels_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(con_trial.loc[con_trial.Block==10, 'SleepState'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "rk = 2\n",
    "W, W0, H = NMFf.get_nnmf_Epi(M_B_nmf, rk, it=2000)\n",
    "plt.figure(figsize=(30,5))\n",
    "for i in range(rk):\n",
    "    plt.plot(H[i])\n",
    "plt.plot(arr_sleepstate)\n",
    "plt.xticks(np.arange(len(M_all)), M_SleepState)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/data/BM_all_trial_sig.npy') : \n",
    "    M_all = np.load(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/data/BM_all_trial_sig.npy')\n",
    "else:\n",
    "    i =0\n",
    "    for b in np.unique(con_trial.Block):\n",
    "        summ = con_trial[(con_trial.LL>0)&(con_trial.Sig_block_surr ==1)&(con_trial.Block==b)]\n",
    "        summ = summ.groupby(['Stim', 'Chan'], as_index=False)['LL_peak'].mean()#summ[summ.Sig_block>3]\n",
    "        t = np.bincount(con_trial.loc[con_trial.Block==b, 'Hour']).argmax()\n",
    "        M = np.zeros((len(labels_all),len(labels_all)))\n",
    "        for sc in np.unique(summ.Stim).astype('int'):\n",
    "            chan =summ.loc[summ.Stim==sc, 'Chan'].values.astype('int')\n",
    "            LL =summ.loc[summ.Stim==sc, 'LL_peak'].values\n",
    "            M[sc,chan] = LL\n",
    "        M = np.nan_to_num(M)\n",
    "        # BM plot\n",
    "        labels_sel   = np.delete(labels_all, bad_all, 0)\n",
    "        areas_sel    = np.delete(labels_region_L, bad_all, 0)\n",
    "        M_resp       = np.delete(np.delete(M, bad_all, 0), bad_all, 1)\n",
    "\n",
    "        # sort\n",
    "        ind = np.argsort(areas_sel)\n",
    "        areas_sel    = np.delete(labels_region, bad_all, 0)\n",
    "        M_resp= M_resp[ind,:]\n",
    "        M_resp = M_resp[:,ind]\n",
    "        labels_sel = labels_sel[ind]\n",
    "        areas_sel = areas_sel[ind]\n",
    "        if i==0:\n",
    "            M_all = M_resp\n",
    "        elif i==1:\n",
    "            M_all = np.stack([M_all, M_resp],0)\n",
    "        else:\n",
    "            M_all = np.concatenate([M_all,np.expand_dims(M_resp,0)],0)\n",
    "        ll = 'BM'+str(int(b)).zfill(2)\n",
    "        plot_BM_CR_trial_sig(M_resp, labels_sel,areas_sel, ll, t)\n",
    "        i = i+1\n",
    "    np.save(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/data/BM_all_trial_sig.npy', M_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correleation_BM_hyp(M, binary=0):\n",
    "    if binary:\n",
    "        M[np.where(M>0)] = 1 \n",
    "        M[np.where(M<=0)] = 0\n",
    "        title = subj+'-- Correlation of connectivity (binary)'\n",
    "        file = 'BM_corr_CR_binary'\n",
    "    else:\n",
    "        title = subj+'-- Correlation of connectivity (LL)'\n",
    "        file = 'BM_corr_CR'\n",
    "        \n",
    "    df = pd.DataFrame(M.T)\n",
    "    corrMatrix = df.corr().values\n",
    "\n",
    "    fig = plt.figure(figsize=(25, 30))\n",
    "    d_x = int(total_hour/5)\n",
    "    gs       = fig.add_gridspec(2,1, height_ratios=[1,10])  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "    ## hypnogram\n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    plt.plot(stimlist_hypno.ix_chron, stimlist_hypno.sleep, c=color_elab[0,:], linewidth=2)\n",
    "    plt.axhspan(-1, 0.2, color=color_elab[0,:])\n",
    "    plt.fill_between(stimlist_hypno.ix_chron,stimlist_hypno.sleep,np.zeros((len(stimlist_hypno.ix_chron),))-1, color=color_elab[0,:])\n",
    "    #plt.ylabel('score', fontsize=25)\n",
    "    plt.yticks([0,1,2,3,4], ['Wake','N1','N2','N3','REM'], fontsize=40)\n",
    "    plt.ylim([-1,5])\n",
    "    plt.gca().invert_yaxis()\n",
    "    #plt.xticks(x_tick1,x_ax_h )\n",
    "    plt.xticks([])\n",
    "    plt.tick_params(axis=\"y\", labelsize=18)\n",
    "    \n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "    plt.imshow(corrMatrix, cmap=plt.cm.jet, vmin=np.percentile(corrMatrix,20), vmax=np.percentile(corrMatrix,90))\n",
    "    plt.ylabel('Block Number')\n",
    "    plt.title(title)\n",
    "    #plt.colorbar(extend='both')\n",
    "    plt.xticks(x_block,x_hour , rotation=45)\n",
    "    plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/'+file+'_hyp.svg')\n",
    "    plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/'+file+'_hyp.jpg')\n",
    "\n",
    "    print(cond_folder +'/figures/BM_plot_trial_sig/'+file)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "if cond_folder == 'CR':\n",
    "    Mh    = np.copy(M_all)\n",
    "    Mh[np.where(Mh==-1)] = np.nan\n",
    "    Mh_flat    = Mh.reshape(Mh.shape[0],Mh.shape[1]*Mh.shape[2]) #\n",
    "\n",
    "    # delta = 0\n",
    "    # Mh    = np.copy(BM_all)\n",
    "    # Mh[np.where(Mh==-1)] = np.nan\n",
    "    # \n",
    "    # Mh_flat    = Mh.reshape(Mh.shape[0],Mh.shape[1]*Mh.shape[2]) #(70, 2916)\n",
    "    # dist_flat  = distance.pdist(Mh_flat,'hamming') #(2415,)\n",
    "    # M          = np.zeros((Mh.shape[0],Mh.shape[0]))\n",
    "    # for i in range(Mh.shape[0]):\n",
    "    #     for j in range(Mh.shape[0]):\n",
    "    #         M[i,j] = dist_flat[int(Mh.shape[0] * i + j - ((i + 2) * (i + 1)) // 2)]\n",
    "    x_block = np.unique(con_trial.Block)#[np.arange(0, len(Mh_flat),len(Mh_flat)/8).astype('int')]\n",
    "    #np.arange(1, len(Mh_flat),4)\n",
    "    x_hour =[]\n",
    "    for b in x_block:\n",
    "        x_raw = np.bincount(con_trial.loc[con_trial.Block==b, 'Hour']).argmax()\n",
    "        x_hour.append(f\"{x_raw:02}\"+\":00\")\n",
    "\n",
    "    plot_correleation_BM(Mh_flat, binary=0)\n",
    "    #plot_correleation_BM_hyp(Mh_flat, binary=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimlist_hypno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-survival",
   "metadata": {},
   "source": [
    "## GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import nxviz\n",
    "from nxviz.plots import CircosPlot, MatrixPlot, ArcPlot, BasePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes   = pd.DataFrame({'ID': labels_all, 'Region': labels_region})\n",
    "nodes   = nodes.drop(nodes[(nodes.Region == 'WM') | (nodes.Region == 'OUT') | (nodes.Region == 'Putamen')].index)\n",
    "nodes  =nodes.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(nodes_df, edges_df):\n",
    "    \n",
    "    # make graph from nodes and edges\n",
    "    g = nx.DiGraph()\n",
    "    for i,row in nodes_df.iterrows():\n",
    "\n",
    "        keys = row.index.tolist()\n",
    "\n",
    "        values = row.values\n",
    "\n",
    "        # The dict contains all attributes\n",
    "\n",
    "        g.add_node(row['ID'], **dict(zip(keys,values)))\n",
    "\n",
    "\n",
    "    for i,row in edges_df.iterrows():\n",
    "\n",
    "        keys = row.index.tolist()\n",
    "\n",
    "        values = row.values\n",
    "\n",
    "        g.add_edge(row['source'], row['target'], weight=row['LL_peak'],**dict(zip(keys,values)))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph(graph_dat, nodes, feature='LL_peak', labels_all=labels_all):\n",
    "    #graph_dat = data.groupby(['Stim', 'Chan'], as_index=False)['LL_peak'].mean()#summ[summ.Sig_block>3]\n",
    "    graph_dat.insert(0, 'source',graph_dat.Stim )\n",
    "    graph_dat.insert(0, 'target',graph_dat.Chan )\n",
    "    for i in range(len(labels_all)):\n",
    "        graph_dat.loc[graph_dat.Stim==i, 'source'] = labels_all[i]\n",
    "        graph_dat.loc[graph_dat.Chan==i, 'target'] = labels_all[i]\n",
    "    #G       = nx.from_pandas_edgelist(graph_dat, source=\"S\", target=\"C\",edge_attr=\"LL_peak\")\n",
    "    edges   = graph_dat.drop(columns=['Stim', 'Chan'])\n",
    "    edges =edges.reset_index(drop=True)\n",
    "    #print(edges.LL_peak.values[0])\n",
    "    G       = make_graph(nodes, edges)\n",
    "    #print(nx.info(G))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_out = np.zeros((len(labels_all),len(np.unique(con_trial.Block))))\n",
    "deg_in = np.zeros((len(labels_all),len(np.unique(con_trial.Block))))\n",
    "den_arr = np.zeros((len(np.unique(con_trial.Block)),))\n",
    "i = 0\n",
    "for b in np.unique(con_trial.Block):\n",
    "    data = con_trial[(con_trial.Sig_block_surr==1)&(con_trial.Block==b)]\n",
    "    graph_dat = data.groupby(['Stim', 'Chan'], as_index=False)['LL_peak'].mean()#summ[summ.Sig_block>3]\n",
    "    G = get_graph(graph_dat, nodes)\n",
    "    den_arr[i]= nx.density(G)\n",
    "    for l in np.unique([graph_dat.target,graph_dat.source]):\n",
    "        sc = np.where(labels_all==l)[0][0]\n",
    "        deg_in[sc,i] = G.in_degree[l]\n",
    "        deg_out[sc,i] = G.out_degree[l]\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-swaziland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig      =  plt.figure(figsize=(total_hour/4,8))\n",
    "\n",
    "d_x = int(total_hour/5)\n",
    "gs       = fig.add_gridspec(2,1, height_ratios=[1,3])  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "\n",
    "## hypnogram\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "plt.plot(stimlist_hypno.ix_chron, stimlist_hypno.sleep, c=color_elab[0,:], linewidth=2)\n",
    "plt.axhspan(-1, 0.2, color=color_elab[0,:])\n",
    "plt.fill_between(stimlist_hypno.ix_chron,stimlist_hypno.sleep,np.zeros((len(stimlist_hypno.ix_chron),))-1, color=color_elab[0,:])\n",
    "#plt.ylabel('score', fontsize=25)\n",
    "plt.yticks([0,1,2,3,4], ['Wake','N1','N2','N3','REM'])\n",
    "plt.ylim([-1,5])\n",
    "plt.gca().invert_yaxis()\n",
    "#plt.xticks(x_tick1,x_ax_h )\n",
    "plt.xticks([])\n",
    "plt.tick_params(axis=\"y\", labelsize=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = fig.add_subplot(gs[1, 0], sharex=ax)\n",
    "plt.suptitle(subj+' -- Density of Connection Map across time', fontsize=18)\n",
    "plt.scatter(time_overview.Hour_chron+0.5, time_overview.density)\n",
    "plt.ylim([0.05, 0.2])\n",
    "plt.xlabel('Time',  fontsize=15)\n",
    "plt.ylabel('Density Value',  fontsize=15)\n",
    "plt.tick_params(axis=\"y\", labelsize=18)\n",
    "plt.tick_params(axis=\"x\", labelsize=18)\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/density.jpg')\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/density.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig      =  plt.figure(figsize=(25,30))\n",
    "\n",
    "d_x = int(total_hour/5)\n",
    "gs       = fig.add_gridspec(2,1, height_ratios=[1,10])  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "## hypnogram\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "plt.plot(stimlist_hypno.ix_chron, stimlist_hypno.sleep, c=color_elab[0,:], linewidth=2)\n",
    "plt.axhspan(-1, 0.2, color=color_elab[0,:])\n",
    "plt.fill_between(stimlist_hypno.ix_chron,stimlist_hypno.sleep,np.zeros((len(stimlist_hypno.ix_chron),))-1, color=color_elab[0,:])\n",
    "#plt.ylabel('score', fontsize=25)\n",
    "plt.yticks([0,1,2,3,4], ['Wake','N1','N2','N3','REM'], fontsize=40)\n",
    "plt.ylim([-1,5])\n",
    "plt.gca().invert_yaxis()\n",
    "#plt.xticks(x_tick1,x_ax_h )\n",
    "plt.xticks([])\n",
    "plt.tick_params(axis=\"y\", labelsize=18)\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "plt.pcolormesh(deg_out[:-1], cmap=plt.cm.jet, vmin=0, vmax=np.percentile(deg_out,90))\n",
    "plt.yticks(np.arange(len(labels_all)), labels_all, fontsize=20)\n",
    "plt.xticks(np.linspace(0,deg_out[:-1].shape[1],d_x), time_overview.Hour_label[np.linspace(0,total_hour-1,d_x).astype('int')], rotation=45, fontsize=20)\n",
    "\n",
    "plt.title('Degree out', fontsize=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig      =  plt.figure(figsize=(25,30))\n",
    "\n",
    "d_x = int(total_hour/5)\n",
    "gs       = fig.add_gridspec(2,1, height_ratios=[1,10])  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "## hypnogram\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "plt.plot(stimlist_hypno.ix_chron, stimlist_hypno.sleep, c=color_elab[0,:], linewidth=2)\n",
    "plt.axhspan(-1, 0.2, color=color_elab[0,:])\n",
    "plt.fill_between(stimlist_hypno.ix_chron,stimlist_hypno.sleep,np.zeros((len(stimlist_hypno.ix_chron),))-1, color=color_elab[0,:])\n",
    "#plt.ylabel('score', fontsize=25)\n",
    "plt.yticks([0,1,2,3,4], ['Wake','N1','N2','N3','REM'], fontsize=40)\n",
    "plt.ylim([-1,5])\n",
    "plt.gca().invert_yaxis()\n",
    "#plt.xticks(x_tick1,x_ax_h )\n",
    "plt.xticks([])\n",
    "plt.tick_params(axis=\"y\", labelsize=18)\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0])\n",
    "plt.pcolormesh(deg_in[:-1], cmap=plt.cm.jet, vmin=0, vmax=np.percentile(deg_out,90))\n",
    "plt.yticks(np.arange(len(labels_all)), labels_all, fontsize=20)\n",
    "plt.xticks(np.linspace(0,deg_in[:-1].shape[1],d_x), time_overview.Hour_label[np.linspace(0,total_hour-1,d_x).astype('int')], rotation=45, fontsize=20)\n",
    "\n",
    "plt.title('Degree in', fontsize=40)\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/deg_in.jpg')\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/deg_in.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.imshow(deg_out, cmap=plt.cm.jet, vmin=0, vmax=np.percentile(deg_in,90))\n",
    "plt.xlabel('Block Number')\n",
    "plt.yticks(np.arange(len(labels_all)), labels_all)\n",
    "plt.title('Degree in')\n",
    "plt.colorbar(extend='both')\n",
    "# plt.xticks(x_block,x_hour , rotation=45)\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/deg_out.jpg')\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/deg_out.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 18))\n",
    "plt.imshow(deg_in, cmap=plt.cm.jet, vmin=0, vmax=np.percentile(deg_in,90))\n",
    "plt.xlabel('Block Number')\n",
    "plt.yticks(np.arange(len(labels_all)), labels_all)\n",
    "plt.title('Degree in')\n",
    "plt.colorbar(extend='both')\n",
    "# plt.xticks(x_block,x_hour , rotation=45)\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/deg_in.jpg')\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/deg_in.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-matthew",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "den_arr = np.zeros((len(np.unique(con_trial.Block)),))\n",
    "i = 0\n",
    "for b in np.unique(con_trial.Block):\n",
    "    data = con_trial[(con_trial.Sig_block_surr==1)&(con_trial.Block==b)] #&(con_trial.Sig_block>2)\n",
    "    graph_dat = data.groupby(['Stim', 'Chan'], as_index=False)['LL_peak'].mean()#summ[summ.Sig_block>3]\n",
    "    G = get_graph(graph_dat, nodes)\n",
    "    den_arr[i]= nx.density(G)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = np.unique(con_trial.Date)\n",
    "t0 = np.min(con_trial.loc[(con_trial.Date==day[0]), 'Hour']).astype('int')\n",
    "t1 = np.max(con_trial.loc[(con_trial.Date==day[-1]), 'Hour']).astype('int')\n",
    "total_hour = (len(day)-1)*24 -(t0-t1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-intention",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_overview = np.zeros((total_hour,5))\n",
    "b0 = np.min(con_trial.Block)\n",
    "time_overview[:,:]=np.nan\n",
    "time_overview[:,0] = np.arange(total_hour)\n",
    "i = 0\n",
    "h0 =  np.bincount(con_trial.loc[con_trial.Block==b0, 'Hour']).argmax()\n",
    "for b in np.unique(con_trial.Block):\n",
    "    date = np.bincount(con_trial.loc[con_trial.Block==b, 'Date']).argmax()\n",
    "    d = np.where(day==date)[0]\n",
    "    i = np.bincount(con_trial.loc[con_trial.Block==b, 'Hour']).argmax() +d*24-h0\n",
    "    time_overview[i,1] = d\n",
    "    time_overview[i,2] = np.bincount(con_trial.loc[con_trial.Block==b, 'Hour']).argmax()\n",
    "    time_overview[i,3] = b\n",
    "    time_overview[i,4] = b\n",
    "time_overview = pd.DataFrame(time_overview[:,:4], columns=['ix', 'Day', 'Hour', 'Block'])   \n",
    "time_overview.insert(3,'Hour_label', 0)\n",
    "for b in np.unique(time_overview.Block):\n",
    "    if b>0:\n",
    "        time_overview.loc[time_overview.Block==b, 'Hour_label'] = str(int(time_overview.loc[time_overview.Block==b, 'Hour'])).zfill(2)+':00'\n",
    "    \n",
    "time_overview.to_csv(path_patient_analysis + '/BrainMapping/CR/data/time_overview.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-large",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_overview = pd.read_csv(path_patient + '/Analysis/BrainMapping/CR/data/time_overview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_overview.insert(0, 'density', 0)\n",
    "i =0\n",
    "for b in np.unique(con_trial.Block):\n",
    "    time_overview.loc[time_overview.Block==b, 'density'] = den_arr[i]\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-numbers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load hypnogram\n",
    "file_hypno = path_patient_analysis + '/stimlist_hypnogram.csv'\n",
    "if os.path.isfile(file_hypno):\n",
    "    stimlist_hypno = pd.read_csv(file_hypno)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add chornologic hours for plotting\n",
    "#stimlist_hypno.insert(0, 'ix_chron', 0)\n",
    "for d in range(len(np.unique(stimlist_hypno.date))):\n",
    "    stimlist_hypno.loc[stimlist_hypno.date == np.unique(stimlist_hypno.date)[d],'ix_chron']= stimlist_hypno.loc[stimlist_hypno.date == np.unique(stimlist_hypno.date)[d],'ix_h']+d*24\n",
    "time_overview.insert(5, 'Hour_chron', time_overview.Hour+ time_overview.Day*24)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig      =  plt.figure(figsize=(total_hour/4,8))\n",
    "\n",
    "d_x = int(total_hour/4)\n",
    "gs       = fig.add_gridspec(2,1, height_ratios=[1,3])  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "\n",
    "## hypnogram\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "plt.plot(stimlist_hypno.ix_chron, stimlist_hypno.sleep, c=color_elab[0,:], linewidth=2)\n",
    "plt.axhspan(-1, 0.2, color=color_elab[0,:])\n",
    "plt.fill_between(stimlist_hypno.ix_chron,stimlist_hypno.sleep,np.zeros((len(stimlist_hypno.ix_chron),))-1, color=color_elab[0,:])\n",
    "#plt.ylabel('score', fontsize=25)\n",
    "plt.yticks([0,1,2,3,4], ['Wake','N1','N2','N3','REM'])\n",
    "plt.ylim([-1,5])\n",
    "plt.gca().invert_yaxis()\n",
    "#plt.xticks(x_tick1,x_ax_h )\n",
    "plt.xticks([])\n",
    "plt.tick_params(axis=\"y\", labelsize=18)\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0], sharex=ax)\n",
    "plt.suptitle(subj+' -- Density of Connection Map across time', fontsize=18)\n",
    "plt.scatter(time_overview_real.Hour_chron+0.5, H[0,:-1])\n",
    "plt.scatter(time_overview_real.Hour_chron+0.5, H[1,:-1])\n",
    "plt.scatter(time_overview_real.Hour_chron+0.5, H[2,:-1])\n",
    "plt.xticks(time_overview.Hour_chron[np.linspace(0,total_hour-5,d_x).astype('int')].values, time_overview.Hour_label[np.linspace(0,total_hour-5,d_x).astype('int')].to_list(), rotation=45)\n",
    "plt.ylim([0.05, 10])\n",
    "plt.xlabel('Time',  fontsize=15)\n",
    "plt.ylabel('H acitivtion',  fontsize=15)\n",
    "plt.tick_params(axis=\"y\", labelsize=18)\n",
    "plt.tick_params(axis=\"x\", labelsize=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_overview_real = time_overview[time_overview.Block>-1]\n",
    "time_overview_real = time_overview_real.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_overview_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_overview_new = time_overview[time_overview.Block>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_dir_path = path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\BM_figures\\\\Block\\\\BM_LL.npy'\n",
    "M_Block = np.load(M_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Block.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(H[0])\n",
    "plt.plot(H[1])\n",
    "plt.plot(H[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "north-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Block_new = M_Block[0:,:,:]\n",
    "M_B_nmf = M_Block_new.reshape(len(M_Block_new), -1)\n",
    "M_B_nmf = M_B_nmf.T\n",
    "M_B_nmf[np.isnan(M_B_nmf)] = 0\n",
    "M_B_nmf[M_B_nmf < 0] = 0\n",
    "# run NMF with rk = 3\n",
    "rk = 3\n",
    "W, W0, H = NMFf.get_nnmf_Epi(M_B_nmf, rk, it=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-ghana",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig      =  plt.figure(figsize=(total_hour/4,8))\n",
    "\n",
    "d_x = int(total_hour/5)\n",
    "gs       = fig.add_gridspec(2,1, height_ratios=[1,3])  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "\n",
    "## hypnogram\n",
    "ax = fig.add_subplot(gs[0, 0])\n",
    "plt.plot(stimlist_hypno.ix_chron, stimlist_hypno.sleep, c=color_elab[0,:], linewidth=2)\n",
    "plt.axhspan(-1, 0.2, color=color_elab[0,:])\n",
    "plt.fill_between(stimlist_hypno.ix_chron,stimlist_hypno.sleep,np.zeros((len(stimlist_hypno.ix_chron),))-1, color=color_elab[0,:])\n",
    "#plt.ylabel('score', fontsize=25)\n",
    "plt.yticks([0,1,2,3,4], ['Wake','N1','N2','N3','REM'])\n",
    "plt.ylim([-1,5])\n",
    "plt.gca().invert_yaxis()\n",
    "#plt.xticks(x_tick1,x_ax_h )\n",
    "plt.xticks([])\n",
    "plt.tick_params(axis=\"y\", labelsize=18)\n",
    "\n",
    "ax = fig.add_subplot(gs[1, 0], sharex=ax)\n",
    "plt.suptitle(subj+' -- Density of Connection Map across time', fontsize=18)\n",
    "plt.scatter(time_overview.Hour_chron+0.5, time_overview.density)\n",
    "plt.xticks(time_overview.Hour_chron[np.linspace(0,total_hour-1,d_x).astype('int')], time_overview.Hour_label[np.linspace(0,total_hour-1,d_x).astype('int')], rotation=45)\n",
    "plt.ylim([0.05, 0.2])\n",
    "plt.xlabel('Time',  fontsize=15)\n",
    "plt.ylabel('Density Value',  fontsize=15)\n",
    "plt.tick_params(axis=\"y\", labelsize=18)\n",
    "plt.tick_params(axis=\"x\", labelsize=18)\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/density.jpg')\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/density.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-consistency",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(time_overview.ix, time_overview.density)\n",
    "plt.xticks(time_overview.ix, time_overview.Hour_label, rotation='vertical')\n",
    "plt.ylim([0.1, 0.25])\n",
    "plt.xlabel('Time',  fontsize=15)\n",
    "plt.ylabel('Density Value',  fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = con_trial[(con_trial.Sig_block_surr==1)&(con_trial.Block==8)] # &(con_trial.Sig_block>3)\n",
    "graph_dat = data.groupby(['Stim', 'Chan'], as_index=False)['LL_peak'].mean()#summ[summ.Sig_block>3]\n",
    "G = get_graph(graph_dat, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'BM'+str(int(b)).zfill(2)\n",
    "c = CircosPlot(G, node_color='Region', group_label_position=\"middle\", group_label_offset=12, node_grouping='Region', node_labels=True, node_label_layout='rotation', figsize=(8,8))\n",
    "\n",
    "c.draw()\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/graph_'+label+'.jpg')\n",
    "plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/graph_plots/graph_'+label+'.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_test = con_trial[(con_trial.Sig_block_surr==1)&(con_trial.Block==8)] # &(con_trial.Sig_block>3)#LL_CCEP[(LL_CCEP.RespC==1)&(LL_CCEP.LL>1)&(LL_CCEP.d>50)]\n",
    "data_test = data_test.drop(columns=['RespC', 'RespR', 'RespA','rLL', 'zLL', 'Day'])\n",
    "data_test.insert(0,'Recs', 0)\n",
    "data_test.insert(0,'Stims', 0)\n",
    "for c in range(len(labels_all)):\n",
    "    data_test.loc[(data_test.Stim ==c), \"Region\"] = labels_region[c]\n",
    "    data_test.loc[(data_test.Chan ==c), \"RegionC\"] = labels_region[c]\n",
    "    data_test.loc[(data_test.Chan ==c), \"Recs\"]   = labels_all[c]\n",
    "    data_test.loc[(data_test.Stim ==c), \"Stims\"]  = labels_all[c]\n",
    "data_test=data_test.drop(data_test[data_test.Region=='WM'].index)\n",
    "data_test=data_test.drop(data_test[data_test.RegionC=='WM'].index)\n",
    "data_test = data_test.drop(columns=['Region', 'RegionC'])\n",
    "G       = nx.from_pandas_edgelist(data_test, \"Stims\", \"Recs\",[\"LL\", \"d\"])\n",
    "edges   = nx.to_pandas_edgelist(G)\n",
    "nodes   = pd.DataFrame({'ID': labels_all, 'Region': labels_region, 'H': labels_L})\n",
    "nodes   = nodes.drop(nodes[nodes.Region=='WM'].index)\n",
    "G       = make_graph(nodes, edges)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "pos = nx.circular_layout(G) #nx.spring_layout(G)\n",
    "nx.draw_networkx_nodes(G, pos, cmap=plt.get_cmap('jet'), \n",
    "                        node_size = 500)\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "nx.draw_networkx_edges(G, pos,edge_color='r', arrows=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-mainstream",
   "metadata": {},
   "source": [
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NMF_funcs as NMFf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add path\n",
    "nmf_fig_path = path_patient_analysis + '/BrainMapping/' + cond_folder + '/NNMF/figures/'\n",
    "nmf_path = path_patient_analysis + '/BrainMapping/' + cond_folder + '/NNMF/'\n",
    "for path_find in [nmf_path, nmf_fig_path]:\n",
    "    try:\n",
    "        os.mkdir(path_find)\n",
    "    except OSError:\n",
    "        print(path_find + \" -- already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial.insert(4,'LLs', np.nan)\n",
    "con_trial.loc[(con_trial.Sig==1), 'LLs'] = con_trial.loc[(con_trial.Sig==1), 'LL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial_nan = con_trial.copy(deep=True)\n",
    "\n",
    "con_trial_nan.LL_peak = con_trial_nan.groupby(['Stim', 'Chan', 'Block', 'Sleep'])['LL_peak'].transform(\n",
    "    lambda x: x.fillna(x.mean()))\n",
    "con_trial_nan.LL_peak = con_trial_nan.groupby(['Stim', 'Chan', 'Block'])['LL_peak'].transform(\n",
    "    lambda x: x.fillna(x.mean()))\n",
    "con_trial_nan.LL_peak = con_trial_nan.groupby(['Stim', 'Chan', 'Sleep'])['LL_peak'].transform(\n",
    "    lambda x: x.fillna(x.mean()))\n",
    "con_trial_nan.LL_peak = con_trial_nan.groupby(['Stim', 'Chan'])['LL_peak'].transform(lambda x: x.fillna(x.mean()))\n",
    "con_trial_nan.LL_peak = con_trial_nan.groupby(['Chan'])['LL_peak'].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "rk = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "[W, H, H_sleep,W_pref_z] = np.load(path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\NNMF\\\\nmf_rk' + str(\n",
    "            rk) + '.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_path = nmf_path + 'IO_LLpeak.npy'\n",
    "title_LL = subj + ', Stim: all, LL as input'\n",
    "if os.path.isfile(V_path):\n",
    "    NMF_input = np.load(V_path)\n",
    "else:\n",
    "    con_trial_nan = con_trial.copy(deep=True)\n",
    "\n",
    "    con_trial_nan.LL_peak = con_trial_nan.groupby(['Stim', 'Chan', 'Block', 'Sleep'])['LL_peak'].transform(\n",
    "        lambda x: x.fillna(x.mean()))\n",
    "    con_trial_nan.LL_peak = con_trial_nan.groupby(['Stim', 'Chan', 'Block'])['LL_peak'].transform(\n",
    "        lambda x: x.fillna(x.mean()))\n",
    "    con_trial_nan.LL_peak = con_trial_nan.groupby(['Stim', 'Chan', 'Sleep'])['LL_peak'].transform(\n",
    "        lambda x: x.fillna(x.mean()))\n",
    "    con_trial_nan.LL_peak = con_trial_nan.groupby(['Stim', 'Chan'])['LL_peak'].transform(lambda x: x.fillna(x.mean()))\n",
    "    con_trial_nan.LL_peak = con_trial_nan.groupby(['Chan'])['LL_peak'].transform(lambda x: x.fillna(x.mean()))\n",
    "    NMF_input = np.zeros((len(labels_all), len(np.unique(con_trial_nan.Num).astype('int'))))\n",
    "    i = 0\n",
    "    nums = con_trial_nan.Num.values\n",
    "    nums, idx = np.unique(nums, return_index=True)\n",
    "\n",
    "    for num in nums.astype('int'):\n",
    "        # for num in nums[np.sort(idx)].astype('int'):\n",
    "        dat = con_trial_nan[con_trial_nan.Num == num]\n",
    "        chan = dat.Chan.values.astype('int')\n",
    "        NMF_input[chan, i] = abs(dat.LL_peak.values)\n",
    "        i = i + 1\n",
    "    NMF_input = np.nan_to_num(NMF_input, nan=0)\n",
    "    np.save(V_path, NMF_input)\n",
    "    # todo: plot NMF input\n",
    "    # W\n",
    "    labels_clean = np.delete(labels_all, bad_region, 0)\n",
    "    NMF_input_clean = np.delete(NMF_input, bad_region, 0)\n",
    "    file = nmf_fig_path + 'NMF_input_IO_LLpeak'\n",
    "    NMFf.plot_V(NMF_input_clean, subj + ' -- NMF input matrix: LL ', ylabels=labels_clean, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMF_input = np.zeros((len(labels_all), len(np.unique(con_trial_nan.Num).astype('int'))))\n",
    "i = 0\n",
    "nums = con_trial_nan.Num.values\n",
    "nums, idx = np.unique(nums, return_index=True)\n",
    "\n",
    "for num in nums.astype('int'):\n",
    "    # for num in nums[np.sort(idx)].astype('int'):\n",
    "    dat = con_trial_nan[con_trial_nan.Num == num]\n",
    "    chan = dat.Chan.values.astype('int')\n",
    "    NMF_input[chan, i] = abs(dat.LL_peak.values)\n",
    "    i = i + 1\n",
    "NMF_input = np.nan_to_num(NMF_input, nan=0)\n",
    "np.save(V_path, NMF_input)\n",
    "# todo: plot NMF input\n",
    "# W\n",
    "labels_clean = np.delete(labels_all, bad_region, 0)\n",
    "NMF_input_clean = np.delete(NMF_input, bad_region, 0)\n",
    "file = nmf_fig_path + 'NMF_input_IO_LLpeak'\n",
    "NMFf.plot_V(NMF_input_clean, subj + ' -- NMF input matrix: LL ', ylabels=labels_clean, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMFf.plot_V(NMF_input_clean, subj + ' -- NMF input matrix: LL ', ylabels=labels_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "k0 = 3\n",
    "k1 = 10\n",
    "num_it = 25\n",
    "ranks = np.arange(k0, k1 + 1)\n",
    "stability, instability = NMFf.get_stability(NMF_input, num_it=num_it, k0=k0, k1=k1)\n",
    "stab_sel = (stability / stability.max() - instability / instability.max())\n",
    "ix0 = np.argmax(stab_sel)\n",
    "print('Best Rank: '+ str(ranks[ix0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "rk = ranks[ix0]\n",
    "[W, H] = NMFf.get_nnmf(NMF_input, rk, it=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "col0 = ['Stim', 'Block', 'Hour', 'Date', 'Sleep', 'Num']  # 'Hour',\n",
    "col = ['Stim', 'Block', 'Hour', 'Date', 'Sleep', 'Num']   # 'Hour',\n",
    "W_col = []\n",
    "H_col = []\n",
    "for i in range(H.shape[0]):\n",
    "    col.append('H' + str(i + 1))\n",
    "    W_col.append('W' + str(i + 1))\n",
    "    H_col.append('H' + str(i + 1))\n",
    "\n",
    "con_nmf = np.zeros((H.shape[1], len(col0) + H.shape[0]))\n",
    "con_nmf[:, len(col0):] = H.T\n",
    "# add stim channel, Hour and Intensity\n",
    "i = 0\n",
    "for n in nums.astype('int'):\n",
    "    for k in range(len(col0)):\n",
    "        #np.bincount(con_trial.loc[con_trial.Num == n, col0[k]]).argmax()\n",
    "        con_nmf[i, k] = con_trial.loc[con_trial.Num == n, col0[k]].values[0]\n",
    "    i = i + 1\n",
    "\n",
    "pd_con_nnmf = pd.DataFrame(con_nmf, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_con_nnmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hl in H_col:\n",
    "    thr = 1.2*np.median(pd_con_nnmf[hl])\n",
    "    h_max = pd_con_nnmf.groupby(['Stim'])[hl].max().values\n",
    "    h_min = pd_con_nnmf.groupby(['Stim'])[hl].min().values\n",
    "    stim_sel = np.where(pd_con_nnmf.groupby(['Stim'])[hl].mean().values>thr)[0]\n",
    "    pd_con_nnmf.insert(pd_con_nnmf.shape[1],'n'+hl , 0)\n",
    "    for sc_clean in stim_sel.astype('int'):\n",
    "        sc = Stims[sc_clean]\n",
    "        pd_con_nnmf.loc[pd_con_nnmf.Stim==sc, 'n'+hl] = pd_con_nnmf.loc[pd_con_nnmf.Stim==sc, hl]/h_max[sc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_con_nnmf= pd_con_nnmf.drop(columns=['nH3', 'nH2', 'nH1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,12))\n",
    "plt.suptitle('normalized H fluctuation across time, all trials ')\n",
    "gs    = fig.add_gridspec(len(H_col),1)\n",
    "i =0\n",
    "for hl in H_col:\n",
    "    fig.add_subplot(gs[i,0])\n",
    "    plt.title(hl, fontsize=15)\n",
    "    data_plot = pd_con_nnmf[pd_con_nnmf['n'+hl]>0.1]\n",
    "    plt.scatter(data_plot.Block,data_plot['n'+hl], alpha = 0.3)\n",
    "    plt.plot(np.unique(data_plot.Block), data_plot.groupby(['Block'])['n'+hl].mean() , color=[0,0,0])\n",
    "    #plt.xlim([0,3])\n",
    "    plt.ylabel('normalized H by stim specific max')\n",
    "    i = i+1\n",
    "plt.xlabel('Block Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,12))\n",
    "plt.suptitle('normalized H fluctuation across time, all trials ')\n",
    "gs    = fig.add_gridspec(len(H_col),1)\n",
    "i =0\n",
    "for hl in H_col:\n",
    "    fig.add_subplot(gs[i,0])\n",
    "    plt.title(hl, fontsize=15)\n",
    "    data_plot = pd_con_nnmf[pd_con_nnmf['n'+hl]>0.1]\n",
    "    plt.scatter(data_plot.Num,data_plot['n'+hl], alpha = 0.3)\n",
    "    #plt.plot(np.unique(data_plot.Num), data_plot.groupby(['Num'])['n'+hl].mean() , color=[0,0,0])\n",
    "    #plt.xlim([0,3])\n",
    "    i = i+1\n",
    "plt.xlabel('Trials')\n",
    "#plt.xlabel('Block Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,17))\n",
    "plt.suptitle('Finding stim channels associated to Activiation functions: H mean')\n",
    "gs    = fig.add_gridspec(1,len(H_col))\n",
    "i =0\n",
    "for hl in H_col:\n",
    "    fig.add_subplot(gs[0,i])\n",
    "    plt.title(hl, fontsize=15)\n",
    "    plt.errorbar( pd_con_nnmf.groupby(['Stim'])[hl].mean().values,np.unique(pd_con_nnmf.Stim), xerr=pd_con_nnmf.groupby(['Stim'])[hl].std().values, fmt='o')\n",
    "    #plt.scatter( pd_con_nnmf[hl],pd_con_nnmf.Stim, alpha = 0.3)\n",
    "    if i ==0:\n",
    "        plt.yticks(np.arange(len(labels_all)), labels_all)\n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    plt.axvline(np.median(pd_con_nnmf[hl]), color=[0,0,0])\n",
    "    #plt.axvline(np.median(pd_con_nnmf[hl])+np.std(pd_con_nnmf[hl]), color=[0,0,0])\n",
    "    plt.xlim([0,4])\n",
    "    i = i+1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-trout",
   "metadata": {},
   "source": [
    "fig = plt.figure(figsize=(20,2))\n",
    "hl = 'H1'\n",
    "dat_plot = pd_con_nnmf[(pd_con_nnmf.Stim==9)]\n",
    "plt.scatter(dat_plot.Block,dat_plot[hl], alpha = 1)\n",
    "\n",
    "plt.xlabel('Block Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-heating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,12))\n",
    "plt.suptitle('H fluctuation across time,all trials ')\n",
    "gs    = fig.add_gridspec(len(H_col),1)\n",
    "i =0\n",
    "for hl in H_col:\n",
    "    fig.add_subplot(gs[i,0])\n",
    "    plt.title(hl, fontsize=15)\n",
    "    plt.scatter(pd_con_nnmf.Block,pd_con_nnmf[hl], alpha = 0.3)\n",
    "    #plt.xlim([0,3])\n",
    "    i = i+1\n",
    "plt.xlabel('Block Number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-patrick",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(rk*2+2,17))\n",
    "plt.suptitle('Finding stim channels associated to Activiation functions: H STD')\n",
    "gs    = fig.add_gridspec(1,len(H_col))\n",
    "i =0\n",
    "for hl in H_col:\n",
    "    fig.add_subplot(gs[0,i])\n",
    "    plt.title(hl, fontsize=15)\n",
    "    plt.scatter( pd_con_nnmf.groupby(['Stim'])[hl].std().values,np.unique(pd_con_nnmf.Stim))\n",
    "    #plt.scatter( pd_con_nnmf[hl],pd_con_nnmf.Stim, alpha = 0.3)\n",
    "    if i ==0:\n",
    "        plt.yticks(np.arange(len(labels_all)), labels_all)\n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    plt.axvline(np.median(pd_con_nnmf.groupby(['Stim'])[hl].std().values), color=[0,0,0])\n",
    "    #plt.xlim([0,3])\n",
    "    i = i+1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-restoration",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,17))\n",
    "plt.suptitle('Finding stim channels associated to Activiation functions: H mean')\n",
    "gs    = fig.add_gridspec(1,len(H_col))\n",
    "i =0\n",
    "for hl in H_col:\n",
    "    fig.add_subplot(gs[0,i])\n",
    "    plt.title(hl, fontsize=15)\n",
    "    plt.errorbar( pd_con_nnmf.groupby(['Stim'])[hl].mean().values,np.unique(pd_con_nnmf.Stim), xerr=pd_con_nnmf.groupby(['Stim'])[hl].std().values, fmt='o')\n",
    "    #plt.scatter( pd_con_nnmf[hl],pd_con_nnmf.Stim, alpha = 0.3)\n",
    "    if i ==0:\n",
    "        plt.yticks(np.arange(len(labels_all)), labels_all)\n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    plt.axvline(np.median(pd_con_nnmf[hl]), color=[0,0,0])\n",
    "    #plt.axvline(np.median(pd_con_nnmf[hl])+np.std(pd_con_nnmf[hl]), color=[0,0,0])\n",
    "    plt.xlim([0,4])\n",
    "    i = i+1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMFf.plot_W(np.delete(W, bad_region, 0),  'Basic Function', ylabels = labels_clean, file=0)\n",
    "NMFf.plot_H(H,  'Activation Function', file=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-welding",
   "metadata": {},
   "source": [
    "## BM connectivity plots on mean of LL trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-economy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_BM_CR_trial(M, labels,areas, label, t):\n",
    "    time        = str(t).zfill(2)+':00'\n",
    "    fig      = plt.figure(figsize=(15,15))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, aspect='auto', origin='lower',cmap='hot', vmin=2, vmax= 15)\n",
    "    plt.xlim([-1.5, len(labels)-0.5])\n",
    "    plt.ylim([-0.5, len(labels)+0.5])\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90);\n",
    "    plt.yticks(range(len(labels)), labels);\n",
    "    for i in range(len(labels)):\n",
    "        r         = areas[i]\n",
    "        axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "        axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.04,0.85,0.08,0.08]) # x, y, x_len, y_len\n",
    "    circle1 = plt.Circle((0.5,0.5), 0.4, color = CR_color[t], alpha = CR_color_a[t])\n",
    "    plt.text(0.3,0.3, time)\n",
    "    plt.axis('off')\n",
    "    axcolor.add_patch(circle1)\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(label+', '+time+ '-- mean LL')\n",
    "    #plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/BM_plot/BM_'+label+'.svg')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/BM_plot_trial/BM_'+label+'.jpg')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/BM_plot_trial/GIF/BM_'+label+'.jpg')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-heart",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i =0\n",
    "for b in np.unique(con_trial.Block):\n",
    "    summ = con_trial[(con_trial.Sig_block_surr==1)&(con_trial.Sig_block==1)&(con_trial.Block==b)]\n",
    "    summ = summ.groupby(['Stim', 'Chan'], as_index=False)['LL_peak'].mean()#summ[summ.Sig_block>3]\n",
    "    t = np.bincount(con_trial.loc[con_trial.Block==b, 'Hour']).argmax()\n",
    "    M = np.zeros((len(labels_all),len(labels_all)))\n",
    "    for sc in np.unique(summ.Stim).astype('int'):\n",
    "        chan =summ.loc[summ.Stim==sc, 'Chan'].values.astype('int')\n",
    "        LL =summ.loc[summ.Stim==sc, 'LL_peak'].values\n",
    "        M[sc,chan] = LL\n",
    "    M = np.nan_to_num(M)\n",
    "    # BM plot\n",
    "    labels_sel   = np.delete(labels_all, bad_region, 0)\n",
    "    areas_sel    = np.delete(labels_region, bad_region, 0)\n",
    "    M_resp       = np.delete(np.delete(M, bad_region, 0), bad_region, 1)\n",
    "\n",
    "    # sort\n",
    "    ind = np.argsort(areas_sel)\n",
    "    M_resp= M_resp[ind,:]\n",
    "    M_resp = M_resp[:,ind]\n",
    "    labels_sel = labels_sel[ind]\n",
    "    areas_sel = areas_sel[ind]\n",
    "    if i==0:\n",
    "        M_all = M_resp\n",
    "    elif i==1:\n",
    "        M_all = np.stack([M_all, M_resp],0)\n",
    "    else:\n",
    "        M_all = np.concatenate([M_all,np.expand_dims(M_resp,0)],0)\n",
    "    ll = 'BM'+str(int(b)).zfill(2)\n",
    "    plot_BM_CR_trial_sig(M_resp, labels_sel,areas_sel, ll, t)\n",
    "    i = i+1\n",
    "np.save(path_patient + '/Analysis/BrainMapping/CR/data/BM_all_trial_sig.npy', M_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-retreat",
   "metadata": {},
   "source": [
    "## Classic Brain Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial.loc[np.isnan(con_trial.LL), 'LL_peak'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-triumph",
   "metadata": {},
   "outputs": [],
   "source": [
    "#con_trial_block.insert(6, 'Prot', t)\n",
    "block_l = files_list[l][-11:-4]\n",
    "file = path_patient + '/Analysis/BrainMapping/' + cond_folder + '/data/con_trial_'+block_l+'.csv'\n",
    "con_trial_block.to_csv(file, index=False, header=True)\n",
    "file = path_patient + '/Analysis/BrainMapping/' + cond_folder + '/data/con_mean_'+block_l+'.csv'\n",
    "con_mean_cond.to_csv(file, index=False, header=True)\n",
    "# todo: remobe WM, etc.\n",
    "if l ==0:\n",
    "    con_trial = con_trial_block\n",
    "    BM_all = M_resp\n",
    "elif l ==1:\n",
    "    con_trial = pd.concat([con_trial, con_trial_block])\n",
    "    BM_all = np.stack([BM_all,M_resp], 0)\n",
    "else:\n",
    "    con_trial = pd.concat([con_trial, con_trial_block])\n",
    "    BM_all = np.concatenate([BM_all,np.expand_dims(M_resp,0)], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial.to_csv(path_patient + '/Analysis/BrainMapping/CR/data/con_trial_all.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_patient + '/Analysis/BrainMapping/CR/data/BM_all.npy', BM_all)\n",
    "con_trial.to_csv(path_patient + '/Analysis/BrainMapping/CR/data/con_trial_all.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(1.5*Fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SigCon_BM_trial_block(LL_CCEP, EEG_resp, labels_all):\n",
    "    # cond_sel: either Condition or Hour\n",
    "    Fs = 500\n",
    "    t_0 = 1\n",
    "    M_resp = np.zeros((len(labels_all), len(labels_all), 3)) - 1\n",
    "    # (LL_CCEP[cond_sel]==cond_val)\n",
    "    resp_mean = np.zeros((1, 7))\n",
    "    for rc in tqdm.tqdm(range(len(labels_all))):  # for each response channel\n",
    "        for sc in range(len(labels_all)):  # for each stim channel\n",
    "            lists = LL_CCEP[(LL_CCEP['Chan'] == rc) & (LL_CCEP['Stim'] == sc)]\n",
    "            d = np.mean(\n",
    "                LL_CCEP.loc[(LL_CCEP['Chan'] == rc) & (LL_CCEP['Stim'] == sc), 'd'])\n",
    "            lists = lists[~np.isnan(lists.LL.values)]\n",
    "            stimNum_all = lists.Num.values.astype('int')\n",
    "            val = np.zeros((1, 7))\n",
    "            val[0, 0:3] = [rc, sc, d]\n",
    "            if len(stimNum_all) > 0:\n",
    "\n",
    "                resp_z = bf.zscore_CCEP(ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs))\n",
    "                mx = np.max(abs(resp_z[int(Fs):int(1.5*Fs)]))\n",
    "\n",
    "                LL_CCEP.loc[\n",
    "                        (LL_CCEP.Chan == rc) & (LL_CCEP.Stim == sc), 'Sig_block'] = mx\n",
    "            else:\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan == rc) & (LL_CCEP.Stim == sc), 'Sig_block'] = -1\n",
    "\n",
    "\n",
    "    return LL_CCEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "file    = path_patient + '/Analysis/BrainMapping/' + cond_folder + '/data/con_trial_'+block_l+'.csv'\n",
    "con_trial_block = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SigCon_BM_trial_block(LL_CCEP, EEG_resp, labels_all):\n",
    "    # cond_sel: either Condition or Hour\n",
    "    Fs = 500\n",
    "    t_0 = 1\n",
    "    M_resp = np.zeros((len(labels_all), len(labels_all), 3)) - 1\n",
    "    # (LL_CCEP[cond_sel]==cond_val)\n",
    "    resp_mean = np.zeros((1, 7))\n",
    "    for rc in tqdm.tqdm(range(len(labels_all))):  # for each response channel\n",
    "        for sc in range(len(labels_all)):  # for each stim channel\n",
    "            lists = LL_CCEP[(LL_CCEP['Chan'] == rc) & (LL_CCEP['Stim'] == sc)]\n",
    "            d = np.mean(\n",
    "                LL_CCEP.loc[(LL_CCEP['Chan'] == rc) & (LL_CCEP['Stim'] == sc), 'd'])\n",
    "            lists = lists[~np.isnan(lists.LL.values)]\n",
    "            stimNum_all = lists.Num.values.astype('int')\n",
    "            val = np.zeros((1, 7))\n",
    "            val[0, 0:3] = [rc, sc, d]\n",
    "            if len(stimNum_all) > 0:\n",
    "\n",
    "                resp_z = bf.zscore_CCEP(ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs))\n",
    "                mx = np.max(abs(resp_z[int(1.01*Fs):int(1.4*Fs)]))\n",
    "\n",
    "                LL_CCEP.loc[\n",
    "                        (LL_CCEP.Chan == rc) & (LL_CCEP.Stim == sc), 'Sig_block'] = mx\n",
    "            else:\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan == rc) & (LL_CCEP.Stim == sc), 'Sig_block'] = -1\n",
    "\n",
    "\n",
    "    return LL_CCEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-buffer",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for l in range(0,len(files_list)):\n",
    "    print('loading '+files_list[l][-11:-4], end='\\r')\n",
    "    stimlist = pd.read_csv(files_list[l])\n",
    "    EEG_resp = np.load(path_patient + '/Analysis/' + folder + '/data/ALL_resps_'+files_list[l][-11:-4]+'.npy')\n",
    "    if EEG_resp.shape[1]!=len(stimlist):\n",
    "        print('ERROR number of stimulations is not correct')\n",
    "        break\n",
    "    else:\n",
    "        stimlist.StimNum = np.arange(len(stimlist))\n",
    "        t = stimlist.type.values[0]\n",
    "        #con_trial_block = BMf.LL_BM_cond(EEG_resp, stimlist, 'h', bad_chans, coord_all, labels_clinic, StimChanSM, StimChanIx)\n",
    "        block_l = files_list[l][-11:-4]\n",
    "        file    = path_patient + '/Analysis/BrainMapping/' + cond_folder + '/data/con_trial_'+block_l+'.csv'\n",
    "        con_trial_block = pd.read_csv(file)\n",
    "        con_trial_block = get_SigCon_BM_trial_block(con_trial_block, EEG_resp, labels_all)\n",
    "        con_trial_block.to_csv(file, index=False, header=True)\n",
    "        if l ==0:\n",
    "            con_trial = con_trial_block\n",
    "        else:\n",
    "            con_trial = pd.concat([con_trial, con_trial_block])\n",
    "\n",
    "con_trial.insert(9, 'Num_block', con_trial.Num)\n",
    "mx = 0 \n",
    "for b in np.unique(con_trial.Block):\n",
    "    con_trial.loc[(con_trial.Block==b), 'Num'] = con_trial.loc[(con_trial.Block==b), 'Num_block']+mx\n",
    "    mx = np.max(con_trial.loc[(con_trial.Block==b), 'Num'])   \n",
    "#con_trial.to_csv(path_patient + '/Analysis/BrainMapping/CR/data/con_trial_all.csv', index=False, header=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial.insert(9, 'Num_block', con_trial.Num)\n",
    "mx = 0 \n",
    "for b in np.unique(con_trial.Block):\n",
    "    con_trial.loc[(con_trial.Block==b), 'Num'] = con_trial.loc[(con_trial.Block==b), 'Num_block']+mx\n",
    "    mx = np.max(con_trial.loc[(con_trial.Block==b), 'Num'])   \n",
    "con_trial.to_csv(path_patient + '/Analysis/BrainMapping/CR/data/con_trial_all.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-convert",
   "metadata": {},
   "source": [
    "## Test differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean(sc, rc, LL_CCEP,EEG_resp, labels ):\n",
    "    t_0    = 1\n",
    "    lists  = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)&(~np.isnan(LL_CCEP.LL.values))] #\n",
    "    h = np.unique(lists.Hour)[0].astype('int')\n",
    "    b = np.unique(lists.Block)[0].astype('int')\n",
    "    fig   = plt.figure(figsize=(12,7) )\n",
    "    #plt.title(labels_all[Stim_chs]+' -- '+labels_clinic[rc])\n",
    "    #plt.title(labels[sc]+' -- '+labels[rc])\n",
    "    plt.title(labels[sc]+' -- '+labels[rc]+', Dist: '+str(np.round(lists.d.values[0]))+'mm, '+f\"{h:02}\"+\":00\")\n",
    "    \n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    plt.xlabel('time [s]')\n",
    "    #plt.text(-0.37, 200, 'LL: '+str(np.round(np.mean(lists.LLpeak),2))+'uV/ms (of mean)', c=[0,0,0])\n",
    "    \n",
    "    ylim = 1000\n",
    "\n",
    "    #stim_spec                = stimlist[(stimlist.condition>0)&(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "    stimNum_all                  = lists.Num_block.values.astype('int')\n",
    "    for i in range(len(stimNum_all)):\n",
    "        ylim =np.max([ylim, np.max(abs(ff.lp_filter(EEG_resp[rc,stimNum_all[i],Fs:int(1.5*Fs)],45,Fs)))])\n",
    "        plt.plot(x_ax,ff.lp_filter(EEG_resp[rc,stimNum_all[i],:],45,Fs), c=color_elab[0], linewidth=1)\n",
    "    mn = ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "    st  = np.std(ff.lp_filter(EEG_resp[rc,stimNum_all,:],45,Fs),0)\n",
    "    plt.plot(x_ax,mn, c=[0,0,0], linewidth=3, label='mean, n='+str(len(stimNum_all)))\n",
    "    plt.fill_between(x_ax, mn-st, mn+st, color=color_elab[0], alpha= 0.3)\n",
    "    plt.xlim([-0.6,1])\n",
    "    plt.ylim([-np.max([ylim*1.071,300]),np.max([ylim*1.071,300])])\n",
    "    #plt.axvspan(t_0+w_r-1, t_0-1+w_LL, alpha=0.3, color=color_elab[0])\n",
    "    #plt.axvspan(t_0+0.015-1, t_0+w_r-1, alpha=0.8, color=color_elab[1])\n",
    "    #plt.axvspan(t_0+0.015-1-0.2, t_0+w_r-1-0.2, alpha=0.8, color=color_elab[1])\n",
    "    plt.ylabel('[\\u03BCV]', fontsize=18) #\\u0394 delta\n",
    "    plt.xlabel('time [s]', fontsize=18)\n",
    "    plt.legend()\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/'+cond_folder+'/figures/single_con/BM_'+str(b)+'_'+labels_all[sc]+'_'+labels_all[rc]+'.svg')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/'+cond_folder+'/figures/single_con/BM_'+str(b)+'_'+labels_all[sc]+'_'+labels_all[rc]+'.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-story",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_zscore(sc, rc, LL_CCEP,EEG_resp, labels ):\n",
    "    t_0    = 1\n",
    "    lists  = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)&(~np.isnan(LL_CCEP.LL.values))] #&(~np.isnan(LL_CCEP.LL.values))\n",
    "    h = np.unique(lists.Hour)[0].astype('int')\n",
    "    b = np.unique(lists.Block)[0].astype('int')\n",
    "    fig   = plt.figure(figsize=(12,7) )\n",
    "    #plt.title(labels_all[Stim_chs]+' -- '+labels_clinic[rc])\n",
    "    #plt.title(labels[sc]+' -- '+labels[rc])\n",
    "    plt.title(labels[sc]+' -- '+labels[rc]+', Dist: '+str(np.round(lists.d.values[0]))+'mm, '+f\"{h:02}\"+\":00\")\n",
    "    \n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    plt.xlabel('time [s]')\n",
    "    #plt.text(-0.37, 200, 'LL: '+str(np.round(np.mean(lists.LLpeak),2))+'uV/ms (of mean)', c=[0,0,0])\n",
    "    \n",
    "    ylim = 1000\n",
    "\n",
    "    #stim_spec                = stimlist[(stimlist.condition>0)&(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "    stimNum_all                  = lists.Num_block.values.astype('int')\n",
    "    for i in range(len(stimNum_all)):\n",
    "        ylim =np.max([ylim, np.max(abs(ff.lp_filter(EEG_resp[rc,stimNum_all[i],Fs:int(1.5*Fs)],45,Fs)))])\n",
    "        resp = ff.lp_filter(bf.zscore_CCEP(EEG_resp[rc,stimNum_all[i],:]),45,Fs)\n",
    "        plt.plot(x_ax,resp, c=color_elab[0], linewidth=1, label='trial'+str(i+1))\n",
    "    plt.plot(x_ax,ff.lp_filter(np.mean(bf.zscore_CCEP(EEG_resp[rc,stimNum_all,:]),0),45,Fs), c=[0,0,0], linewidth=2, label='mean, n='+str(len(stimNum_all)))\n",
    "    plt.plot(x_ax,bf.zscore_CCEP(ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs)), c=[1,0,0], linewidth=2, label='mean, n='+str(len(stimNum_all)))\n",
    "\n",
    "    plt.xlim([-0.5,1])\n",
    "    plt.ylim([-6,6])\n",
    "    #plt.axvspan(t_0+w_r-1, t_0-1+w_LL, alpha=0.3, color=color_elab[0])\n",
    "    #plt.axvspan(t_0+0.015-1, t_0+w_r-1, alpha=0.8, color=color_elab[1])\n",
    "    #plt.axvspan(t_0+0.015-1-0.2, t_0+w_r-1-0.2, alpha=0.8, color=color_elab[1])\n",
    "    plt.legend()\n",
    "    #plt.savefig()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-hughes",
   "metadata": {},
   "source": [
    "### BZD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "l =0\n",
    "stimlist_BL= pd.read_csv(files_list[l])\n",
    "EEG_resp_BL= np.load(path_patient + '/Analysis/' + folder + '/data/ALL_resps_'+files_list[l][-11:-4]+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "l =1\n",
    "stimlist_BZD= pd.read_csv(files_list[l])\n",
    "EEG_resp_BZD= np.load(path_patient + '/Analysis/' + folder + '/data/ALL_resps_'+files_list[l][-11:-4]+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = con_trial[(con_trial.LL>0)&(con_trial.Sig_block_surr ==1)&(con_trial.Sig_block>5)]\n",
    "summ = summ.groupby(['Stim', 'Chan', 'Block'], as_index=False)['LL_peak'].mean()#summ[summ.Sig_block>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial[(con_trial.LL>0)&(con_trial.Stim ==sc)&(con_trial.Chan==rc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-medium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_mean_zscore(sc, rc, con_trial[con_trial.Block==1], EEG_resp_BL, labels_all)\n",
    "plot_mean_zscore(sc, rc, con_trial[con_trial.Block==3],EEG_resp_BZD, labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 78\n",
    "rc = 67\n",
    "plot_mean(sc, rc, con_trial[con_trial.Block==1], EEG_resp_BL, labels_all)\n",
    "plot_mean(sc, rc, con_trial[con_trial.Block==3],EEG_resp_BZD, labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-things",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 12\n",
    "rc = 57\n",
    "plot_mean(sc, rc, con_trial[con_trial.Block==1], EEG_resp_BL, labels_all)\n",
    "plot_mean(sc, rc, con_trial[con_trial.Block==3],EEG_resp_BZD, labels_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-complement",
   "metadata": {},
   "source": [
    "### CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 9\n",
    "print('loading '+files_list[l][-11:-4], end='\\r')\n",
    "stimlist_9 = pd.read_csv(files_list[l])\n",
    "EEG_resp_9 = np.load(path_patient + '/Analysis/' + folder + '/data/ALL_resps_'+files_list[l][-11:-4]+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 22\n",
    "print('loading '+files_list[l][-11:-4], end='\\r')\n",
    "stimlist_22 = pd.read_csv(files_list[l])\n",
    "EEG_resp_22 = np.load(path_patient + '/Analysis/' + folder + '/data/ALL_resps_'+files_list[l][-11:-4]+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_mean_zscore(sc, rc, con_trial[con_trial.Block==0], EEG_resp_9, labels_all)\n",
    "plot_mean_zscore(sc, rc, con_trial[con_trial.Block==9],EEG_resp_22, labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-residence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 18\n",
    "rc = 65\n",
    "plot_mean(sc, rc, con_trial[con_trial.Block==9], EEG_resp_9, labels_all)\n",
    "plot_mean(sc, rc, con_trial[con_trial.Block==22],EEG_resp_22, labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 19\n",
    "rc = 65\n",
    "plot_mean(sc, rc, con_trial[con_trial.Block==9],EEG_resp_9, labels_all)\n",
    "plot_mean(sc, rc, con_trial[con_trial.Block==22],EEG_resp_22, labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf.zscore_CCEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-fortune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "'single_con'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-faculty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_labels = []\n",
    "for i in range(24):\n",
    "    CR_labels.append(f\"{i:02}\"+\":00\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reliable-columbus",
   "metadata": {},
   "source": [
    "# Connectivvity correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-deployment",
   "metadata": {},
   "source": [
    "## concat con_trial tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.random.randint(0,50, (3,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(test, 99, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan, trial = np.where(np.max(abs(EEG_resp[:, :, int(0.98 * Fs):int(1.02 * Fs)]), 2) > 2000)\n",
    "for i in range(len(trial)):\n",
    "    con_trial_block.loc[\n",
    "        (con_trial_block.Chan == chan[i]) & (con_trial_block.Num == trial[i]), 'LL'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-bedroom",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for l in range(0,len(files_list)):\n",
    "    print('loading '+files_list[l][-11:-4], end='\\r')\n",
    "    stimlist = pd.read_csv(files_list[l])\n",
    "    EEG_resp = np.load(path_patient + '/Analysis/' + folder + '/data/ALL_resps_'+files_list[l][-11:-4]+'.npy')\n",
    "    if EEG_resp.shape[1]!=len(stimlist):\n",
    "        print('ERROR number of stimulations is not correct')\n",
    "        break\n",
    "    else:\n",
    "        stimlist.StimNum = np.arange(len(stimlist))\n",
    "        t = stimlist.type.values[0]\n",
    "        con_trial_block = BMf.LL_BM_cond(EEG_resp, stimlist, 'h', bad_chans, coord_all, labels_clinic, StimChanSM, StimChanIx)\n",
    "        \n",
    "        # remove bad channels and stim channels (nan values)\n",
    "        con_trial_block = con_trial_block[con_trial_block.LL>0]\n",
    "        # con_trial_block = remove_art(EEG_resp, con_trial_block)\n",
    "        # remove trials that have artefacts (high voltage values)\n",
    "        chan, trial = np.where(np.max(abs(EEG_resp), 2) > 2000)\n",
    "        for i in range(len(trial)):\n",
    "            con_trial_block.loc[(con_trial_block.Chan == chan[i]) & (con_trial_block.Num == trial[i]), 'LL'] = np.nan\n",
    "        con_trial_block = con_trial_block[~ np.isin(con_trial_block.Chan, bad_region)]\n",
    "        #con_trial_block = con_trial_block[con_trial_block.d>7]\n",
    "        #\n",
    "        con_trial_block, con_mean_cond, M_resp = BMf.get_SigCon_BM_block(con_trial_block, EEG_resp, labels_all, chan_thr)\n",
    "        # BM plot\n",
    "        labels_sel   = np.delete(labels_all, bad_region, 0)\n",
    "        areas_sel    = np.delete(labels_region, bad_region, 0)\n",
    "        M_resp       = np.delete(np.delete(M_resp[:,:,2], bad_region, 0), bad_region, 1)\n",
    "        \n",
    "        # sort\n",
    "        ind = np.argsort(areas_sel)\n",
    "        M_resp= M_resp[ind,:]\n",
    "        M_resp = M_resp[:,ind]\n",
    "        labels_sel = labels_sel[ind]\n",
    "        areas_sel = areas_sel[ind]\n",
    "\n",
    "        t = np.bincount(stimlist.h).argmax()\n",
    "        plot_BM_CR(M_resp, labels_sel, areas_sel, files_list[l][-8:-4], t)\n",
    "        con_trial_block.insert(6, 'Prot', t)\n",
    "        # todo: remobe WM, etc.\n",
    "        if l ==0:\n",
    "            con_trial = con_trial_block\n",
    "            BM_all = M_resp\n",
    "        elif l ==1:\n",
    "            con_trial = pd.concat([con_trial, con_trial_block])\n",
    "            BM_all = np.stack([BM_all,M_resp], 0)\n",
    "        else:\n",
    "            con_trial = pd.concat([con_trial, con_trial_block])\n",
    "            BM_all = np.concatenate([BM_all,np.expand_dims(M_resp,0)], 0)\n",
    "#con_trial = remove_art(EEG_resp, con_trial)\n",
    "np.save(path_patient + '/Analysis/BrainMapping/CR/data/BM_all.npy', BM_all)\n",
    "con_trial.to_csv(path_patient + '/Analysis/BrainMapping/CR/data/con_trial_block.csv', index=False, header=True)\n",
    "#np.save(path_patient + '/Analysis/BrainMapping/CR/data/con_trial_block.npy', con_trial)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(Mh_flat.T)\n",
    "corr= df.corr().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as spc\n",
    "from scipy.spatial import distance\n",
    "\n",
    "pdist = spc.distance.pdist(corr)\n",
    "linkage = spc.linkage(pdist, method='complete')\n",
    "idx = spc.fcluster(linkage, 0.5 * pdist.max(), 'distance')\n",
    "\n",
    "\n",
    "Mh    = np.copy(M_all)\n",
    "Mh[np.where(Mh==-1)] = np.nan\n",
    "Mh_flat    = Mh.reshape(Mh.shape[0],Mh.shape[1]*Mh.shape[2]) #\n",
    "\n",
    "delta = 0\n",
    "Mh    = np.copy(BM_all)\n",
    "Mh[np.where(Mh==-1)] = np.nan\n",
    "\n",
    "Mh_flat    = Mh.reshape(Mh.shape[0],Mh.shape[1]*Mh.shape[2]) #(70, 2916)\n",
    "# dist_flat  = distance.pdist(Mh_flat,'hamming') #(2415,)\n",
    "# M          = np.zeros((Mh.shape[0],Mh.shape[0]))\n",
    "# for i in range(Mh.shape[0]):\n",
    "#     for j in range(Mh.shape[0]):\n",
    "#         M[i,j] = dist_flat[int(Mh.shape[0] * i + j - ((i + 2) * (i + 1)) // 2)]\n",
    "x_block = np.unique(con_trial.Block)[np.arange(0, len(Mh_flat),len(Mh_flat)/5).astype('int')]\n",
    "#np.arange(1, len(Mh_flat),4)\n",
    "x_hour =[]\n",
    "for b in x_block:\n",
    "    x_raw = np.bincount(con_trial.loc[con_trial.Block==b, 'Hour']).argmax()\n",
    "    x_hour.append(f\"{x_raw:02}\"+\":00\")\n",
    "    \n",
    "plot_correleation_BM(Mh_flat, binary=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-puzzle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-helen",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_correleation_BM(Mh_flat, binary=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-torture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-pension",
   "metadata": {},
   "source": [
    "## LL and Significant responses "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-candidate",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "exp         = 1\n",
    "w           = 0.25\n",
    "LL_CCEP     = pd.read_csv(path_patient + '/Analysis/BrainMapping/LL/CCEP_'+str(exp)+'_'+str(w)+'s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-thomas",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_thr    = pd.read_csv('T:\\EL_experiment\\Patients\\EL009/Analysis/BrainMapping/LL/chan_sig_thr_BL.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-cleaners",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w           = 0.25\n",
    "LL_CCEP     = pd.read_csv(path_patient + '/Analysis/BrainMapping/LL/CCEP_'+str(w)+'s.csv')\n",
    "chan_thr    = pd.read_csv('T:\\EL_experiment\\Patients\\EL009/Analysis/BrainMapping/Ph/data/chan_sig_thr_BL.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_r    = 0.1\n",
    "w_LL   = 0.25\n",
    "t_0    = 1 # time of stimulation in data\n",
    "t_0s   = 0.5 # time of surr stim\n",
    "t_Bl   = 0.5\n",
    "\n",
    "## calcualte mean CCEp and then take LL \n",
    "data_CCEP                = np.zeros((1,10))\n",
    "w                        = 0.25\n",
    "stim_spec                = stimlist[(stimlist.IPI_ms ==0)]#&(stimlist.noise ==0) #&(stimlist.noise ==0\n",
    "stimNum                  = stim_spec.StimNum.values#[:,0]\n",
    "resps                    = ff.lp_filter(EEG_resp[:,stimNum,:],45,Fs)\n",
    "ChanP1                   = bf.SM2IX(stim_spec.ChanP.values,StimChanSM,np.array(StimChanIx))\n",
    "LL_all       = LL_funcs.get_LL_both(data=resps, Fs=Fs, IPI=np.zeros((len(stimNum),1)), t_0=t_0, win=w_LL)\n",
    "LL_r         = LL_funcs.get_LL_ratio(data=resps, Fs=Fs, IPI=np.zeros((len(stimNum),1)),t_bl=t_0-0.2, t_stim=t_0, win=w_r)\n",
    "#LL_CCEP[sc, :, h, 0] = \n",
    "# remove Resp if rec channel was just stimulating before\n",
    "#stim_spec0                = stimlist[(stimlist.StimNum.isin((stim_spec.StimNum.values-1)[1:]))]\n",
    "#ChanP0                    = np.zeros((len(stimNum),))\n",
    "#ChanP0[1:]                = bf.SM2IX(stim_spec0.ChanP.values,StimChanSM,np.array(StimChanIx))\n",
    "\n",
    "for c in range(LL_all.shape[0]):\n",
    "    val         = np.zeros((LL_all.shape[1], 10))\n",
    "    val[:, 0]   = c                                         # response channel\n",
    "    val[:, 1]   = bf.SM2IX(stim_spec.ChanP.values,StimChanSM,np.array(StimChanIx)) #stim Chan, in all labels\n",
    "    val[:, 2]   = LL_all[c,:,1] ## LL absolute\n",
    "    val[:, 3]   = stimNum\n",
    "    val[:, 4]   = LL_r[c,:,1]\n",
    "    val[:, 6]   = stim_spec.h.values\n",
    "    #val[:, 7]   = stim_spec.condition.values\n",
    "    val[:, 8]   = stim_spec.Int_prob.values\n",
    "    val[np.where(bf.check_inStimChan(c, ChanP1, labels_clinic)==1),2] = np.nan\n",
    "    val[np.where(bf.check_inStimChan(c, ChanP1, labels_clinic)==1),4] = np.nan\n",
    "\n",
    "    # #ix         = np.where(np.max(abs(resps[c,:,np.int64(0.95*Fs):np.int64(1.01*Fs)]),1)>400)\n",
    "    # pks         = np.max(abs(resps[c,:,np.int64(0.95*Fs):np.int64(1.5*Fs)]),1)\n",
    "    # pks_loc     = np.argmax(abs(resps[c,:,np.int64(0.95*Fs):np.int64(1.5*Fs)]),1)+np.int64(0.95*Fs)\n",
    "    # #ix         = np.where(np.max(abs(resps[c,:,np.int64(0.95*Fs):np.int64(1.01*Fs)]),1)>400)\n",
    "    # ix          = np.where((pks>200)&(pks_loc>np.int64(0.955*Fs))&(pks_loc<np.int64(1.012*Fs)))\n",
    "    # val[ix, 2] = np.nan\n",
    "    # val[ix, 4] = np.nan\n",
    "    # \n",
    "    # voltage_rec = np.percentile(abs(resps[c,:,0:np.int64(1*Fs)]),90,1)\n",
    "    # ix          = np.where(voltage_rec>500)\n",
    "    # val[ix, 2]  = np.nan\n",
    "    # val[ix, 4]  = np.nan\n",
    "    # #val[ix, 8] = np.nan\n",
    "    # #val[ix, 9] = np.nan\n",
    "    data_CCEP    = np.concatenate((data_CCEP, val), axis=0)\n",
    "\n",
    "data_CCEP = data_CCEP[1:-1, :] # remove first row (dummy row)\n",
    "\n",
    "#LL_CCEP = pd.DataFrame(\n",
    "#    {\"Chan\": data_CCEP[:, 0], \"Stim\": data_CCEP[:, 1], \"LL\": data_CCEP[:, 2],\"d\": data_CCEP[:, 5],\"rLL\": data_CCEP[:, 4],\"zLL\": data_CCEP[:, 4],\"mx\": data_CCEP[:, 8],\"mx/std\": data_CCEP[:, 9],\"Day\": data_CCEP[:, 7],\"Hour\": data_CCEP[:, 6],\"Num\": data_CCEP[:, 3]})\n",
    "#\n",
    "LL_CCEP = pd.DataFrame(\n",
    "    {\"Chan\": data_CCEP[:, 0], \"Stim\": data_CCEP[:, 1], \"Int\": data_CCEP[:, 8], \"LL\": data_CCEP[:, 2],\"d\": data_CCEP[:, 5],\"rLL\": data_CCEP[:, 4],\"zLL\": data_CCEP[:, 4],\"Condition\": data_CCEP[:, 7],\"Hour\": data_CCEP[:, 6],\"Num\": data_CCEP[:, 3]})\n",
    "\n",
    "LL_CCEP.loc[LL_CCEP['Chan'].isin(bad_chans), 'LL'] = np.nan\n",
    "LL_CCEP.loc[LL_CCEP['Stim'].isin(bad_stims), 'LL'] = np.nan\n",
    "\n",
    "\n",
    "##Z-score absolute\n",
    "LL_BL_z   = np.zeros((len(labels_all),2))\n",
    "LL_all_BL       = LL_funcs.get_LL_both(data=resps, Fs=Fs, IPI=np.zeros((len(stimNum),1)), t_0=t_Bl, win=w_LL)\n",
    "LL_BL_z[:,0] = np.nanmean(LL_all_BL[:,:,1],1)\n",
    "LL_BL_z[:,1] = np.nanstd(LL_all_BL[:,:,1],1)\n",
    "for rc in range(len(labels_all)):\n",
    "    LL_CCEP.loc[(LL_CCEP.Chan ==rc), 'zLL'] = (LL_CCEP.loc[(LL_CCEP.Chan ==rc), 'LL']- LL_BL_z[rc,0])/LL_BL_z[rc,1]\n",
    "\n",
    "# distance\n",
    "for i in range(len(StimChans)):\n",
    "    ChanP = StimChanSM[i]\n",
    "    s   = np.where(labels_all == StimChans[i])[0][0]#i#np.int(StimChanNums[i]) \n",
    "    s   = np.int64(s)\n",
    "    for c in np.unique(LL_CCEP.Chan):\n",
    "        c   = np.int64(c)\n",
    "        LL_CCEP.loc[(LL_CCEP.Stim == s)&(LL_CCEP.Chan == c), 'd'] = math.sqrt(((coord_all[s,0]-coord_all[c,0])**2)+((coord_all[s,1]-coord_all[c,1])**2)+((coord_all[s,2]-coord_all[c,2])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_color = pd.read_excel(\"T:\\EL_experiment\\Patients\\\\\" +'all'+\"\\Analysis\\BrainMapping\\CR_color.xlsx\", header=0)\n",
    "CR_color_a = CR_color.a.values\n",
    "CR_color = CR_color.c.values\n",
    "CR_color = np.zeros((24,3))\n",
    "CR_color[6:18,:] =np.array([253, 184, 19 ])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vietnamese-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_BM_CR(M, labels,areas, label, t):\n",
    "    time        = str(t).zfill(2)+':00'\n",
    "    fig      = plt.figure(figsize=(15,15))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, aspect='auto', origin='lower',cmap='hot', vmin=0, vmax= 20)\n",
    "    plt.xlim([-1.5, len(labels)-0.5])\n",
    "    plt.ylim([-0.5, len(labels)+0.5])\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90);\n",
    "    plt.yticks(range(len(labels)), labels);\n",
    "    for i in range(len(labels)):\n",
    "        r         = areas[i]\n",
    "        axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "        axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.04,0.85,0.08,0.08]) # x, y, x_len, y_len\n",
    "    circle1 = plt.Circle((0.5,0.5), 0.4, color = CR_color[c], alpha = CR_color_a[c])\n",
    "    plt.text(0.3,0.3, time)\n",
    "    plt.axis('off')\n",
    "    axcolor.add_patch(circle1)\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(t+ '-- LL z-score')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/BM_'+label+'.svg')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/BM_'+label+'.jpg')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/GIF/BM_'+label+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LL_thr(EEG_resp, LL_all, labels_all, path_patient, n_trial=3):\n",
    "    ## get threshoold value for each response channel (99th and 95h)\n",
    "    chan_thr = np.zeros((len(labels_all), 4))\n",
    "    for rc in range(len(labels_all)):\n",
    "        chan_thr[rc,:] = get_sig_thr(rc, LL_all, EEG_resp, n_trial)\n",
    "    data_A = pd.DataFrame(chan_thr, columns=['99', '95', 'std', 'mean'])\n",
    "    data_A.to_csv(path_patient + '/Analysis/BrainMapping/LL/chan_sig_thr_BL.csv', index=False,header=True)  # scat_plot = scat_plot.fillna(method='ffill')\n",
    "    print('Data stored')\n",
    "    print(path_patient + '/Analysis/BrainMapping/LL/chan_sig_thr_BL.csv')\n",
    "    return chan_thr\n",
    "def LL_mx(EEG_trial, Fs=500, w=0.25,t0=1.01):\n",
    "    # calculate mean response and get LL (incl peak)\n",
    "    resp           = ff.lp_filter(np.mean(EEG_trial,0),45,Fs)\n",
    "    LL_resp        = LL_funcs.get_LL_all(np.expand_dims(np.expand_dims(resp, axis=0),0), Fs, w, 1, 0)\n",
    "    LL_resp        = LL_resp[0,0]\n",
    "    mx             = np.max(LL_resp[np.int64((t0+w/2)*Fs):np.int64((t0+w)*Fs)])\n",
    "    mx_ix          = np.argmax(LL_resp[np.int64((t0+w/2)*Fs):np.int64((t0+w)*Fs)])\n",
    "    return mx, mx_ix, LL_resp\n",
    "\n",
    "def get_sig_thr(rc, LL_CCEP, EEG_resp, t_num, Fs=500,fig_path='no'):\n",
    "    # t_num = number of trials included for mean calculation, IO =3\n",
    "    BL_times       = np.concatenate([np.arange(0, 0.5, 0.01),np.arange(1.6, 2,0.01)])  # times wihtout stimulation, 0-0.5s, 1.6 - 2.5\n",
    "    n              = 300 # number of surrogates\n",
    "    LL_surr        = np.zeros((n, 1))\n",
    "    list_surr      = LL_CCEP[(LL_CCEP['d']>8)&(LL_CCEP['Chan']==rc)&~(LL_CCEP['Stim']==rc)&~np.isnan(LL_CCEP.LL.values)] # take BL when rc is not stimulating and not during noise\n",
    "    list_surr      = list_surr[~np.isnan(list_surr.LL.values)]\n",
    "    stimNum        = list_surr.Num.values.astype('int')\n",
    "    thr            = np.zeros(4,)\n",
    "    if len(stimNum)>0:\n",
    "        for k in range(n):\n",
    "            t0               = np.random.choice(np.round(BL_times,2))\n",
    "            stimNum_choice   = np.random.choice(stimNum, t_num)\n",
    "            EEG_trial        = EEG_resp[rc,stimNum_choice,np.int64((t0)*Fs):np.int64((t0+0.4)*Fs)]#np.flip(EEG_resp[rc,stimNum,:],1)\n",
    "            LL_surr[k,0],_,_ = LL_mx(EEG_trial, t0=0)\n",
    "\n",
    "        thr[0] = np.percentile(LL_surr[:,0],99)\n",
    "        thr[1] = np.percentile(LL_surr[:,0],95)\n",
    "        thr[2] = np.nanstd(LL_surr[:,0])\n",
    "        thr[3] = np.nanmean(LL_surr[:,0]) \n",
    "        if fig_path != 'no':\n",
    "            fig = plt.figure(figsize=(5,5))\n",
    "            plt.title('surrogates - '+labels_all[rc])\n",
    "            plt.hist(LL_surr[:,0])\n",
    "            plt.axvline(thr[0], c= [1,0,0], label='99%')\n",
    "            plt.axvline(thr[1], c= [1,0,0], label='90%')\n",
    "            plt.axvline(np.mean(LL_surr[:,0])+np.std(LL_surr[:,0]), c= [0,0,0], label='mean +std')\n",
    "            plt.xlabel('LL [250ms]')\n",
    "            plt.xlim([0,np.max([2,1.1*max(LL_surr[:,0])]) ])\n",
    "            plt.legend()\n",
    "            plt.savefig(fig_path)\n",
    "            plt.close(fig)    # close the figure window\n",
    "    return thr\n",
    "\n",
    "def get_SigCon_BM(LL_CCEP, EEG_resp, labels_all,chan_thr, Fs=500):\n",
    "    M_resp      = np.zeros((len(labels_all), len(labels_all),3))-1\n",
    "    #(LL_CCEP['Condition'].isin(cond))\n",
    "    for rc in tqdm.tqdm(range(len(labels_all))): # for each response channel\n",
    "        for sc in range(len(labels_all)): # for each stim channel\n",
    "            lists          = LL_CCEP[(LL_CCEP['Int']==3)&(LL_CCEP['Chan']==rc) & (LL_CCEP['Stim']==sc)]\n",
    "            lists          = lists[~np.isnan(lists.LL.values)]\n",
    "            stimNum_all    = lists.Num.values.astype('int')\n",
    "            if len(stimNum_all)>0:\n",
    "                EEG_trial      = EEG_resp[rc,stimNum_all,:]\n",
    "                mx,_,_         = LL_mx(EEG_trial)\n",
    "\n",
    "                if  mx>chan_thr[rc, 0]:\n",
    "                    M_resp[sc,rc,0] = mx\n",
    "                    M_resp[sc,rc,1] = 1\n",
    "                    M_resp[sc,rc,2] = (mx-chan_thr[rc,3])/chan_thr[rc, 2]\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = 1\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'LLpeak'] = mx\n",
    "                else:\n",
    "                    M_resp[sc,rc,:] = 0\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = 0\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'LLpeak'] = mx\n",
    "            else:\n",
    "                M_resp[sc,rc,:] = -1\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = -1\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'LLpeak'] = -1\n",
    "\n",
    "    LL_CCEP.to_csv(path_patient + '/Analysis/BrainMapping/LL/LL_all.csv', index=False,header=True)  # scat_plot = scat_plot.fillna(method='ffill')\n",
    "    return LL_CCEP, M_resp\n",
    "\n",
    "def plot_BM(M, labels,areas, t='BL', area = 0):\n",
    "    fig      = pylab.figure(figsize=(15,15))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, aspect='auto', origin='lower',cmap='hot', vmin=0, vmax= 20)\n",
    "    plt.xlim([-1.5, len(labels)-0.5])\n",
    "    plt.ylim([-0.5, len(labels)+0.5])\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90);\n",
    "    plt.yticks(range(len(labels)), labels);\n",
    "    if area>0:\n",
    "        for i in range(len(labels)):\n",
    "            r = areas[i]\n",
    "            axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "            axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(t+ '-- LL z-score')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/BM_'+t+'.svg')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/BM_'+t+'.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_thr  = get_LL_thr(EEG_resp, LL_CCEP, labels_all, path_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-throw",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LL_CCEP, M_resp_BL = get_SigCon_BM_cond(LL_CCEP, EEG_resp, labels_all,chan_thr, Fs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0,10,(3,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(a[:,1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sel   = np.delete(labels_clinic, bad_region, 0)\n",
    "#labels_sel   = np.delete(labels_all, bad_region, 0)\n",
    "areas_sel    = np.delete(labels_region, bad_region, 0)\n",
    "M            = np.delete(np.delete(M_resp_BL[:,:,2], bad_region, 0), bad_region, 1)\n",
    "# sort\n",
    "\n",
    "plot_BM(M, labels_sel, areas_sel, 'BL_Clinic',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "areas_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-clear",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(areas_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-scanner",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## delete WM\n",
    "# labels_sel   = np.delete(labels_clinic, bad_region, 0)\n",
    "labels_sel   = np.delete(labels_all, bad_region, 0)\n",
    "areas_sel    = np.delete(labels_region, bad_region, 0)\n",
    "M            = np.delete(np.delete(M_resp_BL[:,:,2], bad_region, 0), bad_region, 1)\n",
    "\n",
    "# sort\n",
    "ind = np.argsort(areas_sel)\n",
    "M = M[ind,:]\n",
    "M = M[:,ind]\n",
    "labels_sel = labels_sel[ind]\n",
    "areas_sel = areas_sel[ind]\n",
    "#labels_sel   = labels_clinic\n",
    "# sort\n",
    "\n",
    "plot_BM(M, labels_sel, areas_sel, 'BL_Area', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_BM(M, labels,areas, t='BL', area = 0):\n",
    "    fig      = pylab.figure(figsize=(15,15))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, aspect='auto', origin='lower',cmap='hot', vmin=0, vmax= 20)\n",
    "    plt.xlim([-1.5, len(labels)-0.5])\n",
    "    plt.ylim([-0.5, len(labels)+0.5])\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90);\n",
    "    plt.yticks(range(len(labels)), labels);\n",
    "    if area>0:\n",
    "        for i in range(len(labels)):\n",
    "            r = areas[i]\n",
    "            axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "            axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(t+ '-- LL z-score')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/BM_'+t+'.svg')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/BM_'+t+'.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete WM\n",
    "## sort\n",
    "# ind = np.lexsort((areas_sel,labels_sel))\n",
    "labels_sel   = np.delete(labels_all, bad_region, 0)\n",
    "\n",
    "ind = np.argsort(areas_sel)\n",
    "M = M[ind,:]\n",
    "M = M[:,ind]\n",
    "labels_sel = labels_sel[ind]\n",
    "areas_sel = areas_sel[ind]\n",
    "# sort\n",
    "\n",
    "plot_BM(M, labels_sel, areas_sel, 'BL_Area',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-chapel",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([ 7., 27., 55., 65.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean(sc, rc, LL_CCEP,EEG_resp,labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = rc+1\n",
    "sc = 65\n",
    "\n",
    "plot_mean(sc, rc, LL_CCEP,EEG_resp,labels_clinic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat      = LL_CCEP[(LL_CCEP['d']<10)&(LL_CCEP['RespC']==1)] #(LL_CCEP['d']<60)&\n",
    "# \n",
    "k        = np.random.randint(0, len(dat))\n",
    "stimNum  = np.int64(dat.Num.values[k])\n",
    "sc       = np.int64(dat.Stim.values[k])\n",
    "rc       = np.int64(dat.Chan.values[k])\n",
    "plot_mean(sc, rc, LL_CCEP,EEG_resp,labels_clinic)\n",
    "plot_mean(sc, rc, LL_CCEP,EEG_resp,labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean(75, 28, LL_CCEP,EEG_resp, labels_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean(sc, rc, LL_CCEP,EEG_resp, labels ):\n",
    "    t_0    = 1\n",
    "    lists  = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)&(~np.isnan(LL_CCEP.zLL.values))]\n",
    "    \n",
    "    fig   = plt.figure(figsize=(12,7) )\n",
    "    #plt.title(labels_all[Stim_chs]+' -- '+labels_clinic[rc])\n",
    "    #plt.title(labels[sc]+' -- '+labels[rc])\n",
    "    plt.title(labels[sc]+' -- '+labels[rc]+', Dist: '+str(np.round(lists.d.values[0]))+'mm')\n",
    "    \n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    plt.xlabel('time [s]')\n",
    "    plt.text(-0.37, 200, 'LL: '+str(np.round(np.mean(lists.LLpeak),2))+'uV/ms (of mean)', c=[0,0,0])\n",
    "    \n",
    "    ylim = 200\n",
    "\n",
    "    #stim_spec                = stimlist[(stimlist.condition>0)&(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "    stimNum_all                  = lists.Num.values.astype('int')\n",
    "    for i in range(len(stimNum_all)):\n",
    "        ylim =np.max([ylim, np.max(abs(ff.lp_filter(EEG_resp[rc,stimNum_all[i],Fs:int(1.5*Fs)],45,Fs)))])\n",
    "        plt.plot(x_ax,ff.lp_filter(EEG_resp[rc,stimNum_all[i],:],45,Fs), c=color_elab[0], linewidth=1, label='trial'+str(i+1))\n",
    "    plt.plot(x_ax,ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs), c=[0,0,0], linewidth=2, label='mean, n='+str(len(stimNum_all)))\n",
    "    \n",
    "    plt.xlim([-0.6,1])\n",
    "    plt.ylim([-np.max([ylim*1.071,300]),np.max([ylim*1.071,300])])\n",
    "    #plt.axvspan(t_0+w_r-1, t_0-1+w_LL, alpha=0.3, color=color_elab[0])\n",
    "    #plt.axvspan(t_0+0.015-1, t_0+w_r-1, alpha=0.8, color=color_elab[1])\n",
    "    #plt.axvspan(t_0+0.015-1-0.2, t_0+w_r-1-0.2, alpha=0.8, color=color_elab[1])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LL_thr(EEG_resp, LL_all, labels_all, path_patient, n_trial=3):\n",
    "    ## get threshoold value for each response channel (99th and 95h)\n",
    "    chan_thr = np.zeros((len(labels_all), 4))\n",
    "    for rc in range(len(labels_all)):\n",
    "        chan_thr[rc,:] = get_sig_thr(rc, LL_all, EEG_resp, n_trial)\n",
    "    data_A = pd.DataFrame(chan_thr, columns=['99', '95', 'std', 'mean'])\n",
    "    data_A.to_csv(path_patient + '/Analysis/BrainMapping/data/chan_sig_thr_BL.csv', index=False,header=False)  # scat_plot = scat_plot.fillna(method='ffill')\n",
    "    print('Data stored')\n",
    "    print(path_patient + '/Analysis/BrainMapping/data/chan_sig_thr_BL.csv')\n",
    "    return chan_thr\n",
    "def LL_mx(EEG_trial, Fs=500, w=0.25,t0=1.01):\n",
    "    # calculate mean response and get LL (incl peak)\n",
    "    resp           = np.mean(EEG_trial,0)\n",
    "    LL_resp        = LL_funcs.get_LL_all(np.expand_dims(np.expand_dims(resp, axis=0),0), Fs, w, 1, 0)\n",
    "    LL_resp        = LL_resp[0,0]\n",
    "    mx             = np.max(LL_resp[np.int64((t0+w/2)*Fs):np.int64((t0+w)*Fs)])\n",
    "    mx_ix          = np.argmax(LL_resp[np.int64((t0+w/2)*Fs):np.int64((t0+w)*Fs)])\n",
    "    return mx, mx_ix, LL_resp\n",
    "\n",
    "def get_sig_thr(rc, LL_CCEP, EEG_resp, t_num, Fs=500,fig_path='no'):\n",
    "    # t_num = number of trials included for mean calculation, IO =3\n",
    "    BL_times       = np.concatenate([np.arange(0, 0.5, 0.01),np.arange(1.6, 2,0.01)])  # times wihtout stimulation, 0-0.5s, 1.6 - 2.5\n",
    "    n              = 300 # number of surrogates\n",
    "    LL_surr        = np.zeros((n, 1))\n",
    "    list_surr      = LL_CCEP[(LL_CCEP['d']>8)&(LL_CCEP['Chan']==rc)&~(LL_CCEP['Stim']==rc)&~np.isnan(LL_CCEP.LL.values)] # take BL when rc is not stimulating and not during noise\n",
    "    list_surr      = list_surr[~np.isnan(list_surr.LL.values)]\n",
    "    stimNum        = list_surr.Num.values.astype('int')\n",
    "    thr            = np.zeros(4,)\n",
    "    if len(stimNum)>0:\n",
    "        for k in range(n):\n",
    "            t0               = np.random.choice(np.round(BL_times,2))\n",
    "            stimNum_choice   = np.random.choice(stimNum, t_num)\n",
    "            EEG_trial        = EEG_resp[rc,stimNum_choice,np.int64((t0)*Fs):np.int64((t0+0.4)*Fs)]#np.flip(EEG_resp[rc,stimNum,:],1)\n",
    "            LL_surr[k,0],_,_ = LL_mx(EEG_trial, t0=0)\n",
    "\n",
    "        thr[0] = np.percentile(LL_surr[:,0],99)\n",
    "        thr[1] = np.percentile(LL_surr[:,0],95)\n",
    "        thr[2] = np.nanstd(LL_surr[:,0])\n",
    "        thr[3] = np.nanmean(LL_surr[:,0]) \n",
    "        if fig_path != 'no':\n",
    "            fig = plt.figure(figsize=(5,5))\n",
    "            plt.title('surrogates - '+labels_all[rc])\n",
    "            plt.hist(LL_surr[:,0])\n",
    "            plt.axvline(thr[0], c= [1,0,0], label='99%')\n",
    "            plt.axvline(thr[1], c= [1,0,0], label='90%')\n",
    "            plt.axvline(np.mean(LL_surr[:,0])+np.std(LL_surr[:,0]), c= [0,0,0], label='mean +std')\n",
    "            plt.xlabel('LL [250ms]')\n",
    "            plt.xlim([0,np.max([2,1.1*max(LL_surr[:,0])]) ])\n",
    "            plt.legend()\n",
    "            plt.savefig(fig_path)\n",
    "            plt.close(fig)    # close the figure window\n",
    "    return thr\n",
    "\n",
    "def get_SigCon_BM_cond(LL_CCEP, EEG_resp, labels_all,chan_thr, Fs=500):\n",
    "    M_resp      = np.zeros((len(labels_all), len(labels_all),3))-1\n",
    "    #(LL_CCEP['Condition'].isin(cond))\n",
    "    for rc in tqdm.tqdm(range(len(labels_all))): # for each response channel\n",
    "        for sc in range(len(labels_all)): # for each stim channel\n",
    "            lists          = LL_CCEP[(LL_CCEP['Int']==3)&(LL_CCEP['Chan']==rc) & (LL_CCEP['Stim']==sc)]\n",
    "            lists          = lists[~np.isnan(lists.LL.values)]\n",
    "            stimNum_all    = lists.Num.values.astype('int')\n",
    "            if len(stimNum_all)>0:\n",
    "                EEG_trial      = EEG_resp[rc,stimNum_all,:]\n",
    "                mx,_,_         = LL_mx(EEG_trial)\n",
    "\n",
    "                if  mx>chan_thr[rc, 0]:\n",
    "                    M_resp[sc,rc,0] = mx\n",
    "                    M_resp[sc,rc,1] = 1\n",
    "                    M_resp[sc,rc,2] = (mx-chan_thr[rc,3])/chan_thr[rc, 2]\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = 1\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'LLpeak'] = mx\n",
    "                else:\n",
    "                    M_resp[sc,rc,:] = 0\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = 0\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'LLpeak'] = mx\n",
    "            else:\n",
    "                M_resp[sc,rc,:] = -1\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = -1\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'LLpeak'] = -1\n",
    "\n",
    "    return LL_CCEP, M_resp\n",
    "\n",
    "def plot_BM(M, labels,areas, t='BL'):\n",
    "    fig      = pylab.figure(figsize=(15,15))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, aspect='auto', origin='lower',cmap='hot', vmin=0, vmax= 20)\n",
    "    plt.xlim([-1.5, len(labels)-0.5])\n",
    "    plt.ylim([-0.5, len(labels)+0.5])\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90);\n",
    "    plt.yticks(range(len(labels)), labels);\n",
    "    # for i in range(len(labels)):\n",
    "    #     r = areas[i]\n",
    "    #     axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    #     axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(t+ '-- LL z-score')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/BM_'+t+'.svg')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/BM_'+t+'.jpg')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
