{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "import imageio\n",
    "import h5py\n",
    "#import scipy.fftpack\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import pywt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy import signal\n",
    "from matplotlib.colors import ListedColormap\n",
    "import time\n",
    "import seaborn as sns\n",
    "#import scipy.io as sio\n",
    "#from scipy.integrate import simps\n",
    "import pandas as pd\n",
    "#from scipy import fft\n",
    "import matplotlib.mlab as mlab\n",
    "import sys\n",
    "sys.path.append('T:\\EL_experiment\\Codes\\CCEP_human\\Python_Analysis/py_functions')\n",
    "import analys_func\n",
    "from scipy.stats import norm\n",
    "import LL_funcs as LLf\n",
    "from scipy.stats import norm\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "import ntpath\n",
    "root = Tk()\n",
    "root.withdraw()\n",
    "import math\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import pylab\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import squareform\n",
    "import platform\n",
    "from glob import glob\n",
    "from scipy.io import savemat\n",
    "\n",
    "import BM_func as BMf\n",
    "import basic_func as bf\n",
    "from matplotlib.patches import Rectangle\n",
    "import tqdm\n",
    "import similarity_funcs as sf\n",
    "\n",
    "import freq_funcs as ff\n",
    "subj            = \"EL011\"\n",
    "cwd             = os.getcwd()\n",
    "\n",
    "path_patient_analysis = 'y:\\\\eLab\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\\\' + subj\n",
    "path_gen = os.path.join('y:\\\\eLab\\Patients\\\\' + subj)\n",
    "if not os.path.exists(path_gen):\n",
    "    path_gen = 'T:\\\\EL_experiment\\\\Patients\\\\' + subj\n",
    "path_patient = path_gen + '\\Data\\EL_experiment'  # os.path.dirname(os.path.dirname(cwd))+'/Patients/'+subj\n",
    "path_infos = os.path.join(path_patient, 'infos')\n",
    "if not os.path.exists(path_infos):\n",
    "    path_infos = path_gen + '\\\\infos'\n",
    "\n",
    "color_elab      = ['#594157', \"#F1BF98\",\"#8FB996\"]\n",
    "t_label         = ['Baseline', 'Flumazenil', 'Benzodiazepin']  # ['Baseline', 'Flumazenil', 'Benzodiazepin']\n",
    "lbls = pd.read_excel(os.path.join(path_infos, subj + \"_labels.xlsx\"), header=0, sheet_name='BP')\n",
    "labels_all      = lbls.label.values\n",
    "labels_clinic   = lbls.Clinic.values\n",
    "labels_region   = lbls.Region.values\n",
    "labels_L        = lbls.Hemisphere.values\n",
    "nodes           = pd.DataFrame({'ID': labels_all, 'Region': labels_region, 'H': labels_L})\n",
    "coord_all       = np.array([lbls.x.values,lbls.y.values, lbls.z.values ]).T\n",
    "bad_region = np.where((labels_region=='WM')|(labels_region=='OUT')|(labels_region=='Putamen'))[0]\n",
    "#if subj == 'EL006':\n",
    " #     labels_all      = lbls.Clinic.values\n",
    "badchans  = pd.read_csv(path_patient_analysis + '/BrainMapping/data/badchan.csv')\n",
    "bad_chans = np.unique(np.array(np.where(badchans.values[:,1:]==1))[0,:])\n",
    "\n",
    "bad_stims = np.where(labels_region=='OUT')[0]\n",
    "\n",
    "##all \n",
    "cond_vals   = np.arange(4)\n",
    "cond_labels = ['BM', 'BL', 'Fuma', 'BZD']\n",
    "cond_colors = ['#494159','#594157', \"#F1BF98\",\"#8FB996\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs             = 500\n",
    "dur            = np.zeros((1,2), dtype=np.int32)\n",
    "t0 = 1\n",
    "dur[0,0] =  -t0\n",
    "dur[0,1] =  3\n",
    "\n",
    "#dur[0,:]       = np.int32(np.sum(abs(dur)))\n",
    "x_ax           = np.arange(dur[0,0],dur[0,1],(1/Fs))\n",
    "color_elab      = np.zeros((3,3))\n",
    "color_elab[0,:] = np.array([31, 78, 121])/255\n",
    "color_elab[1,:] = np.array([189, 215, 238])/255\n",
    "color_elab[2,:] = np.array([0.256, 0.574, 0.431])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'BrainMapping'\n",
    "cond_folder = 'CR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-flower",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EEG_CR_file = path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\EEG_CR.npy'\n",
    "EEG_resp = np.load(EEG_CR_file)\n",
    "stimlist = pd.read_csv(path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\Stimlist_CR.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-password",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_MN1 = path_patient_analysis + '\\\\' + folder + '\\\\data\\\\M_N1.npy'\n",
    "file_con = path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\con_trial_all.csv'\n",
    "con_trial    = pd.read_csv(file_con)\n",
    "#M_N1peaks = np.load(file_MN1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-particular",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = np.unique(stimlist.date)\n",
    "# get stimulation channels directly from stimlist\n",
    "StimChanSM   = np.unique(stimlist.ChanP)\n",
    "ChanN        = np.zeros((len(StimChanSM),))\n",
    "StimChans    = []#np.zeros((len(stim_chan)))\n",
    "StimChansC   = []#np.zeros((len(stim_chan)))\n",
    "StimChanIx   = []#np.zeros((len(stim_chan)))\n",
    "for i in range(len(StimChanSM)):\n",
    "    ChanN[i] =  np.median(stimlist[stimlist.ChanP==StimChanSM[i]].ChanN)\n",
    "    #StimChans.append(labels_SM[(np.array(labels.chan_num.values)==stim_chan[i,0])][0])\n",
    "    StimChans.append(labels_all[(np.array(lbls.ChanP_SM.values)==StimChanSM[i])&(np.array(lbls.ChanN_SM.values)==ChanN[i])][0])\n",
    "    StimChansC.append(labels_clinic[(np.array(lbls.ChanP_SM.values)==StimChanSM[i])&(np.array(lbls.ChanN_SM.values)==ChanN[i])][0])\n",
    "    StimChanIx.append(lbls[(np.array(lbls.ChanP_SM.values)==StimChanSM[i])&(np.array(lbls.ChanN_SM.values)==ChanN[i])]['Num'].values[0]-1)\n",
    "    # bad channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-tactics",
   "metadata": {},
   "source": [
    "## Mean resps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-immunology",
   "metadata": {},
   "source": [
    "## LL and Significant responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimlist.insert(0,'h',stimlist.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-apparel",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp    = 1\n",
    "w_r    = 0.1\n",
    "w_LL   = 0.25\n",
    "t_0    = 1 # time of stimulation in data\n",
    "t_0s   = 0.5 # time of surr stim\n",
    "t_Bl   = 0.5\n",
    "\n",
    "## calcualte mean CCEp and then take LL \n",
    "data_CCEP                = np.zeros((1,10))\n",
    "w                        = 0.25\n",
    "stim_spec                = stimlist[(stimlist.IPI_ms ==0)]#&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "stimNum                  = stim_spec.StimNum.values#[:,0]\n",
    "resps                    = ff.lp_filter(EEG_resp[:,stimNum,:],45,Fs)\n",
    "ChanP1                   = bf.SM2IX(stim_spec.ChanP.values,StimChanSM,np.array(StimChanIx))\n",
    "LL_all          = LL_funcs.get_LL_both(data=resps, Fs=Fs, IPI=np.zeros((len(stimNum),1)), t_0=t_0, win=w_LL)\n",
    "LL_r            = LL_funcs.get_LL_ratio(data=resps, Fs=Fs, IPI=np.zeros((len(stimNum),1)),t_bl=t_0-0.2, t_stim=t_0, win=w_r)\n",
    "#LL_CCEP[sc, :, h, 0] = \n",
    "# remove Resp if rec channel was just stimulating before\n",
    "stim_spec0                = stimlist[(stimlist.StimNum.isin((stim_spec.StimNum.values-1)[1:]))]\n",
    "ChanP0                    = np.zeros((len(stimNum),))\n",
    "ChanP0[1:]                = bf.SM2IX(stim_spec0.ChanP.values,StimChanSM,np.array(StimChanIx))\n",
    "\n",
    "for c in range(LL_all.shape[0]):\n",
    "    val         = np.zeros((LL_all.shape[1], 10))\n",
    "    val[:, 0]   = c                                         # response channel\n",
    "    val[:, 1]   = bf.SM2IX(stim_spec.ChanP.values,StimChanSM,np.array(StimChanIx)) #stim Chan, in all labels\n",
    "    val[:, 2]   = LL_all[c,:,1] ## LL absolute\n",
    "    val[:, 3]   = stimNum\n",
    "    val[:, 4]   = LL_r[c,:,1]\n",
    "    val[:, 6]   = stim_spec.h.values\n",
    "    val[:, 7]   = stim_spec.date.values\n",
    "    #val[:, 8]   = np.max(abs(resps[c,:,np.int64(1.015*Fs):np.int64(1.2*Fs)]),1)\n",
    "    #val[:, 9]   = np.max(abs(resps[c,:,np.int64(1.015*Fs):np.int64(1.2*Fs)]),1)/np.std(resps[c,:,0:np.int64(0.9*Fs)],1)\n",
    "    # remove value if response channel is or jsut was aprt of stimulation\n",
    "    val[np.where(bf.check_inStimChan(c, ChanP0, labels_clinic)==1),2] = np.nan\n",
    "    val[np.where(bf.check_inStimChan(c, ChanP0, labels_clinic)==1),4] = np.nan\n",
    "    #val[np.where(bf.check_inStimChan(c, ChanP0, labels_clinic)==1),8] = np.nan\n",
    "    #val[np.where(bf.check_inStimChan(c, ChanP0, labels_clinic)==1),9] = np.nan\n",
    "    val[np.where(bf.check_inStimChan(c, ChanP1, labels_clinic)==1),2] = np.nan\n",
    "    val[np.where(bf.check_inStimChan(c, ChanP1, labels_clinic)==1),4] = np.nan\n",
    "    #val[np.where(bf.check_inStimChan(c, ChanP1, labels_clinic)==1),9] = np.nan\n",
    "    #val[np.where(bf.check_inStimChan(c, ChanP1, labels_clinic)==1),8] = np.nan\n",
    "\n",
    "    #ix         = np.where(np.max(abs(resps[c,:,np.int64(0.95*Fs):np.int64(1.01*Fs)]),1)>400)\n",
    "    pks         = np.max(abs(resps[c,:,np.int64(0.95*Fs):np.int64(1.25*Fs)]),1)\n",
    "    pks_loc     = np.argmax(abs(resps[c,:,np.int64(0.95*Fs):np.int64(1.1*Fs)]),1)+np.int64(0.95*Fs)\n",
    "    #ix         = np.where(np.max(abs(resps[c,:,np.int64(0.95*Fs):np.int64(1.01*Fs)]),1)>400)\n",
    "    ix = np.where((pks>100)&(pks_loc>np.int64(0.955*Fs))&(pks_loc<np.int64(1.012*Fs)))\n",
    "    val[ix, 2] = np.nan\n",
    "    val[ix, 4] = np.nan\n",
    "    #val[ix, 8] = np.nan\n",
    "    #val[ix, 9] = np.nan\n",
    "    data_CCEP    = np.concatenate((data_CCEP, val), axis=0)\n",
    "\n",
    "data_CCEP = data_CCEP[1:-1, :] # remove first row (dummy row)\n",
    "\n",
    "#LL_CCEP = pd.DataFrame(\n",
    "#    {\"Chan\": data_CCEP[:, 0], \"Stim\": data_CCEP[:, 1], \"LL\": data_CCEP[:, 2],\"d\": data_CCEP[:, 5],\"rLL\": data_CCEP[:, 4],\"zLL\": data_CCEP[:, 4],\"mx\": data_CCEP[:, 8],\"mx/std\": data_CCEP[:, 9],\"Day\": data_CCEP[:, 7],\"Hour\": data_CCEP[:, 6],\"Num\": data_CCEP[:, 3]})\n",
    "#\n",
    "LL_CCEP = pd.DataFrame(\n",
    "    {\"Chan\": data_CCEP[:, 0], \"Stim\": data_CCEP[:, 1], \"LL\": data_CCEP[:, 2],\"d\": data_CCEP[:, 5],\"rLL\": data_CCEP[:, 4],\"zLL\": data_CCEP[:, 4],\"Day\": data_CCEP[:, 7],\"Hour\": data_CCEP[:, 6],\"Num\": data_CCEP[:, 3]})\n",
    "\n",
    "LL_CCEP.loc[LL_CCEP['Chan'].isin(bad_chans), 'LL'] = np.nan\n",
    "\n",
    "##Z-score absolute\n",
    "LL_BL_z   = np.zeros((len(labels_all),2))\n",
    "LL_all_BL       = LL_funcs.get_LL_both(data=resps, Fs=Fs, IPI=np.zeros((len(stimNum),1)), t_0=t_Bl, win=w_LL)\n",
    "LL_BL_z[:,0] = np.nanmean(LL_all_BL[:,:,1],1)\n",
    "LL_BL_z[:,1] = np.nanstd(LL_all_BL[:,:,1],1)\n",
    "for rc in range(len(labels_all)):\n",
    "    LL_CCEP.loc[(LL_CCEP.Chan ==rc), 'zLL'] = (LL_CCEP.loc[(LL_CCEP.Chan ==rc), 'LL']- LL_BL_z[rc,0])/LL_BL_z[rc,1]\n",
    "\n",
    "## Resp based on absolute LL 99th        \n",
    "LL_CCEP.insert(0,'RespA', 0)\n",
    "thr = np.percentile(LL_all_BL[:,:,1], 99,1)\n",
    "for rc in range(len(labels_all)):\n",
    "    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.LL>thr[rc]), 'RespA'] = 1\n",
    "LL_CCEP.loc[(LL_CCEP.LL==-2), 'RespA'] = 0  \n",
    "\n",
    "\n",
    "## Resp based on absolute LL 99th        \n",
    "LL_CCEP.insert(0,'RespR', 0)\n",
    "LL_BL_ratio      = LL_funcs.get_LL_ratio(data=ff.lp_filter(EEG_resp[:,stimNum,:],45,Fs), Fs=Fs, IPI=np.zeros((len(stimNum),1)),t_bl=t_0s-0.2, t_stim=t_0s, win=w_r)\n",
    "thr              = np.percentile(LL_BL_ratio[:,:,1], 99,1)\n",
    "for rc in range(len(labels_all)):\n",
    "    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.rLL>thr[rc]), 'RespR'] = 1\n",
    "LL_CCEP.loc[np.isnan(LL_CCEP.LL), 'RespR'] = 0  \n",
    "\n",
    "#LL_CCEP.insert(0,'RespM', 0)\n",
    "#LL_CCEP.loc[(LL_CCEP['mx/std']>4), 'RespM'] = 1                \n",
    "# distance\n",
    "for i in range(len(StimChans)):\n",
    "    ChanP = StimChanSM[i]\n",
    "    s   = np.where(labels_all == StimChans[i])[0][0]#i#np.int(StimChanNums[i]) \n",
    "    s   = np.int64(s)\n",
    "    for c in np.unique(LL_CCEP.Chan):\n",
    "        c   = np.int64(c)\n",
    "        LL_CCEP.loc[(LL_CCEP.Stim == s)&(LL_CCEP.Chan == c), 'd'] = math.sqrt(((coord_all[s,0]-coord_all[c,0])**2)+((coord_all[s,1]-coord_all[c,1])**2)+((coord_all[s,2]-coord_all[c,2])**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-manner",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_CCEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_CCEP, M_resp = bf.sign_conncetion(LL_CCEP, EEG_resp, labels_all, dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_resp = np.zeros((len(labels_all), len(labels_all)))-1\n",
    "for sc in tqdm.tqdm(range(len(labels_all))):\n",
    "    for rc in range(len(labels_all)):\n",
    "        M_resp[sc, rc] = np.mean(LL_CCEP.loc[(LL_CCEP.Stim==sc)&(LL_CCEP.Chan==rc), 'RespC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-circus",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_resp[np.isnan(M_resp)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "n   = 10 \n",
    "w   = 0.1\n",
    "M_resp = np.zeros((len(labels_all), len(labels_all)))\n",
    "for sc in tqdm.tqdm(range(len(labels_all))):\n",
    "    for rc in range(len(labels_all)):\n",
    "        lists          = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)]\n",
    "        lists          = lists[~np.isnan(lists.zLL.values)]\n",
    "        stimNum_all    = lists.Num.values.astype('int')\n",
    "\n",
    "        if len(stimNum_all)>0:\n",
    "            #list_BL        = LL_CCEP[(LL_CCEP['d']>20)&(LL_CCEP['Chan']==rc)&~(LL_CCEP['Stim']==sc)&~np.isnan(LL_CCEP.zLL.values)]\n",
    "            #stimNum_BL     = list_BL.Num.values.astype('int')\n",
    "            resp           = ff.lp_filter(np.nanmean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "            #resp_BL        = np.zeros((n, np.sum(abs(dur))*Fs))\n",
    "            #for k in range(n):\n",
    "            #    resp_BL[k,:] = ff.lp_filter(np.nanmean(EEG_resp[rc,np.random.choice(stimNum_BL, len(stimNum_all)),:],0),45,Fs)\n",
    "            #resp_BL = np.flip(resp_BL,1)\n",
    "            #LL_BL     = get_LL_all(np.expand_dims(resp_BL, axis=0), Fs, w, 1, 0)\n",
    "            LL_resp   = get_LL_all(np.expand_dims(np.expand_dims(resp, axis=0),0), Fs, w, 1, 0)\n",
    "            #LL_BL     = LL_BL[0]\n",
    "            LL_resp   = LL_resp[0,0]\n",
    "            thr        = np.percentile(LL_BL[:,0:np.int64((1-w/2)*Fs)],99.9)\n",
    "            LL_thr = LL_resp-thr\n",
    "            \n",
    "            #LL_BL = np.concatenate([LL_BL, np.expand_dims(LL_resp,0)])\n",
    "            if np.max(LL_resp[np.int64(Fs*(1.01+w/2)):np.int64(Fs*(1.01+w))])>np.percentile(LL_BL[:,0:np.int64(2*Fs)],99.9):\n",
    "                M_resp[sc,rc] = 1\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = 1\n",
    "            else:\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = 0\n",
    "        else:\n",
    "            M_resp[sc,rc] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-boulder",
   "metadata": {},
   "outputs": [],
   "source": [
    "n   = 10 \n",
    "w   = 0.1\n",
    "M_resp = np.zeros((len(labels_all), len(labels_all)))-1\n",
    "for sc in tqdm.tqdm(range(len(labels_all))):\n",
    "    for rc in range(len(labels_all)):\n",
    "        lists          = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)]\n",
    "        lists          = lists[~np.isnan(lists.zLL.values)]\n",
    "        stimNum_all    = lists.Num.values.astype('int')\n",
    "\n",
    "        if len(stimNum_all)>0:\n",
    "            list_BL        = LL_CCEP[(LL_CCEP['d']>20)&(LL_CCEP['Chan']==rc)&~(LL_CCEP['Stim']==sc)&~np.isnan(LL_CCEP.zLL.values)]\n",
    "            stimNum_BL     = list_BL.Num.values.astype('int')\n",
    "            resp_BL        = np.zeros((n, np.sum(abs(dur))*Fs))\n",
    "            for k in range(n):\n",
    "                resp_BL[k,:] = ff.lp_filter(np.nanmean(EEG_resp[rc,np.random.choice(stimNum_BL, len(stimNum_all)),:],0),45,Fs)\n",
    "            LL_BL     = get_LL_all(np.expand_dims(resp_BL, axis=0), Fs, w, 1, 0)\n",
    "            LL_BL     = LL_BL[0]\n",
    "    \n",
    "            resp       = ff.lp_filter(np.nanmean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "            LL_resp    = get_LL_all(np.expand_dims(np.expand_dims(resp, axis=0),0), Fs, w, 1, 0)\n",
    "            LL_resp    = LL_resp[0,0]\n",
    "            \n",
    "            LL_meregd = np.concatenate([LL_BL, np.expand_dims(LL_resp,0)])\n",
    "            thr        = np.percentile(LL_meregd[0:np.int64((1-w/2-0.05)*Fs)],99)\n",
    "            if  np.mean(LL_resp[np.int64((1.01+w/2)*Fs):np.int64((1+w)*Fs)]>thr)>0.9:\n",
    "                M_resp[sc,rc] = 1\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = 1\n",
    "            else:\n",
    "                M_resp[sc,rc] = 0\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_CCEP.to_csv(path_patient + '/Analysis/BrainMapping/LL/CCEP_'+str(exp)+'_'+str(w)+'s.csv', index=False,\n",
    "              header=True)  # scat_plot = scat_plot.fillna(method='ffill')\n",
    "print('Data saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-director",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions       = np.unique(labels_region)\n",
    "color_regions = ['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6',\"#8FB996\"]\n",
    "\n",
    "v= np.sort(labels_region)\n",
    "region_border = np.where(np.roll(v,1)!=v)[0]\n",
    "region_border = np.concatenate([region_border, [len(labels_all)]])\n",
    "region_num = np.diff(region_border)\n",
    "labels_sort     = labels_all[np.argsort(labels_region)]\n",
    "labels_region_sort = np.sort(labels_region)\n",
    "StimChanIx_sort = np.argsort(labels_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_resp_region = M_resp[np.argsort(labels_region),:]\n",
    "M_resp_region = M_resp_region[:,np.argsort(labels_region)]\n",
    "cmap     = ListedColormap(['white', 'black', 'red'])\n",
    "fig      = pylab.figure(figsize=(20,20))\n",
    "axmatrix = fig.add_axes([0.15,0.15,0.9,0.9])\n",
    "im       = axmatrix.matshow(M_resp_region, aspect='auto', origin='lower',cmap= cmap)\n",
    "for i in range(len(region_border)-1):\n",
    "    axmatrix.add_patch(Rectangle((-1.5, region_border[i]-0.5), 1, region_num[i], color = color_regions[np.where(regions==labels_region_sort[region_border[i]])[0][0]]))\n",
    "    axmatrix.add_patch(Rectangle((region_border[i]-0.5, len(labels_all)-0.5),  region_num[i],1, color = color_regions[np.where(regions==labels_region_sort[region_border[i]])[0][0]]))\n",
    "    t = plt.text(-20, (region_border[i]+region_num[i]/2)-1, np.unique(v)[i], fontsize=15)\n",
    "    t.set_bbox(dict(facecolor=color_regions[np.where(regions==labels_region_sort[region_border[i]])[0][0]], alpha=0.5))\n",
    "plt.xlim([-1.5, len(labels_all)+1])\n",
    "plt.ylim([0, len(labels_all)+0.5])\n",
    "plt.xticks(range(len(labels_all)), labels_sort, rotation=90);\n",
    "plt.yticks(range(len(labels_all)), labels_sort);\n",
    "#filename    = path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/BM_general.png'\n",
    "#plt.savefig(filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-fortune",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = LL_CCEP[(LL_CCEP.RespC==1)&(LL_CCEP.d>7.5)] \n",
    "for c in range(len(labels_all)):\n",
    "    data_test.loc[(data_test.Chan ==c), \"Recs\"]   = labels_all[c]\n",
    "    data_test.loc[(data_test.Stim ==c), \"Stim Region\"]   = labels_region[c]\n",
    "    data_test.loc[(data_test.Chan ==c), \"Resp Region\"]   = labels_region[c]\n",
    "    data_test.loc[(data_test.Stim ==c), \"Stims\"]  = labels_all[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developing-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asym     = np.zeros((1,6))\n",
    "lists         = LL_CCEP[(LL_CCEP['RespC']==1)]\n",
    "lists         = lists[~np.isnan(lists.LL.values)]\n",
    "for s in range(len(labels_all)):\n",
    "    for c in range(len(labels_all)):\n",
    "        list_1 = lists[(lists.Chan==c)&(lists.Stim==s)]\n",
    "        if len(list_1)>0:\n",
    "            val         = np.zeros((1, 6))\n",
    "            val[0, 0]   = c                                         # response channel\n",
    "            val[0, 1]   = s                                         # response channel\n",
    "            val[0, 4]   = np.nanmean(list_1.d)\n",
    "            data_asym    = np.concatenate((data_asym, val), axis=0)\n",
    "data_asym = data_asym[1:-1, :] # remove first row (dummy row)\n",
    "data_A = pd.DataFrame(\n",
    "    {\"Chan\": data_asym[:, 0], \"Stim\": data_asym[:, 1], \"R\": data_asym[:, 2], \"Diff\": data_asym[:, 2], \"d\": data_asym[:, 4]})\n",
    "\n",
    "for c in range(len(labels_all)):\n",
    "    data_A.loc[(data_A.Chan ==c), \"Recs\"]   = labels_all[c]\n",
    "    data_A.loc[(data_A.Stim ==c), \"Stim Region\"]   = labels_region[c]\n",
    "    data_A.loc[(data_A.Chan ==c), \"Resp Region\"]   = labels_region[c]\n",
    "    data_A.loc[(data_A.Stim ==c), \"Stims\"]  = labels_all[c]\n",
    "data_A.insert(5,'Change',0)\n",
    "data_A=data_A.drop(data_A[data_A['Stim Region']=='OUT'].index)\n",
    "data_A=data_A.drop(data_A[data_A['Resp Region']=='OUT'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.figure(figsize=(13,13))\n",
    "\n",
    "fig, ax     = plt.subplots(figsize=(15,12))\n",
    "plt.title(subj+' - Connection decrease by Benzo')\n",
    "k=0\n",
    "\n",
    "data_test = data_A[(data_A.d>7.5)] \n",
    "for i in range(len(labels_all)):\n",
    "    s = StimChanIx_sort[i]\n",
    "    ax.add_patch(Rectangle((6.5, i-0.5), 1, 1, color = color_regions[np.where(regions==labels_region[s])[0][0]]))\n",
    "    data_plot = data_test[data_test.Stim==s]\n",
    "    for j in range(len(data_plot)):\n",
    "        #plt.plot(data_plot.d.values[j], i,'o', markersize=10, c= color_regions[np.where(regions==data_plot['Resp Region'].values[j])[0][0]])\n",
    "        plt.scatter(data_plot.d.values[j], i, s=80, c=color_regions[np.where(regions==data_plot['Resp Region'].values[j])[0][0]], alpha=0.8, edgecolors=[0,0,0])\n",
    "    if any (region_border == i):\n",
    "        num= region_num[np.where(region_border==i)[0][0]]\n",
    "        t = plt.text(-15, (i+num/2)-1, v[i], fontsize=15)\n",
    "        #t = plt.text(0.5, 0.5, 'text', transform=ax.transAxes, fontsize=30)\n",
    "        t.set_bbox(dict(facecolor=color_regions[np.where(regions==labels_region[s])[0][0]], alpha=0.5, edgecolor=color_regions[np.where(regions==labels_region[s])[0][0]]))\n",
    "\n",
    "\n",
    "plt.yticks(np.arange(len(labels_all)),labels_sort, fontsize=7)\n",
    "plt.xlim([6.5, 105])\n",
    "plt.ylim([-0.5, len(labels_all)-0.5])\n",
    "plt.xlabel('euclidean distance [mm]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_resp = pd.DataFrame(M_resp)\n",
    "sig_resp.to_csv(path_patient + '/Analysis/all/sign_chan.csv', index=False,\n",
    "              header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-fellowship",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LL_CCEP =pd.read_csv(path_patient + '/Analysis/BrainMapping/LL/CCEP_'+str(exp)+'_'+str(w)+'s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(M_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-diesel",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig      = pylab.figure(figsize=(20,20))\n",
    "axmatrix = fig.add_axes([0.15,0.15,0.9,0.9])\n",
    "cmap     = ListedColormap(['white', 'black', 'silver'])\n",
    "im = axmatrix.matshow(M_resp, aspect='auto', origin='lower',cmap= cmap)\n",
    "\n",
    "plt.xticks(range(len(labels_all)), labels_all, rotation=90);\n",
    "plt.yticks(range(len(labels_all)), labels_all);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungry-reflection",
   "metadata": {},
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-highlight",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-argument",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#w =0.1\n",
    "#d = 15\n",
    "#r = 1\n",
    "#c = 1\n",
    "#dat      = LL_CCEP[~(LL_CCEP['Chan'].isin(bad_chans))&(LL_CCEP['RespC'] ==c)&(LL_CCEP['d'] >d)&(LL_CCEP['RespR'] ==r)]\n",
    "#\n",
    "#k        = np.random.randint(0, len(dat))\n",
    "#stimNum  = np.int64(dat.Num.values[k])\n",
    "#sc = np.int64(dat.Stim.values[k])\n",
    "#rc = np.int64(dat.Chan.values[k])\n",
    "\n",
    "j = 3\n",
    "\n",
    "sc = 30\n",
    "rc = 43\n",
    "lists          = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)]\n",
    "lists          = lists[~np.isnan(lists.zLL.values)]\n",
    "stimNum_all    = lists.Num.values.astype('int')\n",
    "n= 100\n",
    "if len(stimNum_all)>0:\n",
    "    resp           = ff.lp_filter(np.nanmean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "    fig   = plt.figure(figsize=(10,10) )\n",
    "    plt.suptitle(labels_all[sc]+' -- '+labels_all[rc]+', Distance: '+str(np.round(lists.d.values[0],2))+'mm')\n",
    "    gs    = fig.add_gridspec(2,1)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "    ax   = fig.add_subplot(gs[0,0])\n",
    "\n",
    "    plt.xlim([-1, 1])\n",
    "    \n",
    "    plt.axvspan(0.01, w, alpha=0.2, color=[1,0,0])\n",
    "    plt.axvspan(0.015+w/2,0.015+3*w/2, color=[1,0.5,0], alpha=0.1)\n",
    "    for k in range(len(stimNum_all)):\n",
    "        plt.plot(x_ax, ff.lp_filter(EEG_resp[rc,stimNum_all[k],:],45,Fs))\n",
    "    plt.plot(x_ax,resp, c=[0,0,0], linewidth=3, label='mean resp, n:'+str(len(stimNum_all)))\n",
    "    plt.title('Mean Responses')\n",
    "    #plt.legend(bbox_to_anchor=(1.05,1), loc='upper left')\n",
    "    plt.ylim([-np.min([np.max([150,np.max(abs(resp))*2]),800]),np.min([np.max([150,np.max(abs(resp))*2]),800])])\n",
    "    #plt.ylim([-100,100])\n",
    "    plt.ylabel('[uV/ms]')\n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    ax   = fig.add_subplot(gs[1,0], sharex=ax)\n",
    "\n",
    "    \n",
    "    LL_resp   = get_LL_all(np.expand_dims(np.expand_dims(resp, axis=0),0), Fs, w, 1, 0)\n",
    "    LL_resp   = LL_resp[0,0]\n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    #plt.axvline(0+0.01+w/2, c=[0,0,0])\n",
    "    #plt.axvspan(0.01+w/2, resp, alpha=0.8, color=color_elab[1])\n",
    "\n",
    "   # for k in range(n):\n",
    "   #     plt.plot(x_ax,LL_BL[k], c=color_elab[0],alpha=0.7, linewidth=3)\n",
    "   #     #plt.plot(x_ax,LL_resp[k], c=[0,0,0], linewidth=3)\n",
    "    plt.plot(x_ax,LL_resp, c=[0,0,0], linewidth=3)\n",
    "    plt.plot(np.argmax(LL_resp[np.int64(Fs*(1.01+w/2)):np.int64(Fs*(1.01+1.5*w))])/Fs+0.01+w/2,np.max(LL_resp[np.int64(Fs*(1.01+w/2)):np.int64(Fs*(1.01+1.5*w))]), 'or')\n",
    "    plt.title('LL of Mean Responses')\n",
    "    #plt.axhline(np.percentile(LL_BL[:,0:np.int64(2*Fs)],99), c=[1,0,0], label ='99th percentile, entire 2s')#0:np.int64((1-w/2)*Fs)\n",
    "    LL_meregd = np.concatenate([LL_BL, np.expand_dims(LL_resp,0)])\n",
    "    #plt.axhline(np.percentile(LL_meregd[:,0:np.int64((2)*Fs)],99), c=[0.8,0,1], label ='99th percentile')#0:np.int64((1-w/2)*Fs)\n",
    "    #plt.axhline(np.percentile(LL_resp[0:np.int64((1-w/2)*Fs)],99), c=[0.8,0,1], label ='99th percentile')#0:np.int64((1-w/2)*Fs)\n",
    "    \n",
    "    \n",
    "    plt.ylim([0,np.max([2,LL_resp[np.int64(Fs*(1.01+w/2))]*1.1])])\n",
    "    #plt.ylim([0,1.5])\n",
    "    plt.ylabel('0.25s LL [uV/ms]')\n",
    "\n",
    "    thr        = np.percentile(LL_resp[0:np.int64((1-w/2)*Fs)],99)\n",
    "    plt.axhline(thr, c=[1,0,0], label ='99th percentile')#0:np.int64((1-w/2)*Fs)\n",
    "    plt.axvline(0.01+w/2, c=[1,0,0], alpha=0.8)\n",
    "    plt.axvline(0.01+w, c=[1,0.5,0], alpha=0.8)\n",
    "    plt.legend()\n",
    "    if  all(LL_resp[np.int64((1.015+w/2)*Fs):np.int64((1.015+1.5*w)*Fs)]>thr):\n",
    "        print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.1\n",
    "d = 15\n",
    "\n",
    "c = 1\n",
    "dat      = LL_CCEP[~(LL_CCEP['Chan'].isin(bad_chans))]\n",
    "\n",
    "k        = np.random.randint(0, len(dat))\n",
    "stimNum  = np.int64(dat.Num.values[k])\n",
    "sc = 36#np.int64(dat.Stim.values[k])\n",
    "rc = 28#np.int64(dat.Chan.values[k])\n",
    "n= 10\n",
    "lists          = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)]\n",
    "lists          = lists[~np.isnan(lists.zLL.values)]\n",
    "stimNum_all    = lists.Num.values.astype('int')\n",
    "if len(stimNum_all)>0:\n",
    "    list_BL        = LL_CCEP[(LL_CCEP.RespR==0)&(LL_CCEP['d']>20)&(LL_CCEP['Chan']==rc)&~(LL_CCEP['Stim']==sc)&~np.isnan(LL_CCEP.zLL.values)]\n",
    "    stimNum_BL     = list_BL.Num.values.astype('int')\n",
    "    resp           = ff.lp_filter(np.nanmean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "    resp_BL        = np.zeros((n, np.sum(abs(dur))*Fs))\n",
    "    #resp           = np.zeros((n, np.sum(abs(dur))*Fs))\n",
    "    for k in range(n):\n",
    "        resp_BL[k,:] = ff.lp_filter(np.nanmean(EEG_resp[rc,np.random.choice(stimNum_BL, len(stimNum_all)),:],0),45,Fs)\n",
    "        #resp[k,:] = ff.lp_filter(np.nanmean(EEG_resp[rc,np.random.choice(stimNum_all, j),:],0),45,Fs)\n",
    "    LL_BL     = get_LL_all(np.expand_dims(resp_BL, axis=0), Fs, w, 1, 0)\n",
    "    #LL_resp   = get_LL_all(np.expand_dims(resp, axis=0), Fs, w, 1, 0)\n",
    "    LL_resp   = get_LL_all(np.expand_dims(np.expand_dims(resp, axis=0),0), Fs, w, 1, 0)\n",
    "    LL_BL     = LL_BL[0]\n",
    "    LL_resp   = LL_resp[0,0]\n",
    "\n",
    "    #####figure \n",
    "    fig   = plt.figure(figsize=(10,10) )\n",
    "    plt.suptitle(labels_all[sc]+' -- '+labels_all[rc]+', Distance: '+str(np.round(lists.d.values[0],2))+'mm')\n",
    "    gs    = fig.add_gridspec(2,1)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "    ax   = fig.add_subplot(gs[0,0])\n",
    "\n",
    "    plt.xlim([-1, 1])\n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    plt.axvspan(0.015, 0.015+w, alpha=0.2, color=[1,0,0])\n",
    "    plt.axvspan(0.015+w/2,0.015+3*w/2, color=[1,0.5,0], alpha=0.1)\n",
    "    for k in range(n):\n",
    "        plt.plot(x_ax,resp_BL[k], c=color_elab[0],alpha=0.7, linewidth=3, label='time surr '+str(k))\n",
    "        #plt.plot(x_ax,resp[k], c=[0,0,0], linewidth=3, label='mean resp, n:'+str(len(stimNum_all)))\n",
    "    plt.plot(x_ax,resp, c=[0,0,0], linewidth=3, label='mean resp, n:'+str(len(stimNum_all)))\n",
    "    plt.title('Mean Responses')\n",
    "    plt.legend(bbox_to_anchor=(1.05,1), loc='upper left')\n",
    "    plt.ylim([-np.max([100,np.max(abs(resp))*1.1]),np.max([100,np.max(abs(resp))*1.1])])\n",
    "    #plt.ylim([-100,100])\n",
    "    plt.ylabel('[uV/ms]')\n",
    "    ax   = fig.add_subplot(gs[1,0], sharex=ax)\n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    #plt.axvline(0+0.01+w/2, c=[0,0,0])\n",
    "    #plt.axvspan(0.01+w/2, resp, alpha=0.8, color=color_elab[1])\n",
    "\n",
    "    for k in range(n):\n",
    "        plt.plot(x_ax,LL_BL[k], c=color_elab[0],alpha=0.7, linewidth=3)\n",
    "        #plt.plot(x_ax,LL_resp[k], c=[0,0,0], linewidth=3)\n",
    "    plt.plot(x_ax,LL_resp, c=[0,0,0], linewidth=3)\n",
    "    #plt.plot(np.argmax(LL_resp[np.int64(Fs*(1.01+w/2)):np.int64(Fs*(1.01+1.5*w))])/Fs+0.01+w/2,np.max(LL_resp[np.int64(Fs*(1.01+w/2)):np.int64(Fs*(1.01+1.5*w))]), 'or')\n",
    "    plt.title('LL of Mean Responses')\n",
    "    #plt.axhline(np.percentile(LL_BL[:,0:np.int64(2*Fs)],99), c=[1,0,0], label ='99th percentile, entire 2s')#0:np.int64((1-w/2)*Fs)\n",
    "    LL_meregd = np.concatenate([LL_BL, np.expand_dims(LL_resp,0)])\n",
    "    #plt.axhline(np.percentile(LL_meregd[:,0:np.int64((2)*Fs)],99), c=[0.8,0,1], label ='99th percentile')#0:np.int64((1-w/2)*Fs)\n",
    "    #plt.axhline(np.percentile(LL_resp[0:np.int64((1-w/2)*Fs)],99), c=[0.8,0,1], label ='99th percentile')#0:np.int64((1-w/2)*Fs)\n",
    "    \n",
    "    \n",
    "    plt.ylim([0,np.max([2,LL_resp[np.int64(Fs*(1.01+w/2))]*1.1])])\n",
    "    #plt.ylim([0,1.5])\n",
    "    plt.ylabel(str(w)+'s LL [uV/ms]')\n",
    "\n",
    "    thr        = np.percentile(LL_meregd[0:np.int64((1-w/2-0.05)*Fs)],99)\n",
    "    plt.axhline(thr, c=[1,0,0], label ='99th percentile')#0:np.int64((1-w/2)*Fs)\n",
    "    plt.legend()\n",
    "    plt.axvline(0.01+w/2, c=[1,0,0], alpha=0.8)\n",
    "    plt.axvline(0.01+w, c=[1,0.5,0], alpha=0.8)\n",
    "    #plt.axvspan((0.015+0.5*w), (0.015+1*w), alpha=0.2, color=[1,0,0])\n",
    "    LL_meregd = np.concatenate([LL_BL, np.expand_dims(LL_resp,0)])\n",
    "    thr        = np.percentile(LL_meregd[0:np.int64((1-w/2-0.05)*Fs)],99)\n",
    "    if  np.mean(LL_resp[np.int64((1.01+w/2)*Fs):np.int64((1+w)*Fs)]>thr)>0.9:\n",
    "        print('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LL_all(data, Fs,win, t0, IPI):  # specific for Int and IPI\n",
    "    t1                  = np.int64(t0 * Fs) #start conditioning stim, time zero\n",
    "    t2                  = np.int64((t0 + IPI / 1000) * Fs)#start probing stim\n",
    "    #blank out stim artifact\n",
    "    #data[:, :, np.int(t1 - 0.002 * Fs):np.int(t1 + 0.01 * Fs)] = 0\n",
    "    #data[:, :, np.int(t2 - 0.002 * Fs):np.int(t2 + 0.01 * Fs)] = 0\n",
    "    #wdp         = np.int(Fs * wdp_S)  # sliding window size in samples\n",
    "    wdp         = np.int64(Fs * win)  # 100ms -> 50 sample points\n",
    "    EEG_pad     = np.pad(data, [(0, 0), (0, 0), (np.int64(wdp / 2), np.int64(wdp / 2))], 'reflect')  # (18, 3006)\n",
    "    LL_trial    = np.zeros((data.shape[0], data.shape[1], data.shape[2]))\n",
    "    LL_max      = np.zeros((data.shape[0], data.shape[1], 2))\n",
    "    for i in range(data.shape[2]):  # entire response\n",
    "        n                       = i + np.int64(wdp / 2)\n",
    "        LL_trial[:, :, i]       = np.nansum(abs(np.diff(EEG_pad[:, :, n - np.int64(wdp / 2):n + np.int64(wdp / 2)], axis=-1)),\n",
    "                                   axis=-1)/(win*1000)\n",
    " # onset in ms after probing pulse, must be at least 10ms + half of the sliding window to not include fake data\n",
    "    return LL_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-promise",
   "metadata": {},
   "source": [
    "### pk of mean method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sign resp channels\n",
    "# LL_CCEP= LL_CCEP.drop(columns='RespC')\n",
    "LL_CCEP.insert(0,'RespC', 0)\n",
    "t0    = 1\n",
    "w     = 0.2\n",
    "Stims = np.unique(LL_CCEP.Stim)\n",
    "for i in range(len(Stims)):\n",
    "    sc = Stims[i]\n",
    "    for rc in range(len(labels_all)):\n",
    "        lists          = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)]\n",
    "        lists          = lists[~np.isnan(lists.zLL.values)]\n",
    "        stimNum_all    = lists.Num.values.astype('int')\n",
    "        if len(stimNum_all)>0:\n",
    "            resp           = ff.lp_filter(np.nanmean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "            resp_BL = np.zeros((n, np.sum(abs(dur))*Fs))\n",
    "            for k in range(n):\n",
    "                resp_BL[k,:] = ff.lp_filter(np.nanmean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "            pk             = np.max(abs(resp[np.int64((t0+0.015)*Fs):np.int64((t0+w)*Fs)]))\n",
    "            BL_m           = np.nanmean(resp[0:np.int64((t0-0.1)*Fs)])\n",
    "            BL_s           = np.nanstd(resp[0:np.int64((t0-0.1)*Fs)])\n",
    "            if pk > BL_m+6*BL_s:\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = 1       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[(dat.Num==stimNum)&(dat.Chan== rc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "### single trial example\n",
    "\n",
    "r = 1 #&(LL_CCEP['LL'] <1)\n",
    "a = 0\n",
    "dat      = LL_CCEP[~(LL_CCEP['Chan'].isin(bad_chans))&(LL_CCEP['d']>70)&(LL_CCEP['LL']>10)&(LL_CCEP['RespC'] ==1)]\n",
    "\n",
    "k        = np.random.randint(0, len(dat))\n",
    "stimNum  = np.int64(dat.Num.values[k])\n",
    "Stim_chs = np.int64(dat.Stim.values[k])\n",
    "\n",
    "ChanP = StimChanSM[np.array(np.where(np.array(StimChans) == labels_all[Stim_chs]))[0,0]]\n",
    "rc    = np.int64(dat.Chan.values[k])\n",
    "# find other stimulations\n",
    "lists = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==Stim_chs)]\n",
    "lists = lists[~np.isnan(lists.zLL.values)]\n",
    "\n",
    "fig   = plt.figure(figsize=(10,5) )\n",
    "#plt.title(labels_all[Stim_chs]+' -- '+labels_clinic[rc])\n",
    "plt.title(labels_all[Stim_chs]+' -- '+labels_all[rc]+', Dist: '+str(np.round(dat.d.values[k]))+'mm')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlim([-0.6,1])\n",
    "plt.ylim([-np.max([np.max(EEG_resp[rc,stimNum,:])*1.1,800]),np.max([np.max(EEG_resp[rc,stimNum,:])*1.1,500])])\n",
    "plt.axvline(0, c=[0,0,0])\n",
    "plt.xlabel('time [s]')\n",
    "plt.text(-0.3, 200, 'rLL: '+str(np.round(dat.rLL.values[k],2)), c=[1-r,0,0])\n",
    "plt.text(-0.3, 300, 'zLL: '+str(np.round(dat.zLL.values[k],2)), c=[0,0,0])\n",
    "plt.text(-0.3, 100, 'LL: '+str(np.round(dat.LL.values[k],2)), c=[0,0,0])\n",
    "\n",
    "\n",
    "#stim_spec                = stimlist[(stimlist.condition>0)&(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "stimNum_all                  = lists.Num.values.astype('int')\n",
    "plt.plot(x_ax,ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs), c=[0,0,0], linewidth=1, label='mean, n='+str(len(stimNum_all)))\n",
    "plt.plot(x_ax,ff.lp_filter(EEG_resp[rc,stimNum,:],45,Fs), c=color_elab[0], linewidth=2, label='trial')\n",
    "plt.axvspan(t_0+w_r-1, t_0-1+w_LL, alpha=0.3, color=color_elab[0])\n",
    "plt.axvspan(t_0+0.015-1, t_0+w_r-1, alpha=0.8, color=color_elab[1])\n",
    "plt.axvspan(t_0+0.015-1-0.2, t_0+w_r-1-0.2, alpha=0.8, color=color_elab[1])\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â  butterlfy example\n",
    "rc =28\n",
    "Stim_chs = 36#rc-2# 22\n",
    "lists = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==Stim_chs)]\n",
    "lists = lists[~np.isnan(lists.zLL.values)]\n",
    "fig   = plt.figure(figsize=(10,7))\n",
    "plt.title(labels_clinic[Stim_chs]+' -- '+labels_clinic[rc])\n",
    "#plt.title(labels_all[Stim_chs]+' -- '+labels_clinic[rc]+', Dist: '+str(np.round(dat.d.values[k]))+'mm')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlim([-0.2,0.3])\n",
    "plt.ylim([-np.max([np.min([np.max(EEG_resp[rc,stimNum,:])*1.1,900]),300]),np.max([np.min([np.max(EEG_resp[rc,stimNum,:])*1.1,900]),300])])\n",
    "\n",
    "plt.xlabel('time [s]')\n",
    "#plt.text(-0.6, 200, 'rLL: '+str(np.round(dat.rLL.values[k],2)), c=[1-r,0,0])\n",
    "#plt.text(-0.6, 300, 'zLL: '+str(np.round(dat.zLL.values[k],2)), c=[1-a,0,0])\n",
    "axes = plt.gca()\n",
    "\n",
    "#stim_spec                = stimlist[(stimlist.condition>0)&(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "stimNum_all                  = lists.Num.values.astype('int')\n",
    "for i in range(len(stimNum_all)):\n",
    "        plt.plot(x_ax,ff.lp_filter(EEG_resp[rc,stimNum_all[i],:],45,Fs), c=color_elab[1], linewidth=1)\n",
    "plt.plot(x_ax,ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs), c=[0,0,0], linewidth=3)\n",
    "#plt.text(-0.7, axes.get_ylim()[0]*2/3, 'n: '+str(len(stimNum_all)))\n",
    "plt.axvline(0, c=[0,0,0])\n",
    "plt.axvline(0.015, c=[0,0,0], linewidth=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "## single trial and mean\n",
    "r =0 #&(LL_CCEP['LL'] <1)\n",
    "d = 8\n",
    "ll = 0\n",
    "dat      = LL_CCEP[~(LL_CCEP['Chan'].isin(bad_chans))&(LL_CCEP['RespC'] ==1)&(LL_CCEP['LL'] >ll)&(LL_CCEP['d'] >d)&(LL_CCEP['RespR'] ==r)]\n",
    "\n",
    "k        = np.random.randint(0, len(dat))\n",
    "stimNum  = np.int64(dat.Num.values[k])\n",
    "Stim_chs = np.int64(dat.Stim.values[k])\n",
    "\n",
    "ChanP = StimChanSM[np.array(np.where(np.array(StimChans) == labels_all[Stim_chs]))[0,0]]\n",
    "rc    = np.int64(dat.Chan.values[k])\n",
    "# find other stimulations\n",
    "lists = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==Stim_chs)]\n",
    "lists = lists[~np.isnan(lists.zLL.values)]\n",
    "stimNum_all                  = lists.Num.values.astype('int')\n",
    "resp = ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "fig   = plt.figure(figsize=(10,10) )\n",
    "plt.suptitle(labels_all[Stim_chs]+' -- '+labels_all[rc]+', Dist: '+str(np.round(dat.d.values[k]))+'mm')\n",
    "gs    = fig.add_gridspec(2,1)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "ax   = fig.add_subplot(gs[0,0])\n",
    "\n",
    "plt.xlim([-1,0.5])\n",
    "plt.ylim([-np.min([np.max([np.max(abs(EEG_resp[rc,stimNum,:]))*1.1,400]), 800]),np.min([np.max([np.max(abs(EEG_resp[rc,stimNum,:]))*1.1,400])])])\n",
    "plt.axvline(0, c=[0,0,0])\n",
    "plt.text(-0.7, 200, 'rLL: '+str(np.round(dat.rLL.values[k],2)), c=[1-r,0,0])\n",
    "plt.text(-0.7, 300, 'zLL: '+str(np.round(dat.zLL.values[k],2)), c=[0,0,0])\n",
    "plt.text(-0.7, 100, 'LL: '+str(np.round(dat.LL.values[k],2)), c=[0,0,0])\n",
    "plt.axvspan(t_0+w_r-1, t_0-1+w_LL, alpha=0.3, color=color_elab[0] )\n",
    "plt.axvspan(t_0+0.015-1, t_0+w_r-1, alpha=0.8, color=color_elab[1])\n",
    "plt.axvspan(t_0+0.015-1-0.2, t_0+w_r-1-0.2, alpha=0.8, color=color_elab[1])\n",
    "plt.plot(x_ax,ff.lp_filter(EEG_resp[rc,stimNum,:],45,Fs), c=color_elab[0], linewidth=3)\n",
    "plt.plot(x_ax,resp, c=[0,0,0],alpha=0.7, linewidth=3, label='mean, n='+str(len(stimNum_all)))\n",
    "plt.legend()\n",
    "plt.title('Trial')\n",
    "\n",
    "#plt.title(labels_all[Stim_chs]+' -- '+labels_clinic[rc]+', Dist: '+str(np.round(dat.d.values[k]))+'mm')\n",
    "\n",
    "\n",
    "ax   = fig.add_subplot(gs[1,0], sharex=ax)\n",
    "plt.xlabel('time [s]')\n",
    "axes = plt.gca()\n",
    "plt.title('MEAN')\n",
    "plt.plot(x_ax,resp, c=[0,0,0],alpha=0.7, linewidth=3, label = 'mean resp')\n",
    "plt.plot(x_ax,abs(resp), c=[0,0,0], linewidth=1, label = 'abs mean resp')\n",
    "plt.axhline(np.max(abs(resp)[np.int64((t0+0.015)*Fs):np.int64((t0+0.2)*Fs)]), c=color_elab[0], label = 'peak resp')\n",
    "plt.axhline(np.mean(resp[0:np.int64((t0-0.1)*Fs)])+6*np.std(abs(resp)[0:np.int64((t0-0.1)*Fs)]), c=[1,0,0], label = 'thr: zscore of 6')\n",
    "plt.axhline(np.mean(resp[0:np.int64((t0-0.1)*Fs)]), alpha=0.1, c=[1,0,0])\n",
    "\n",
    "#plt.text(-0.7, axes.get_ylim()[0]*2/3, 'n: '+str(len(stimNum_all)))\n",
    "plt.axvline(0, c=[0,0,0])\n",
    "plt.legend()\n",
    "#plt.ylim([-100, 100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-final",
   "metadata": {},
   "source": [
    "## PCIst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-kruger",
   "metadata": {},
   "source": [
    "https://github.com/renzocom/PCIst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capital-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "par      = {'baseline_window':(-0.5, -0.02), 'response_window':(0.02,0.5), 'k':1.2, 'min_snr':1.1, 'max_var':99, 'embed':False,'n_steps':5} #\n",
    "hour     = np.unique(LL_CCEP.Hour)\n",
    "M_PCI    = np.zeros((len(np.unique(LL_CCEP.Stim)), 24))\n",
    "resp_all = np.zeros((len(np.unique(LL_CCEP.Stim)), len(labels_all),24, 2000))\n",
    "for i in range(24):\n",
    "    for j in range(len(np.unique(LL_CCEP.Stim))):\n",
    "        sc      = np.int64(np.sort(np.unique(LL_CCEP.Stim))[j])\n",
    "        \n",
    "        lists     = LL_CCEP[(LL_CCEP['Stim']==sc)&(LL_CCEP['Hour']==i)]\n",
    "        if len(lists)>0:\n",
    "            list_nan  = lists[np.isnan(lists.LL.values)]\n",
    "            stimNum   = np.int64(np.unique(lists.Num))\n",
    "            resp      = ff.lp_filter(EEG_resp[:,stimNum,:],40,Fs)\n",
    "            # remove bad combinations\n",
    "            for k in range(len(list_nan)):\n",
    "                n = np.int64(list_nan.Num.values[k])\n",
    "                n = np.where(stimNum== n)[0][0]\n",
    "                resp[np.int64(list_nan.Chan.values[k]),n,:] = np.nan\n",
    "            if len(resp)>0:\n",
    "                mean_resp          = np.nanmean(resp, 1)\n",
    "                resp_all[j,:,i,:]  = mean_resp\n",
    "                if np.nanmean(abs(mean_resp))>0: \n",
    "                    PCIst              =  pci.calc_PCIst(np.nan_to_num(mean_resp), np.arange(-1,3, 1/Fs), **par)\n",
    "                    M_PCI[j,i]         = PCIst\n",
    "                else:# if all data are nan\n",
    "                    M_PCI[j,i]         = -1\n",
    "        else:\n",
    "                M_PCI[j,i]         = -1\n",
    "                resp_all[j,:,i,:]  = np.nan\n",
    "                \n",
    "labels_stims = labels_all[np.int64(np.sort(np.unique(LL_CCEP.Stim)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_patient + '/Analysis/BrainMapping/PCI/PCI_h.npy', M_PCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(path_patient + '/Analysis/BrainMapping/PCI/figures/')\n",
    "    os.mkdir( path_patient + '/Analysis/BrainMapping/PCI/')\n",
    "    \n",
    "except OSError:\n",
    "    print(\"test already exists\")\n",
    "filename     = path_patient + '/Analysis/BrainMapping/PCI/figures/PCI_hours.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-mumbai",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 73\n",
    "fig, axs = plt.subplots(4,6, figsize=(25,15), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = .1, wspace=.1)\n",
    "plt.suptitle(labels_stims[sc])\n",
    "axs = axs.ravel()\n",
    "for i in range(24):\n",
    "    axs[i].set_title(str(i)+':00, PCI: '+str(np.round(M_PCI[sc,i])))\n",
    "    axs[i].set_yticks([])\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_ylim(-700, 700)\n",
    "    axs[i].set_xlim(-0.5, 1)\n",
    "    axs[i].axvline(0, c=[0,0,0])\n",
    "    for c in range(len(labels_all)):\n",
    "        axs[i].plot(x_ax,resp_all[sc,c,i,:] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-emergency",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename     = path_patient + '/Analysis/BrainMapping/PCI/figures/PCI_hours.png'\n",
    "\n",
    "# Plot distance matrix.\n",
    "#cmap     = ListedColormap(['r', 'k', 'w'])\n",
    "fig      = pylab.figure(figsize=(15,15))\n",
    "axmatrix = fig.add_axes([0.15,0.05,0.7,0.9])#fig.add_axes([0.4,0.1,0.6,0.6])\n",
    "\n",
    "im = axmatrix.matshow(M_PCI, aspect='auto', origin='lower',cmap='hot', vmin=np.percentile(M_PCI,30), vmax=np.percentile(M_PCI,95))\n",
    "\n",
    "plt.xticks(np.arange(0, 24, 6));\n",
    "plt.xlabel('Time of the day')\n",
    "plt.yticks(range(len(StimChans)), labels_stims);\n",
    "#plt.axvline(15, c=[0,0,0], linewidth=35)\n",
    "# Plot colorbar.\n",
    "axcolor = fig.add_axes([0.9,0.05,0.01,0.9])\n",
    "pylab.colorbar(im, cax=axcolor)\n",
    "plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-marble",
   "metadata": {},
   "source": [
    "## CCEP CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_CCEP = pd.read_csv(path_patient + '/Analysis/BrainMapping/LL/LL_CCEP_'+str(exp)+'_'+str(w)+'s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all[StimChanNums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-charter",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = np.unique(LL_CCEP.loc[(LL_CCEP.LL >0)&(LL_CCEP.RespC ==1)&(LL_CCEP.Stim ==s), 'Chan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-movement",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours    = np.unique(LL_CCEP.Hour)\n",
    "StimChanNums = np.sort(StimChanIx)\n",
    "M_hour   = np.zeros((len(labels_all), len(labels_all), len(hours)))\n",
    "M_resp   = np.zeros((len(labels_all), len(labels_all)))\n",
    "\n",
    "for sc in range(len(StimChans)):\n",
    "    s      = StimChanNums[sc]\n",
    "    dat    = LL_CCEP.loc[(LL_CCEP.LL >0)&(LL_CCEP.RespC ==1)&(LL_CCEP.Stim ==s)]\n",
    "    cs     = np.unique(LL_CCEP.loc[(LL_CCEP.LL >0)&(LL_CCEP.RespC ==1)&(LL_CCEP.Stim ==s), 'Chan'])\n",
    "    if len(dat)>0:\n",
    "        for c in cs:\n",
    "            c = np.int64(c)\n",
    "            for hs in range(len(hours)):\n",
    "                h              = hours[hs]\n",
    "                M_hour[s,c,hs] = np.nanmean(dat.loc[(dat.Hour ==h)&(dat.Chan ==c), 'LL'].values)\n",
    "            \n",
    "M_hour=np.nan_to_num(M_hour, -2)\n",
    "M_hour[:,bad_chans,:] = -2\n",
    "M_resp[:,bad_chans] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "##test single plot\n",
    "h        = 3\n",
    "fig      = pylab.figure(figsize=(20,20))\n",
    "axmatrix = fig.add_axes([0.1,0.1,0.9,0.9])\n",
    "\n",
    "im = axmatrix.matshow(M_hour[:,:,h], aspect='auto', origin='lower', cmap='hot', vmin=1, vmax=10)\n",
    "\n",
    "plt.xticks(range(len(labels_all)), labels_all, rotation=90)\n",
    "plt.yticks(range(len(labels_all)), labels_all)\n",
    "plt.xlabel(str(h)+':00', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-catering",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(path_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â GIF\n",
    "path_fig   = path_patient + '/Analysis/BrainMapping/LL/figures/LL_dist'\n",
    "hours      = np.unique(LL_CCEP.Hour)\n",
    "n_frames   = len(hours)\n",
    "gif_name   = 'scatter'\n",
    "\n",
    "print('Creating charts\\n')\n",
    "filenames = []\n",
    "\n",
    "for i in np.arange(n_frames):\n",
    "    # plot\n",
    "    #fig, ax    = plt.subplots(figsize=(12, 8))\n",
    "    fig   = plt.figure(figsize=(15,8) )\n",
    "    gs    = fig.add_gridspec(1,2, width_ratios=[20,1])  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "    ax   = fig.add_subplot(gs[0,0])\n",
    "    #ax.set_facecolor(bg_color)\n",
    "    data     = LL_CCEP[~(LL_CCEP['Chan'].isin(bad_chans))&(LL_CCEP.Hour ==hours[i])&(LL_CCEP.d >7.5)&(LL_CCEP['RespR'] ==1)&(LL_CCEP['RespC'] ==1)]\n",
    "    #dataR    = LL_CCEP[~(LL_CCEP['Chan'].isin(bad_chans))&(LL_CCEP.Hour ==hours[i])&(LL_CCEP.d >7.5)&(LL_CCEP['RespR'] ==0)&(LL_CCEP['RespC'] ==1)]\n",
    "    data0    = LL_CCEP[~(LL_CCEP['Chan'].isin(bad_chans))&(LL_CCEP.Hour ==hours[i])&(LL_CCEP.d >7.5)&(LL_CCEP['RespC'] ==0)]\n",
    "    n_all  = len(LL_CCEP[~(LL_CCEP['Chan'].isin(bad_chans))&(LL_CCEP.Hour ==hours[i])&(LL_CCEP.d >7.5)])\n",
    "    n_resp = len(data)\n",
    "    #axs.scatter(data.Distance, data['LL norm'], 5, c=\"g\", alpha=1, label = 'LL')\n",
    "    plt.plot(data0.d, data0['LL'], 'o', c=[0,0,0], label = 'non-resp channel', mfc='none', alpha=0.25)\n",
    "    plt.plot(dataR.d, dataR['LL'], 'o', c=color_elab[1], label = 'non-resp ratio', alpha=0.45)\n",
    "    plt.plot(data.d, data['LL'], 'o', c=color_elab[0], label = 'resp')\n",
    "    plt.ylim([0,20])\n",
    "    plt.xlim([0,120])\n",
    "    plt.xlabel('distance [mm]')\n",
    "    plt.ylabel('LL [uV/ms]')\n",
    "    plt.legend()\n",
    "    plt.title(str(np.int(hours[i]))+':00 --- Resp = '+str(np.round(n_resp/n_all,4)*100)+'%')\n",
    "    \n",
    "    # remove spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    # grid\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.yaxis.grid(color='gray', linestyle='dashed', alpha=0.7)\n",
    "    ax = fig.add_subplot(gs[0,1])\n",
    "    n_stim = len(data)\n",
    "    plt.title('number of valid recordings: '+str(n_all))\n",
    "    plt.bar(1,n_resp/n_all*100+len(dataR)/n_all*100+len(data0)/n_all*100, color=[0,0,0])\n",
    "    plt.bar(1,n_resp/n_all*100+len(dataR)/n_all*100, color=color_elab[1])\n",
    "    plt.bar(1,n_resp/n_all*100, color=color_elab[0])\n",
    "    plt.ylim([0,100])\n",
    "    plt.xlim([0.5,1.5])\n",
    "    plt.xticks([])\n",
    "    plt.ylabel('%')\n",
    "    # build file name and append to list of file names\n",
    "    filename = path_fig+'/frame_'+str(i)+'.png'\n",
    "    filenames.append(filename)\n",
    "\n",
    "    # last frame of each viz stays longer\n",
    "    if (i == n_frames):\n",
    "        for i in range(5):\n",
    "            filenames.append(filename)\n",
    "    # save img\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "print('Charts saved\\n')\n",
    "# Build GIF\n",
    "print('Creating gif\\n')\n",
    "with imageio.get_writer(path_fig+'/scatter.gif', mode='I') as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "print('Gif saved\\n')\n",
    "print('Removing Images\\n')\n",
    " # Remove files\n",
    "for filename in set(filenames):\n",
    "    os.remove(filename)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â GIF BM\n",
    "path_fig  = path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot'\n",
    "n_frames   = len(hours)\n",
    "if not os.path.exists(path_fig):\n",
    "    os.makedirs(path_fig)\n",
    "    \n",
    "print('Creating charts\\n')\n",
    "filenames = []\n",
    "for i in np.arange(n_frames):\n",
    "    fig      = pylab.figure(figsize=(20,20))\n",
    "    axmatrix = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "\n",
    "    im = axmatrix.matshow(M_hour[:,:,i], aspect='auto', origin='lower', cmap='hot', vmin=0.5, vmax=10)\n",
    "\n",
    "    plt.xticks(range(len(labels_all)), labels_all, rotation=90)\n",
    "    plt.yticks(range(len(labels_all)), labels_all)\n",
    "    plt.xlabel(str(i)+':00', fontsize=16)\n",
    "\n",
    "    # build file name and append to list of file names\n",
    "    filename = path_fig+'/frame_'+str(i)+'.png'\n",
    "    filenames.append(filename)\n",
    "\n",
    "    # save img\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "print('Charts saved\\n')\n",
    "# Build GIF\n",
    "print('Creating gif\\n')\n",
    "with imageio.get_writer(path_fig+'/BM_LL.gif', mode='I') as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "print('Gif saved\\n')\n",
    "print('Removing Images\\n')\n",
    " # Remove files\n",
    "for filename in set(filenames):\n",
    "    os.remove(filename)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc     = 8\n",
    "rc     =  5\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title(labels_all[sc]+'-->'+labels_all[rc])\n",
    "# stim_spec                = stimlist[(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "# stimNum_all                  = stim_spec.StimNum.values#[:,0]\n",
    "\n",
    "lists     = LL_CCEP[(LL_CCEP['Stim']==sc)&(LL_CCEP['Chan']==rc)]\n",
    "lists  = lists[~np.isnan(lists.LL.values)]\n",
    "stimNum   = np.int64(np.unique(lists.Num))\n",
    "            \n",
    "color_time = np.zeros((len(stimNum),3))\n",
    "color_time[:,0] = np.linspace(0,1,len(stimNum))\n",
    "\n",
    "for t in range(len(stimNum)):\n",
    "    plt.plot(x_ax,ff.lp_filter(EEG_resp[rc,stimNum[t],:], 30, Fs), c=color_time[t], linewidth=1)\n",
    "plt.plot(x_ax,np.mean(EEG_resp[rc,stimNum,:],0), c=[0,0,0], linewidth=3)\n",
    "plt.xlim([-0.5,1])\n",
    "#plt.ylim([-400,400])\n",
    "plt.axvline(0, c=[0,0,0], linewidth=5)\n",
    "plt.xlabel('time [s]')\n",
    "plt.ylim([-800,800])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-sullivan",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat   = LL_CCEP[~(LL_CCEP['Chan'].isin(bad_chans))&(LL_CCEP.d >60)&(LL_CCEP['RespC']==1)]\n",
    "\n",
    "k       = np.random.randint(0, len(dat))\n",
    "stimNum = np.int(dat.Num.values[k])\n",
    "\n",
    "Stim_chs = np.int(dat.Stim.values[k])\n",
    "ChanP = StimChanNums[np.array(np.where(np.array(StimChans) == labels_all[Stim_chs]))[0,0]]\n",
    "rc = np.int(dat.Chan.values[k])\n",
    "    \n",
    "fig   = plt.figure(figsize=(8,8) )\n",
    "plt.suptitle(labels_all[Stim_chs]+' -- '+labels_all[rc]+', Dist: '+str(np.round(dat.d.values[k]))+'mm')\n",
    "gs    = fig.add_gridspec(2,1)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "axs   = fig.add_subplot(gs[0,0])\n",
    "CCEP_mean = EEG_resp[rc,stimNum,:]\n",
    "#plt.plot(x_ax,CCEP_mean, c=color_elab[1], linewidth=1.5)\n",
    "plt.plot(x_ax,CCEP_mean, c=color_elab[0], linewidth=2.5,alpha=0.5,  label = 'org')\n",
    "plt.plot(x_ax,ff.lp_filter(CCEP_mean, 45,Fs), c=color_elab[2], linewidth=1.5, label = 'LP45Hz')\n",
    "plt.plot(x_ax,ff.lp_filter(CCEP_mean, 30,Fs), c=[0,0,0], linewidth=1.5, label = 'LP30Hz')\n",
    "plt.text(-0.3, 200, 'LL: '+str(np.round(dat.LL.values[k],2)))\n",
    "plt.text(-0.3, 100, 'zLL: '+str(np.round(dat['zLL'].values[k],2)))\n",
    "plt.text(-0.3, 300, 'rLL: '+str(np.round(dat['rLL'].values[k],2)))\n",
    "#plt.xlim([-0.5,1])\n",
    "#plt.ylim([-400,400])\n",
    "plt.axvline(0, c=[0,0,0])\n",
    "plt.xlim([-0.4,1])\n",
    "plt.title('single trial')\n",
    "plt.legend()\n",
    "\n",
    "axs   = fig.add_subplot(gs[1,0], sharex=axs, sharey=axs)\n",
    "stim_spec                = stimlist[(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "stimNum_all                  = stim_spec.StimNum.values#[:,0]\n",
    "\n",
    "for t in range(len(stimNum_all)):\n",
    "    plt.plot(x_ax,ff.lp_filter(EEG_resp[rc,stimNum_all[t],:], 30, Fs), c=color_elab[0], linewidth=1)\n",
    "plt.plot(x_ax,np.mean(EEG_resp[rc,stimNum_all,:],0), c=[0,0,0], linewidth=3)\n",
    "plt.text(-0.3, 100, 'zLL: '+str(np.round(np.mean(LL_CCEP[(LL_CCEP.Chan==rc)&(LL_CCEP.Stim==Stim_chs)]['zLL']),2)))\n",
    "#plt.xlim([-0.5,1])\n",
    "#plt.ylim([-400,400])\n",
    "plt.axvline(0, c=[0,0,0])\n",
    "plt.title('all trials')\n",
    "plt.xlabel('time [s]')\n",
    "#plt.ylim([-15,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-situation",
   "metadata": {},
   "source": [
    "## Asymmetry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_av = StimChanIx\n",
    "for i in range(len(bad_chans)):\n",
    "    stim_av = np.delete(stim_av, np.where(stim_av==bad_chans[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_A[(data_A.R>1.2)&(data_A.d>7.5)]   \n",
    "#data_test = data_A[(data_A.R>0.95)&(data_A.R<1.05)&(data_A.d>7.5)]   \n",
    "k = np.random.choice(len(data_test))\n",
    "c1 = np.int64(data_test.Stim.values[k])\n",
    "c2 = np.int64(data_test.Chan.values[k])\n",
    "lists     = LL_CCEP[(LL_CCEP['Stim']==c1)&(LL_CCEP['Chan']==c2)]\n",
    "lists     = lists[~np.isnan(lists.LL.values)]\n",
    "stimNum   = np.int64(np.unique(lists.Num))\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "gs    = fig.add_gridspec(1,2)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "plt.suptitle(labels_all[c1]+'<-->'+labels_all[c2]+', Dist: '+str(np.round(np.mean(lists.d),1))+'mm')\n",
    "\n",
    "##plot 1\n",
    "ax         = fig.add_subplot(gs[0,0])\n",
    "\n",
    "            \n",
    "color_time = np.zeros((len(stimNum),3))\n",
    "color_time[:,0] = np.linspace(0,1,len(stimNum))\n",
    "plt.title('mean LL: '+str(np.round(np.mean(lists.LL),1))+' uV/ms')\n",
    "for t in range(len(stimNum)):\n",
    "    plt.plot(x_ax,ff.lp_filter(EEG_resp[c2,stimNum[t],:], 30, Fs), c=color_time[t], linewidth=1)\n",
    "plt.plot(x_ax,np.mean(ff.lp_filter(EEG_resp[c2,stimNum,:], 30, Fs),0), c=[0,0,0], linewidth=3)\n",
    "plt.xlim([-0.3,0.7])\n",
    "#plt.ylim([-400,400])\n",
    "plt.axvline(0, c=[0,0,0], linewidth=5)\n",
    "plt.xlabel('time [s]')\n",
    "plt.text(0.4, 600, 'n: '+str(len(stimNum)))\n",
    "plt.ylim([-800,800])\n",
    "\n",
    "##plot 2\n",
    "ax   = fig.add_subplot(gs[0,1], sharex = ax, sharey=ax)\n",
    "lists     = LL_CCEP[(LL_CCEP['Stim']==c2)&(LL_CCEP['Chan']==c1)]\n",
    "lists  = lists[~np.isnan(lists.LL.values)]\n",
    "stimNum   = np.int64(np.unique(lists.Num))\n",
    "            \n",
    "color_time = np.zeros((len(stimNum),3))\n",
    "color_time[:,0] = np.linspace(0,1,len(stimNum))\n",
    "plt.title('mean LL: '+str(np.round(np.mean(lists.LL),1))+' uV/ms')\n",
    "for t in range(len(stimNum)):\n",
    "    plt.plot(x_ax,ff.lp_filter(EEG_resp[c1,stimNum[t],:], 30, Fs), c=color_time[t], linewidth=1)\n",
    "plt.plot(x_ax,np.mean(ff.lp_filter(EEG_resp[c1,stimNum,:], 30, Fs),0), c=[0,0,0], linewidth=3)\n",
    "\n",
    "plt.text(0.4, 600, 'n: '+str(len(stimNum)))\n",
    "plt.axvline(0, c=[0,0,0], linewidth=5)\n",
    "plt.xlabel('time [s]')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-witch",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 6#np.random.choice(stim_av)\n",
    "c2 = 16 #np.random.choice(stim_av)\n",
    "\n",
    "lists     = LL_CCEP[(LL_CCEP['Stim']==c1)&(LL_CCEP['Chan']==c2)]\n",
    "lists     = lists[~np.isnan(lists.LL.values)]\n",
    "stimNum   = np.int64(np.unique(lists.Num))\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "gs    = fig.add_gridspec(1,2)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "plt.suptitle(labels_all[c1]+'<-->'+labels_all[c2]+', Dist: '+str(np.round(np.mean(lists.d),1))+'mm')\n",
    "\n",
    "##plot 1\n",
    "ax         = fig.add_subplot(gs[0,0])\n",
    "\n",
    "            \n",
    "color_time = np.zeros((len(stimNum),3))\n",
    "color_time[:,0] = np.linspace(0,1,len(stimNum))\n",
    "plt.title('mean LL: '+str(np.round(np.mean(lists.LL),1))+' uV/ms')\n",
    "for t in range(len(stimNum)):\n",
    "    plt.plot(x_ax,ff.lp_filter(EEG_resp[c2,stimNum[t],:], 30, Fs), c=color_time[t], linewidth=1)\n",
    "plt.plot(x_ax,np.mean(ff.lp_filter(EEG_resp[c2,stimNum,:], 30, Fs),0), c=[0,0,0], linewidth=3)\n",
    "plt.xlim([-0.3,0.7])\n",
    "#plt.ylim([-400,400])\n",
    "plt.axvline(0, c=[0,0,0], linewidth=5)\n",
    "plt.xlabel('time [s]')\n",
    "plt.text(0.4, 600, 'n: '+str(len(stimNum)))\n",
    "plt.ylim([-800,800])\n",
    "\n",
    "##plot 2\n",
    "ax   = fig.add_subplot(gs[0,1], sharex = ax, sharey=ax)\n",
    "lists     = LL_CCEP[(LL_CCEP['Stim']==c2)&(LL_CCEP['Chan']==c1)]\n",
    "lists  = lists[~np.isnan(lists.LL.values)]\n",
    "stimNum   = np.int64(np.unique(lists.Num))\n",
    "            \n",
    "color_time = np.zeros((len(stimNum),3))\n",
    "color_time[:,0] = np.linspace(0,1,len(stimNum))\n",
    "plt.title('mean LL: '+str(np.round(np.mean(lists.LL),1))+' uV/ms')\n",
    "for t in range(len(stimNum)):\n",
    "    plt.plot(x_ax,ff.lp_filter(EEG_resp[c1,stimNum[t],:], 30, Fs), c=color_time[t], linewidth=1)\n",
    "plt.plot(x_ax,np.mean(ff.lp_filter(EEG_resp[c1,stimNum,:], 30, Fs),0), c=[0,0,0], linewidth=3)\n",
    "\n",
    "plt.text(0.4, 600, 'n: '+str(len(stimNum)))\n",
    "plt.axvline(0, c=[0,0,0], linewidth=5)\n",
    "plt.xlabel('time [s]')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_asym     = np.zeros((1,6))\n",
    "lists         = LL_CCEP[(LL_CCEP['RespC']==1)]\n",
    "lists         = lists[~np.isnan(lists.LL.values)]\n",
    "for s in range(len(labels_all)):\n",
    "    for c in range(len(labels_all)):\n",
    "        list_1 = lists[(lists.Stim==s)&(lists.Chan==c)]\n",
    "        list_2 = lists[(lists.Stim==c)&(lists.Chan==s)]\n",
    "        if len(list_1)>0 and len(list_2)>0:\n",
    "            val         = np.zeros((1, 6))\n",
    "            val[0, 0]   = c                                         # response channel\n",
    "            val[0, 1]   = s                                         # response channel\n",
    "            val[0, 2]   = np.nanmean(list_1.LL)/np.nanmean(list_2.LL)\n",
    "            val[0, 3]   = np.nanmean(list_1.d)\n",
    "            data_asym    = np.concatenate((data_asym, val), axis=0)\n",
    "data_asym = data_asym[1:-1, :] # remove first row (dummy row)\n",
    "data_A = pd.DataFrame(\n",
    "    {\"Chan\": data_asym[:, 0], \"Stim\": data_asym[:, 1], \"R\": data_asym[:, 2], \"d\": data_asym[:, 3]})\n",
    "\n",
    "for c in range(len(labels_all)):\n",
    "    data_A.loc[(data_A.Chan ==c), \"Recs\"]      = labels_all[c]\n",
    "    data_A.loc[(data_A.Stim ==c), \"Stim Region\"]   = labels_region[c]\n",
    "    data_A.loc[(data_A.Chan ==c), \"Resp Region\"]   = labels_region[c]\n",
    "    data_A.loc[(data_A.Stim ==c), \"Stims\"]     = labels_all[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.figure(figsize=(13,13))\n",
    "\n",
    "fig, ax     = plt.subplots(figsize=(15,12))\n",
    "RR = np.round(1/1.2,2)\n",
    "plt.title(subj+' - Connections with Ratio < '+str(RR))\n",
    "\n",
    "data_test = data_A[(data_A.R<RR)&(data_A.d>7.5)]        \n",
    "for i in range(len(labels_all)):\n",
    "    s = StimChanIx_sort[i]\n",
    "    ax.add_patch(Rectangle((6.5, i-0.5), 1, 1, color = color_regions[np.where(regions==labels_region[s])[0][0]]))\n",
    "    data_plot = data_test[data_test.Stim==s]\n",
    "    for j in range(len(data_plot)):\n",
    "        #plt.plot(data_plot.d.values[j], i,'o', markersize=10, c= color_regions[np.where(regions==data_plot['Resp Region'].values[j])[0][0]])\n",
    "        plt.scatter(data_plot.d.values[j], i, s=80, c=color_regions[np.where(regions==data_plot['Resp Region'].values[j])[0][0]], alpha=0.8, edgecolors=[0,0,0])\n",
    "    if any (region_border == i):\n",
    "        num= region_num[np.where(region_border==i)[0][0]]\n",
    "        t = plt.text(-10, (i+num/2)-1, v[i], fontsize=15)\n",
    "        #t = plt.text(0.5, 0.5, 'text', transform=ax.transAxes, fontsize=30)\n",
    "        t.set_bbox(dict(facecolor=color_regions[np.where(regions==labels_region[s])[0][0]], alpha=0.5, edgecolor=color_regions[np.where(regions==labels_region[s])[0][0]]))\n",
    "\n",
    "\n",
    "plt.yticks(np.arange(len(labels_all)),labels_sort, fontsize=7)\n",
    "plt.xlim([6.5, 80])\n",
    "plt.ylim([-0.5, len(labels_all)-0.5])\n",
    "plt.xlabel('euclidean distance [mm]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-generic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig    = plt.figure(figsize=(12, 6))\n",
    "data_A2 = data_A#[(data_A.Region1!='WM')&(data_A.Region2!='WM')]\n",
    "#axs.scatter(data.Distance, data['LL norm'], 5, c=\"g\", alpha=1, label = 'LL')\n",
    "tissue = np.unique(data_A2.Region2)\n",
    "for i in range(len(tissue)):\n",
    "    data_A3 = data_A2[data_A2.Region2==tissue[i]]\n",
    "    plt.plot(data_A3.d, data_A3['R'], 'o', alpha=0.8, label=tissue[i])\n",
    "\n",
    "plt.xlabel('distance [mm]')\n",
    "plt.ylabel('LL ratio')\n",
    "plt.legend(title='Tissue2')\n",
    "#plt.axhline(1,c=[0,0,0])\n",
    "plt.ylim([1,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig    = plt.figure(figsize=(12, 6))\n",
    "data_A2 = data_A#[(data_A.Region1!='WM')&(data_A.Region2!='WM')]\n",
    "#axs.scatter(data.Distance, data['LL norm'], 5, c=\"g\", alpha=1, label = 'LL')\n",
    "tissue = np.unique(data_A2.Region1)\n",
    "for i in range(len(tissue)):\n",
    "    data_A3 = data_A2[data_A2.Region1==tissue[i]]\n",
    "    plt.plot(data_A3.d, data_A3['R'], 'o', alpha=0.8, label=tissue[i])\n",
    "\n",
    "plt.xlabel('distance [mm]')\n",
    "plt.ylabel('LL ratio')\n",
    "plt.legend(title='Tissue1')\n",
    "#plt.axhline(1,c=[0,0,0])\n",
    "plt.ylim([1,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_hourA        = np.zeros((len(labels_all), len(labels_all), 24))-1\n",
    "# remove bad stims\n",
    "lists         = LL_CCEP[(LL_CCEP['RespC']==1)]\n",
    "lists         = lists[~np.isnan(lists.LL.values)]\n",
    "for h in range(24):\n",
    "    print(h)\n",
    "    for s in range(len(labels_all)):\n",
    "        for c in range(len(labels_all)):\n",
    "            list_1 = lists[(lists.Stim==s)&(lists.Chan==c)&(lists.Hour==h)]\n",
    "            list_2 = lists[(lists.Stim==c)&(lists.Chan==s)&(lists.Hour==h)]\n",
    "            if len(list_1)>0 and len(list_2)>0:\n",
    "                M_hourA[s,c,h] = np.nanmean(list_1.LL)/np.nanmean(list_2.LL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_hourA[M_hourA==-1] =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GIF BM\n",
    "path_fig  = path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot'\n",
    "n_frames   = 24\n",
    "if not os.path.exists(path_fig):\n",
    "    os.makedirs(path_fig)\n",
    "    \n",
    "print('Creating charts\\n')\n",
    "filenames = []\n",
    "for i in np.arange(n_frames):\n",
    "    fig      = pylab.figure(figsize=(20,20))\n",
    "    axmatrix = fig.add_axes([0.1,0.1,0.7,0.7])\n",
    "\n",
    "    im = axmatrix.matshow(M_hourA[:,:,i], aspect='auto', origin='lower', cmap='seismic', vmin=0, vmax=2)\n",
    "\n",
    "    plt.xticks(range(len(labels_all)), labels_all, rotation=90)\n",
    "    plt.yticks(range(len(labels_all)), labels_all)\n",
    "    plt.xlabel(str(i)+':00', fontsize=16)\n",
    "    \n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.9,0.05,0.01,0.9])\n",
    "    pylab.colorbar(im, cax=axcolor)\n",
    "\n",
    "    # build file name and append to list of file names\n",
    "    filename = path_fig+'/frame_'+str(i)+'.png'\n",
    "    filenames.append(filename)\n",
    "\n",
    "    # save img\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "print('Charts saved\\n')\n",
    "# Build GIF\n",
    "print('Creating gif\\n')\n",
    "with imageio.get_writer(path_fig+'/BM_asym.gif', mode='I') as writer:\n",
    "    for filename in filenames:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "print('Gif saved\\n')\n",
    "print('Removing Images\\n')\n",
    " # Remove files\n",
    "#for filename in set(filenames):\n",
    "#    os.remove(filename)\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-smooth",
   "metadata": {},
   "source": [
    "## NETWORK PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import nxviz\n",
    "from nxviz.plots import CircosPlot, MatrixPlot, ArcPlot, BasePlot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-nutrition",
   "metadata": {},
   "source": [
    "G.add_edge(1, 3, weight=7, capacity=15, length=342.7)\n",
    "plt.figure(figsize=(15,15))\n",
    "nx.draw(g, with_labels=True, alpha= 0.6, node_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_graph(nodes_df, edges_df):\n",
    "    g = nx.DiGraph()\n",
    "    for i,row in nodes.iterrows():\n",
    "\n",
    "        keys = row.index.tolist()\n",
    "\n",
    "        values = row.values\n",
    "\n",
    "        # The dict contains all attributes\n",
    "\n",
    "        g.add_node(row['ID'], **dict(zip(keys,values)))\n",
    "\n",
    "\n",
    "    for i,row in edges.iterrows():\n",
    "\n",
    "        keys = row.index.tolist()\n",
    "\n",
    "        values = row.values\n",
    "\n",
    "        g.add_edge(row['source'], row['target'], weight=row['LL'],**dict(zip(keys,values)))\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-andorra",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = LL_CCEP[(LL_CCEP.RespC==1)&(LL_CCEP.LL>1)&(LL_CCEP.d>50)]\n",
    "data_test = data_test.drop(columns=['RespC', 'RespR', 'RespA','rLL', 'zLL', 'Day'])\n",
    "data_test.insert(0,'Recs', 0)\n",
    "data_test.insert(0,'Stims', 0)\n",
    "for c in range(len(labels_all)):\n",
    "    data_test.loc[(data_test.Stim ==c), \"Region\"] = labels_region[c]\n",
    "    data_test.loc[(data_test.Chan ==c), \"RegionC\"] = labels_region[c]\n",
    "    data_test.loc[(data_test.Chan ==c), \"Recs\"]   = labels_all[c]\n",
    "    data_test.loc[(data_test.Stim ==c), \"Stims\"]  = labels_all[c]\n",
    "data_test=data_test.drop(data_test[data_test.Region=='WM'].index)\n",
    "data_test=data_test.drop(data_test[data_test.RegionC=='WM'].index)\n",
    "data_test = data_test.drop(columns=['Region', 'RegionC'])\n",
    "G       = nx.from_pandas_edgelist(data_test, \"Stims\", \"Recs\",[\"LL\", \"d\"])\n",
    "edges   = nx.to_pandas_edgelist(G)\n",
    "nodes   = pd.DataFrame({'ID': labels_all, 'Region': labels_region, 'H': labels_L})\n",
    "nodes   = nodes.drop(nodes[nodes.Region=='WM'].index)\n",
    "G       = make_graph(nodes, edges)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "pos = nx.circular_layout(G) #nx.spring_layout(G)\n",
    "nx.draw_networkx_nodes(G, pos, cmap=plt.get_cmap('jet'), \n",
    "                        node_size = 500)\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "nx.draw_networkx_edges(G, pos,edge_color='r', arrows=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-candle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "pos = nx.circular_layout(G) #nx.spring_layout(G)\n",
    "nx.draw_networkx_nodes(G, pos, cmap=plt.get_cmap('jet'), \n",
    "                        node_size = 500)\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "nx.draw_networkx_edges(G, pos,edge_color='r', arrows=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-election",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "nx.draw_networkx_edges(G, pos, arrows=True)\n",
    "nx.draw_networkx_edge_labels(G,pos,edge_labels=nx.get_edge_attributes(G, 'LL'))#edge_labels=nx.get_edge_attributes(G, 'LL')\n",
    "nx.draw(G,pos, node_size=100,edge_cmap=plt.cm.Reds)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-green",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c = MatrixPlot(G,node_grouping='Region', node_color='H', edge_width=None, edge_color=None)\n",
    "c.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-patent",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CircosPlot(G, node_color='Region', group_label_position=\"middle\", group_label_offset=12, node_grouping='H', node_labels=True, node_label_layout='rotation', figsize=(8,8))\n",
    "\n",
    "c.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CircosPlot(G, node_color='H', group_label_position=\"middle\", group_label_offset=12, edge_width=(edges['LL'] / edges['LL'].quantile(0.8)).tolist(), node_grouping='Region', node_labels=True, node_label_layout='rotation', figsize=(8,8))\n",
    "\n",
    "c.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-cruise",
   "metadata": {},
   "source": [
    "## LL on mean CCEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-nancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimlist = stimlist.fillna(0)\n",
    "hours    = np.unique(stimlist.h)\n",
    "\n",
    "\n",
    "exp = 1\n",
    "## calcualte mean CCEp and then take LL \n",
    "data_CCEP = np.zeros((1,8))\n",
    "CCEP_mean = np.zeros((len(StimChans),len(labels_all),len(hours), 2000,2))\n",
    "#LL_CCEP   = np.zeros(((len(StimChans),len(labels_all),len(hours),2)))\n",
    "w = 0.25\n",
    "for h in range(len(hours)):\n",
    "    hs = hours[h]\n",
    "    print(hs)\n",
    "    for sc in range(len(StimChans)):\n",
    "        ChanP  = StimChanNums[sc]\n",
    "        s      = np.where(labels_all == StimChans[sc])[0][0]#i#np.int(StimChanNums[i]) \n",
    "        stim_spec                = stimlist[(stimlist.h ==hs)&(stimlist.ChanP ==ChanP)]#&(stimlist.noise ==0)\n",
    "        stimNum                  = stim_spec.StimNum.values#[:,0]\n",
    "        CCEP_mean[sc, :, h,:,0]  = np.nanmean(ff.lp_filter(EEG_resp[:,stimNum,:],45,Fs), axis=1)\n",
    "        CCEP_mean[sc, :, h,:,1]  = np.nanstd(ff.lp_filter(EEG_resp[:,stimNum,:],45,Fs), axis=1)\n",
    "        LL_all     = LL_funcs.get_LL_both(data=np.expand_dims(np.nanmean(ff.lp_filter(EEG_resp[:,stimNum,:],45,Fs), axis=1),1), Fs=Fs, IPI=np.array([0]), t_0=1, win=w)\n",
    "        \n",
    "        #LL_CCEP[sc, :, h, 0] = \n",
    "        \n",
    "        val         = np.zeros((LL_all.shape[0], 8))\n",
    "        val[:, 0]   = np.arange(LL_all.shape[0])                                         # response channel\n",
    "        val[:, 1]   = ChanP\n",
    "        val[:, 2]   = LL_all[:,0,1]\n",
    "        val[:, 3]   = LL_all[:,0,1]\n",
    "        val[:, 4]   = LL_all[:,0,1]\n",
    "        val[:, 5]   = np.sqrt(((coord_all[s,0]-coord_all[:,0])**2)+((coord_all[s,1]-coord_all[:,1])**2)+((coord_all[s,2]-coord_all[:,2])**2))\n",
    "        val[:, 6]   = hs\n",
    "        data_CCEP    = np.concatenate((data_CCEP, val), axis=0)\n",
    "\n",
    "data_CCEP = data_CCEP[1:-1, :] # remove first row (dummy row)\n",
    "\n",
    "\n",
    "LL_CCEP = pd.DataFrame(\n",
    "    {\"Chan\": data_CCEP[:, 0], \"Stim\": data_CCEP[:, 1], \"LL\": data_CCEP[:, 2],\"Distance\": data_CCEP[:, 5],\"LL norm\": data_CCEP[:, 4],\"Hour\": data_CCEP[:, 6]})\n",
    "LL_CCEP.insert(0, 'Dist_cat', 0)\n",
    "LL_CCEP.loc[(LL_CCEP.Distance < 15), 'Dist_cat'] = 1\n",
    "LL_CCEP.loc[(LL_CCEP.Distance > 15)&(LL_CCEP.Distance < 25), 'Dist_cat'] = 2\n",
    "LL_CCEP.loc[(LL_CCEP.Distance > 25)&(LL_CCEP.Distance < 40), 'Dist_cat'] = 3\n",
    "LL_CCEP.loc[(LL_CCEP.Distance > 40)&(LL_CCEP.Distance < 60), 'Dist_cat'] = 4\n",
    "LL_CCEP.loc[(LL_CCEP.Distance > 60), 'Dist_cat'] = 5\n",
    "LL_CCEP.to_csv(path_patient + '/Analysis/BrainMapping/LL/LL_CCEP_'+str(exp)+'_'+str(w)+'s.csv', index=False,\n",
    "              header=True)  # scat_plot = scat_plot.fillna(method='ffill')\n",
    "print('Data saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-parameter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inappropriate-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 2\n",
    "## calcualte mean CCEp and then take LL \n",
    "data_CCEP = np.zeros((1,8))\n",
    "CCEP_mean = np.zeros((len(StimChans),len(labels_all),len(hours), 2000,2))\n",
    "#LL_CCEP   = np.zeros(((len(StimChans),len(labels_all),len(hours),2)))\n",
    "w = 0.25\n",
    "for h in range(len(hours)):\n",
    "    hs = hours[h]\n",
    "    print(hs)\n",
    "    for sc in range(len(StimChans)):\n",
    "        ChanP  = StimChanNums[sc]\n",
    "        s      = np.where(labels_all == StimChans[sc])[0][0]#i#np.int(StimChanNums[i]) \n",
    "        stim_spec                = stimlist[(stimlist.h ==hs)&(stimlist.ChanP ==ChanP)]#&(stimlist.noise ==0)\n",
    "        stimNum                  = stim_spec.StimNum.values#[:,0]\n",
    "        CCEP_mean[sc, :, h,:,0]  = np.nanmean(ff.lp_filter(EEG_resp[:,stimNum,:],45,Fs), axis=1)\n",
    "        CCEP_mean[sc, :, h,:,1]  = np.nanstd(ff.lp_filter(EEG_resp[:,stimNum,:],45,Fs), axis=1)\n",
    "        LL_all     = LL_funcs.get_LL_both(data=np.expand_dims(np.nanmean(ff.lp_filter(EEG_resp[:,stimNum,:],45,Fs), axis=1),1), Fs=Fs, IPI=np.array([0]), t_0=1, win=w)\n",
    "        \n",
    "        #LL_CCEP[sc, :, h, 0] = \n",
    "        \n",
    "        val         = np.zeros((LL_all.shape[0], 8))\n",
    "        val[:, 0]   = np.arange(LL_all.shape[0])                                         # response channel\n",
    "        val[:, 1]   = ChanP\n",
    "        val[:, 2]   = LL_all[:,0,1]\n",
    "        val[:, 3]   = LL_all[:,0,1]\n",
    "        val[:, 4]   = LL_all[:,0,1]\n",
    "        val[:, 5]   = np.sqrt(((coord_all[s,0]-coord_all[:,0])**2)+((coord_all[s,1]-coord_all[:,1])**2)+((coord_all[s,2]-coord_all[:,2])**2))\n",
    "        val[:, 6]   = hs\n",
    "        data_CCEP    = np.concatenate((data_CCEP, val), axis=0)\n",
    "\n",
    "data_CCEP = data_CCEP[1:-1, :] # remove first row (dummy row)\n",
    "\n",
    "\n",
    "LL_CCEP = pd.DataFrame(\n",
    "    {\"Chan\": data_CCEP[:, 0], \"Stim\": data_CCEP[:, 1], \"LL\": data_CCEP[:, 2],\"Distance\": data_CCEP[:, 5],\"LL norm\": data_CCEP[:, 4],\"Hour\": data_CCEP[:, 6]})\n",
    "LL_CCEP.insert(0, 'Dist_cat', 0)\n",
    "LL_CCEP.loc[(LL_CCEP.Distance < 15), 'Dist_cat'] = 1\n",
    "LL_CCEP.loc[(LL_CCEP.Distance > 15)&(LL_CCEP.Distance < 25), 'Dist_cat'] = 2\n",
    "LL_CCEP.loc[(LL_CCEP.Distance > 25)&(LL_CCEP.Distance < 40), 'Dist_cat'] = 3\n",
    "LL_CCEP.loc[(LL_CCEP.Distance > 40)&(LL_CCEP.Distance < 60), 'Dist_cat'] = 4\n",
    "LL_CCEP.loc[(LL_CCEP.Distance > 60), 'Dist_cat'] = 5\n",
    "LL_CCEP.to_csv(path_patient + '/Analysis/BrainMapping/LL/LL_CCEP_'+str(exp)+'_'+str(w)+'s.csv', index=False,\n",
    "              header=True)  # scat_plot = scat_plot.fillna(method='ffill')\n",
    "print('Data saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-luxury",
   "metadata": {},
   "source": [
    "adding Z- Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-tennessee",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_it = 200\n",
    "stim_spec                = stimlist[(stimlist.noise ==0)]\n",
    "stimNum                  = stim_spec.StimNum.values#[:,0]\n",
    "LL_BL = np.zeros((len(labels_all),n_it,2))\n",
    "LL_BL_z = np.zeros((len(labels_all),2))\n",
    "for i in range(n_it):\n",
    "    ix_choice = np.random.choice(len(stimNum), 3)\n",
    "    LL                    = LL_funcs.get_LL_both(data=np.expand_dims(np.nanmean(ff.lp_filter(EEG_resp[:,stimNum[ix_choice],:],45,Fs), axis=1),1), Fs=Fs, IPI=np.array([0]), t_0=0.5, win=w)\n",
    "    LL_BL[:,i,0] = LL[:,0,1] \n",
    "LL_BL_z[:,0] = np.nanmean(LL_BL[:,:,0],1)\n",
    "LL_BL_z[:,1] = np.nanstd(LL_BL[:,:,0],1)\n",
    "for c in range(len(labels_all)):\n",
    "    LL_BL[c,:,1] = (LL_BL[c,:,0] - LL_BL_z[c,0])/LL_BL_z[c,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-holly",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rc in range(len(labels_all)):\n",
    "    LL_CCEP.loc[(LL_CCEP.Chan ==rc), 'LL norm'] = (LL_CCEP.loc[(LL_CCEP.Chan ==rc), 'LL']- LL_BL_z[rc,0])/LL_BL_z[rc,1]\n",
    "    \n",
    "LL_CCEP.loc[(LL_CCEP.Distance <7), 'LL'] = 0\n",
    "LL_CCEP.loc[(LL_CCEP.Distance <7), 'LL norm'] = 0\n",
    "LL_CCEP.loc[(LL_CCEP.Chan.isin(bad_chans)), 'LL'] = 0\n",
    "LL_CCEP.loc[(LL_CCEP.Chan.isin(bad_chans)), 'LL norm'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ChanP = StimChanNums[sc]\n",
    "plt.figure(figsize=(10,6))\n",
    "n, bins, patches = plt.hist(LL_BL[0,:,0], 50, alpha=0.75)\n",
    "bincenters       = 0.5*(bins[1:]+bins[:-1])\n",
    "y                = norm.pdf(bincenters, np.mean(LL_BL[0,:,0]), np.std(LL_BL[0,:,0]))\n",
    "plt.plot(bincenters, y*30, 'r--', linewidth=1)\n",
    "n, bins, patches = plt.hist(LL_CCEP.loc[(LL_CCEP.Stim ==ChanP)&(LL_CCEP.Chan ==rc), 'LL'].values, alpha=0.75)\n",
    "plt.title('Stim: ' + StimChans[sc] + ', Resp: ' + labels_all[rc], fontsize=16)\n",
    "plt.xlabel('LL [uV/ms] of 250ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "ChanP = StimChanNums[sc]\n",
    "n, bins, patches = plt.hist(LL_BL[0,:,1], 50, alpha=0.75)\n",
    "bincenters       = 0.5*(bins[1:]+bins[:-1])\n",
    "y                = norm.pdf(bincenters, np.mean(LL_BL[0,:,1]), np.std(LL_BL[0,:,1]))\n",
    "plt.plot(bincenters, y*30, 'r--', linewidth=1)\n",
    "n, bins, patches = plt.hist(LL_CCEP.loc[(LL_CCEP.Stim ==ChanP)&(LL_CCEP.Chan ==rc), 'LL norm'].values, alpha=0.75)\n",
    "plt.title('Stim: ' + StimChans[sc] + ', Resp: ' + labels_all[rc], fontsize=16)\n",
    "plt.xlabel('LL z-scored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_CCEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP.Stim ==s)&(LL_CCEP.Hour ==hs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = 8\n",
    "sc = 36\n",
    "\n",
    "ChanP = StimChanNums[sc]\n",
    "s      = np.where(labels_all == StimChans[sc])[0][0]#i#np.int(StimChanNums[i]) \n",
    "\n",
    "hours = np.unique(stimlist.h)\n",
    "hours = np.array([0,6,12,18])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(11, 8))\n",
    "gs  = fig.add_gridspec(2,2)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "plt.suptitle('Stim: ' + StimChans[sc] + ', Resp: ' + labels_all[rc], fontsize=16)\n",
    "for i in range(len(hours)):\n",
    "    hs = hours[i]\n",
    "    stim_spec           = stimlist[(stimlist.ChanP ==ChanP)&(stimlist.h ==hs)]\n",
    "    stimNum                  = stim_spec.StimNum.values#[:,0]\n",
    "    CCEP_mean = np.nanmean(ff.lp_filter(EEG_resp[rc,stimNum,:],20,Fs), axis=0)\n",
    "    CCEP_std = np.nanstd(ff.lp_filter(EEG_resp[rc,stimNum,:],20,Fs), axis=0)\n",
    "    if i>1:\n",
    "        axs                 = fig.add_subplot(gs[1,i-2])\n",
    "    else:\n",
    "        axs                 = fig.add_subplot(gs[0,i])\n",
    "    \n",
    "    plt.plot(x_ax,CCEP_mean)\n",
    "    plt.fill_between(x_ax, CCEP_mean-CCEP_std, CCEP_mean+CCEP_std, alpha=0.1)\n",
    "    plt.ylabel('uV', fontsize=12)\n",
    "    plt.axvline(0, c=[1, 0, 0], linewidth=1.5)\n",
    "    plt.title(str(hs)+':00')\n",
    "    plt.xlim([-0.2,0.5])\n",
    "    plt.ylim([-800,400])\n",
    "    if np.max(CCEP_mean) >0:\n",
    "        plt.text(0.3, -300, 'LL: '+str(np.round(np.mean(LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP.Stim ==s)&(LL_CCEP.Hour ==hs)]['LL'].values),2)))\n",
    "        #plt.text(0.3, -200, 'zLL: '+str(np.round(LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP.Stim ==ChanP)&(LL_CCEP.Hour ==hs)]['LL norm'].values[0],2)))\n",
    "    #plt.ylim(limy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-original",
   "metadata": {},
   "source": [
    "make matrix with 0 and 1 if there is a response based on mean z-score across hours (>1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_chans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_resp = np.zeros((len(StimChanNums), len(labels_all)))\n",
    "for sc in range(len(StimChans)):\n",
    "    ChanP  = StimChanNums[sc]\n",
    "    s = np.where(labels_all == StimChans[sc])[0][0]#i#np.int(StimChanNums[i]) \n",
    "    for rc in range(len(labels_all)):\n",
    "        z_mean = np.nanmedian(LL_CCEP.loc[(LL_CCEP.Stim ==ChanP)&(LL_CCEP.Chan ==rc), 'LL norm'].values)\n",
    "        if z_mean > 1.96:\n",
    "            M_resp[sc,rc] =1\n",
    "        if s == rc:\n",
    "            M_resp[sc,rc] =-1\n",
    "M_resp[:,bad_chans] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-japanese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distance matrix.\n",
    "cmap = ListedColormap(['r', 'k', 'w'])\n",
    "fig = pylab.figure(figsize=(25,15))\n",
    "axmatrix = fig.add_axes([0.4,0.1,0.6,0.6])\n",
    "\n",
    "im = axmatrix.matshow(M_resp,cmap=cmap, aspect='auto', origin='lower')\n",
    "\n",
    "plt.xticks(range(len(labels_all)), labels_all, rotation=90);\n",
    "plt.yticks(range(len(StimChanNums)), StimChans);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data where there is propagated response\n",
    "resp_ix = np.array(np.where(M_resp==1))\n",
    "\n",
    "n = 145\n",
    "sc = resp_ix[0,n]\n",
    "rc = resp_ix[1,n]\n",
    "\n",
    "ChanP = StimChanNums[sc]\n",
    "s      = np.where(labels_all == StimChans[sc])[0][0]#i#np.int(StimChanNums[i]) \n",
    "hours = np.unique(stimlist.h)\n",
    "hours = np.array([0,6,12,18])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(11, 8))\n",
    "gs  = fig.add_gridspec(2,2)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "plt.suptitle('Stim: ' + StimChans[sc] + ', Resp: ' + labels_all[rc], fontsize=16)\n",
    "for i in range(len(hours)):\n",
    "    hs = hours[i]\n",
    "    stim_spec           = stimlist[(stimlist.ChanP ==ChanP)&(stimlist.h ==hs)]\n",
    "    stimNum                  = stim_spec.StimNum.values#[:,0]\n",
    "    CCEP_mean = np.nanmean(ff.lp_filter(EEG_resp[rc,stimNum,:],45,Fs), axis=0)\n",
    "    CCEP_std = np.nanstd(ff.lp_filter(EEG_resp[rc,stimNum,:],45,Fs), axis=0)\n",
    "    if i>1:\n",
    "        axs                 = fig.add_subplot(gs[1,i-2])\n",
    "    else:\n",
    "        axs                 = fig.add_subplot(gs[0,i])\n",
    "    if i == 0:\n",
    "        mx = np.min([np.max([np.max(abs(CCEP_mean))*1.5,300]),800])\n",
    "    plt.plot(x_ax,CCEP_mean)\n",
    "    plt.fill_between(x_ax, CCEP_mean-CCEP_std, CCEP_mean+CCEP_std, alpha=0.1)\n",
    "    plt.ylabel('uV', fontsize=12)\n",
    "    plt.axvline(0, c=[1, 0, 0], linewidth=1.5)\n",
    "    plt.title(str(hs)+':00')\n",
    "    plt.xlim([-0.2,0.5])\n",
    "    plt.ylim([-mx,mx])\n",
    "    if np.max(CCEP_mean) >0:\n",
    "        plt.text(0.3, -mx/2-100, 'LL: '+str(np.round(LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP.Stim ==ChanP)&(LL_CCEP.Hour ==hs)]['LL'].values[0],2)))\n",
    "        plt.text(0.3, -mx/2, 'zLL: '+str(np.round(LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP.Stim ==ChanP)&(LL_CCEP.Hour ==hs)]['LL norm'].values[0],2)))\n",
    "    #plt.ylim(limy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-charity",
   "metadata": {},
   "source": [
    "## CR effect on brain map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = np.unique(stimlist.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-trial",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_hour = np.zeros((len(StimChanNums), len(labels_all), len(hours)))\n",
    "for hs in range(len(hours)):\n",
    "    h = hours[hs]\n",
    "    for sc in range(len(StimChans)):\n",
    "        ChanP  = StimChanNums[sc]\n",
    "        s = np.where(labels_all == StimChans[sc])[0][0]#i#np.int(StimChanNums[i]) \n",
    "        if LL_CCEP.loc[(LL_CCEP.Hour ==h)&(LL_CCEP.Stim ==ChanP), 'LL norm'].values.shape[0]==110:\n",
    "            M_hour[sc,:,hs] = LL_CCEP.loc[(LL_CCEP.Hour ==h)&(LL_CCEP.Stim ==ChanP), 'LL norm'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-longer",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "for h in range(len(hours)):\n",
    "    fig = pylab.figure(figsize=(25,15))\n",
    "    axmatrix = fig.add_axes([0.4,0.1,0.6,0.6])\n",
    "\n",
    "    im = axmatrix.matshow(M_hour[:,:,h], aspect='auto', origin='lower', cmap='hot', vmin=1.96, vmax=10)\n",
    "\n",
    "    plt.xticks(range(len(labels_all)), labels_all, rotation=90)\n",
    "    plt.yticks(range(len(StimChanNums)), StimChans)\n",
    "    plt.xlabel(str(hours[h])+':00', fontsize=16)\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_'+str(hours[h])+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 36\n",
    "rc = 8\n",
    "\n",
    "ChanP = StimChanNums[sc]\n",
    "s      = np.where(labels_all == StimChans[sc])[0][0]#i#np.int(StimChanNums[i]) \n",
    "hours = np.unique(stimlist.h)\n",
    "hours = np.array([0,6,12,18])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(11, 8))\n",
    "gs  = fig.add_gridspec(2,2)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "plt.suptitle('Stim: ' + StimChans[sc] + ', Resp: ' + labels_all[rc], fontsize=16)\n",
    "for i in range(len(hours)):\n",
    "    hs = hours[i]\n",
    "    stim_spec           = stimlist[(stimlist.ChanP ==ChanP)&(stimlist.h ==hs)]\n",
    "    stimNum                  = stim_spec.StimNum.values#[:,0]\n",
    "    \n",
    "    stim_list_rec   = stimlist[(stimlist['StimNum'].isin((stimNum-1).clip(min=0)))]\n",
    "    ReChanP         = SM2IX(stim_list_rec.ChanP.values,StimChanNums,np.array(StimChanIx))\n",
    "    #ReChanN = SM2IX(stim_list_rec.ChanN.values,StimChanNums,np.array(StimChanIx))\n",
    "    stimNum         = stimNum[((ReChanP!=rc)&(ReChanP+1!=rc)&(ReChanP-1!=rc))|(stim_list_rec.ISI_s.values>4)]\n",
    "            \n",
    "            \n",
    "    CCEP_mean = np.nanmean(ff.lp_filter(EEG_resp[rc,stimNum,:],45,Fs), axis=0)\n",
    "    CCEP_std = np.nanstd(ff.lp_filter(EEG_resp[rc,stimNum,:],45,Fs), axis=0)\n",
    "    if i>1:\n",
    "        axs                 = fig.add_subplot(gs[1,i-2])\n",
    "    else:\n",
    "        axs                 = fig.add_subplot(gs[0,i])\n",
    "    if i == 0:\n",
    "        mx = np.min([np.max([np.max(abs(CCEP_mean))*1.5,300]),800])\n",
    "    plt.plot(x_ax,CCEP_mean)\n",
    "    plt.fill_between(x_ax, CCEP_mean-CCEP_std, CCEP_mean+CCEP_std, alpha=0.1)\n",
    "    plt.ylabel('uV', fontsize=12)\n",
    "    plt.axvline(0, c=[1, 0, 0], linewidth=1.5)\n",
    "    plt.title(str(hs)+':00')\n",
    "    plt.xlim([-0.2,0.5])\n",
    "    plt.ylim([-mx,mx])\n",
    "    if np.max(CCEP_mean) >0:\n",
    "        plt.text(0.3, -mx/2-100, 'LL: '+str(np.round(LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP.Stim ==s)&(LL_CCEP.Hour ==hs)]['LL'].values[0],2)))\n",
    "        #plt.text(0.3, -mx/2, 'zLL: '+str(np.round(LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP.Stim ==ChanP)&(LL_CCEP.Hour ==hs)]['LL norm'].values[0],2)))\n",
    "    #plt.ylim(limy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_nums     = np.arange(len(labels_all))\n",
    "chan_nums_req = chan_nums[req]\n",
    "# plot ratio of LL of mean CCEP vs distance \n",
    "#data = LL_CCEP[~(LL_CCEP['Chan'].isin(bad_chans))&(LL_CCEP['Chan'].isin(chan_nums_req))&(LL_CCEP['Distance']>3.5)&(LL_CCEP['LL BL norm']>1.5)]\n",
    "data = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP.Stim ==ChanP)]\n",
    "fig    = plt.figure(figsize=(10, 8))\n",
    "\n",
    "sns.catplot(x=\"Hour\", y=\"LL\",data=data, kind=\"swarm\", ci=\"sd\",\n",
    "              height=6,  # make the plot 5 units high\n",
    "              aspect=1.5, legend_out=True)\n",
    "plt.xlabel('hour', fontsize=16)\n",
    "plt.ylabel('LL', fontsize=16)\n",
    "plt.tick_params(axis=\"both\", labelsize=8)\n",
    "#plt.ylim([0,5])\n",
    "#plt.axhline(1, c=[0,0,0])\n",
    "#plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.suptitle('Stim: ' + StimChans[sc] + ', Resp: ' + labels_all[rc], fontsize=16)\n",
    "#plt.savefig(path_patient + '/Analysis/InputOutput/LL/figures/IO_Ph_'+StimChan+ '-'+str(labels_all[rc])+'.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
