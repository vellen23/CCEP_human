{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "headed-glance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('T:\\EL_experiment\\Codes\\CCEP_human\\Python_Analysis/py_functions')\n",
    "\n",
    "from scipy.stats import norm\n",
    "from tkinter import *\n",
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "import platform\n",
    "from glob import glob\n",
    "from scipy.spatial import distance\n",
    "import basic_func as bf\n",
    "from scipy.integrate import simps\n",
    "from numpy import trapz\n",
    "import IO_func as IOF\n",
    "import BM_func as BMf\n",
    "import tqdm\n",
    "from matplotlib.patches import Rectangle\n",
    "from pathlib import Path\n",
    "import LL_funcs as LLf\n",
    "import freq_funcs as ff\n",
    "#\n",
    "from scipy.signal import hilbert, butter, filtfilt\n",
    "import scipy.stats as stats\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import significance_funcs as sig_func\n",
    "\n",
    "dist_groups = np.array([[0, 30], [30, 60], [60, 120]])\n",
    "dist_labels = ['local (<30 mm)', 'short (<60mm)', 'long']\n",
    "Fs = 500\n",
    "dur = np.zeros((1, 2), dtype=np.int32)\n",
    "t0 = 1\n",
    "dur[0, 0] = -t0\n",
    "dur[0, 1] = 3\n",
    "\n",
    "folder = 'BrainMapping'\n",
    "# dur[0,:]       = np.int32(np.sum(abs(dur)))\n",
    "x_ax = np.arange(dur[0, 0], dur[0, 1], (1 / Fs))\n",
    "color_elab = np.zeros((3, 3))\n",
    "color_elab[0, :] = np.array([31, 78, 121]) / 255\n",
    "color_elab[1, :] = np.array([189, 215, 238]) / 255\n",
    "color_elab[2, :] = np.array([0.256, 0.574, 0.431])\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "transparent-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_path  ='X:\\\\4 e-Lab\\\\' # y:\\\\eLab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nutritional-algeria",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subj = 'EL011'\n",
    "cond_folder = 'CR'  # Condition = 'Hour', 'Condition', 'Ph'\n",
    "\n",
    "if cond_folder == 'Ph':\n",
    "    cond_vals = np.arange(4)\n",
    "    cond_labels = ['BM', 'BL', 'Fuma', 'BZD']\n",
    "    cond_colors = ['#494159', '#594157', \"#F1BF98\", \"#8FB996\"]\n",
    "    cond1 = 'Condition'  # 'condition', 'h'\n",
    "    cond_folder = 'Ph'  # 'Ph', 'Sleep', 'CR'\n",
    "    Condition = 'Condition'\n",
    "if cond_folder == 'CR':\n",
    "    Condition = 'Hour'  # Condition = 'Hour'\n",
    "    cond1 = 'h'  # h (as stored in stimlist)\n",
    "\n",
    "######## General Infos\n",
    "\n",
    "path_patient_analysis = sub_path+'\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\\\' + subj\n",
    "path_gen = os.path.join(sub_path+'\\Patients\\\\' + subj)\n",
    "if not os.path.exists(path_gen):\n",
    "    path_gen = 'T:\\\\EL_experiment\\\\Patients\\\\' + subj\n",
    "path_patient = path_gen + '\\Data\\EL_experiment'  # os.path.dirname(os.path.dirname(cwd))+'/Patients/'+subj\n",
    "path_infos = os.path.join(path_patient, 'infos')\n",
    "if not os.path.exists(path_infos):\n",
    "    path_infos = path_gen + '\\\\infos'\n",
    "\n",
    "sep = ';'\n",
    "Fs = 500\n",
    "Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data').mkdir(parents=True, exist_ok=True)\n",
    "Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/BM_plot_trial').mkdir(parents=True, exist_ok=True)\n",
    "Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/figures/single_con').mkdir(parents=True,\n",
    "                                                                                              exist_ok=True)\n",
    "Path(path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/figures/Pipeline').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# get labels\n",
    "if cond_folder == 'Ph':\n",
    "    files_list = glob(path_patient_analysis + '\\\\' + folder + '/data/Stim_list_*Ph*')\n",
    "else:\n",
    "    files_list = glob(path_patient_analysis + '\\\\' + folder + '/data/Stim_list_*')\n",
    "i = 0\n",
    "stimlist = pd.read_csv(files_list[i])\n",
    "EEG_resp = np.load(path_patient_analysis + '\\\\' + folder + '/data/ALL_resps_'+files_list[i][-11:-4]+'.npy')\n",
    "lbls = pd.read_excel(os.path.join(path_infos, subj + \"_labels.xlsx\"), header=0, sheet_name='BP')\n",
    "labels_all, labels_region, labels_clinic, coord_all, StimChans, StimChanSM, StimChansC, StimChanIx, stimlist = bf.get_Stim_chans(\n",
    "    stimlist,\n",
    "    lbls)\n",
    "\n",
    "labels_h = lbls.Hemisphere + '_' + labels_all\n",
    "\n",
    "badchans = pd.read_csv(path_patient_analysis + '\\\\' + folder + '/data/badchan.csv')\n",
    "bad_chans = np.unique(np.array(np.where(badchans.values[:, 1] == 1))[0, :])\n",
    "\n",
    "bad_region = np.where((labels_region == 'WM') | (labels_region == 'OUT') | (labels_region == 'Putamen'))[0]\n",
    "\n",
    "file_con_all = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "file_con = path_patient_analysis + '\\\\' + folder + '/' + cond_folder + '/data/con_trial_all.csv'\n",
    "######### Load data\n",
    "rerun = 0\n",
    "if os.path.isfile(file_con):\n",
    "    # con_trial\n",
    "    con_trial = pd.read_csv(file_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chubby-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_resp = np.load(path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\EEG_' + cond_folder + '.npy')\n",
    "stimlist = pd.read_csv(\n",
    "   path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\stimlist_' + cond_folder + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "level-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs             = 500\n",
    "dur            = np.zeros((1,2), dtype=np.int32)\n",
    "t0 = 1\n",
    "dur[0,0] =  -t0\n",
    "dur[0,1] =  3\n",
    "\n",
    "#dur[0,:]       = np.int32(np.sum(abs(dur)))\n",
    "x_ax           = np.arange(dur[0,0],dur[0,1],(1/Fs))\n",
    "color_elab      = np.zeros((3,3))\n",
    "color_elab[0,:] = np.array([31, 78, 121])/255\n",
    "color_elab[1,:] = np.array([189, 215, 238])/255\n",
    "color_elab[2,:] = np.array([0.256, 0.574, 0.431])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sacred-supplement",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f6fd1656d79b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-mountain",
   "metadata": {},
   "source": [
    "## sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-judge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sig_trials():\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    fig.patch.set_facecolor('xkcd:white')\n",
    "    sns.set(style='white')\n",
    "    plt.title(labels_all[sc] + ' -- ' + labels_all[rc], fontsize=30)\n",
    "    ylim = 300\n",
    "\n",
    "        #fig.add_subplot(gs[0, sig])\n",
    "    #gs = fig.add_gridspec(1,2)  # GridSpec(4,1, height_ratios=[1,2,1,2])\n",
    "    for sig, sig_lab in zip([0,1,2],['Wake', 'NREM', 'REM']):\n",
    "        stimnum = lists.loc[(lists.SleepState==sig_lab),'Num'].values.astype('int')\n",
    "        #fig.add_subplot(gs[0, sig])\n",
    "        # for i in range(len(stimnum)):\n",
    "        #    plt.plot(x_ax, EEG_CR[rc, stimnum[i],:], color=color_elab[0], alpha=0.5)\n",
    "        mn = np.mean(ff.lp_filter(EEG_resp[rc, stimnum,:],30,Fs),0)\n",
    "        st= np.std(ff.lp_filter(EEG_resp[rc, stimnum,:],30,Fs),0)\n",
    "        plt.plot(x_ax, mn, color=color_elab[sig], linewidth=5, alpha=0.7, label=sig_lab+', n: '+str(len(stimnum)))\n",
    "        # st= np.std(ff.lp_filter(trials,30,Fs),0)\n",
    "        # plt.fill_between(x_ax,mn-st, mn+st,color=color_elab[sig*2], alpha=0.2 )\n",
    "    plt.xticks([-0.5, 0,0., 1], fontsize=20)\n",
    "    plt.yticks([-400, 0, 400], fontsize=20)\n",
    "    plt.xlabel('time [s]', fontsize=25)\n",
    "    plt.ylabel('[uV]', fontsize=25)\n",
    "    plt.legend( fontsize=20)\n",
    "    plt.axvline(0, color=[0,0,0], label='stim')\n",
    "        # plt.text(-0.3, 500, 'n: '+str(len(stimnum)), fontsize=20)\n",
    "        #plt.title('Mean Across All Trials', fontsize=25)\n",
    "    plt.xlim([-0.5, 1])\n",
    "    plt.ylim([-ylim,ylim])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path_patient_analysis + '\\\\' + folder + '\\\\'+cond_folder+'\\\\methods\\\\sleep_trials\\\\'+subj+'_'+labels_all[sc]+'_'+labels_all[rc]+'_SS.svg')\n",
    "    # plt.savefig(path_patient_analysis + '\\\\' + folder + '\\\\'+cond_folder+'\\\\methods\\\\CC_surr_example\\\\'+subj+'_'+labels_all[sc]+'_'+labels_all[rc]+'_'+m+'.jpg')\n",
    "    plt.axvspan(0,0.25, alpha=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "several-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ 3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 19., 20., 21., 22., 23.,\n",
    "       24., 25., 26., 27., 31., 32., 33., 34.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(con_trial.loc[(con_trial.Sig==1)&(con_trial.Stim==4),'Chan'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#k = np.random.choice(len(dat_plot),1)[0]\n",
    "sc = 4\n",
    "rc= 13\n",
    "lists = con_trial[(con_trial['Artefact'] <1) & (con_trial['Chan'] == rc) & (con_trial['Stim'] == sc)]\n",
    "plot_sig_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Stim_chans(stimlist, lbls):\n",
    "    labels_all      = lbls.label.values\n",
    "    labels_clinic   = lbls.Clinic.values\n",
    "    labels_region   = lbls.Region.values\n",
    "    coord_all       = np.array([lbls.x.values,lbls.y.values, lbls.z.values ]).T\n",
    "    # get stimulation channels directly from stimlist\n",
    "    StimChanSM = np.unique(stimlist.ChanP)\n",
    "\n",
    "    ChanN = np.zeros((len(StimChanSM),))\n",
    "    StimChans = []  # np.zeros((len(stim_chan)))\n",
    "    StimChansC = []  # np.zeros((len(stim_chan)))\n",
    "    StimChanIx = []  # np.zeros((len(stim_chan)))\n",
    "    i = 0\n",
    "    while i < len(StimChanSM):\n",
    "        ChanN[i] = np.median(stimlist[stimlist.ChanP == StimChanSM[i]].ChanN)\n",
    "        if ((np.array(lbls.ChanP_SM.values) == StimChanSM[i]) & (np.array(lbls.ChanN_SM.values) == ChanN[i])).any():\n",
    "            # StimChans.append(labels_SM[(np.array(labels.chan_num.values)==stim_chan[i,0])][0])\n",
    "            StimChans.append(labels_all[(np.array(lbls.ChanP_SM.values) == StimChanSM[i]) & (\n",
    "                        np.array(lbls.ChanN_SM.values) == ChanN[i])][0])\n",
    "            StimChansC.append(labels_clinic[(np.array(lbls.ChanP_SM.values) == StimChanSM[i]) & (\n",
    "                        np.array(lbls.ChanN_SM.values) == ChanN[i])][0])\n",
    "            StimChanIx.append(\n",
    "                lbls[(np.array(lbls.ChanP_SM.values) == StimChanSM[i]) & (np.array(lbls.ChanN_SM.values) == ChanN[i])][\n",
    "                    'Num'].values[0] - 1)\n",
    "            i = i + 1\n",
    "        else:\n",
    "            StimChanSM = np.delete(StimChanSM, i, 0)\n",
    "\n",
    "    stimlist = stimlist[np.isin(stimlist.ChanP, StimChanSM)]\n",
    "\n",
    "    labels_region[labels_region == 'Temporal'] = 'Basotemporal'\n",
    "    labels_region[labels_region == 'HIPP '] = 'Mesiotemporal'\n",
    "    labels_region[labels_region == 'HIPP'] = 'Mesiotemporal'\n",
    "    labels_region[labels_region == 'Temporal'] = 'Laterotemporal'\n",
    "\n",
    "    return labels_all, labels_region,labels_clinic,coord_all,StimChans, StimChanSM,StimChansC, StimChanIx, stimlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all, labels_region,labels_clinic,coord_all,StimChans, StimChanSM,StimChansC, StimChanIx, stimlist = get_Stim_chans(stimlist, lbls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial = con_trial[~ np.isin(con_trial.Chan, bad_region)]\n",
    "con_trial = con_trial[~ np.isin(con_trial.Stim, bad_region)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = con_trial[con_trial.Sig==1]\n",
    "summ = data.groupby(['Stim','Chan'], as_index=False)[['Sig']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(stimnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-annotation",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_resp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 14\n",
    "rc = 57\n",
    "\n",
    "# sc_sel = 10\n",
    "# sc = StimChanIx[sc_sel]\n",
    "# sc_sm  = StimChanSM[sc_sel]\n",
    "# stimnum = stimlist.loc[stimlist.ChanP==sc_sm, 'Num']\n",
    "stimnum= con_trial.loc[(con_trial.Sleep==0)&(con_trial.Artefact==0)&(con_trial.Stim==sc)&(con_trial.Chan==rc),'Num'].values.astype('int')\n",
    "d = np.round(scipy.spatial.distance.euclidean(coord_all[sc], coord_all[rc]),1)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(labels_clinic[sc]+'('+ labels_all[sc]+')  --- '+ labels_clinic[rc]+'('+ labels_all[rc]+'), d: '+str(d)+'mm', fontsize=20)\n",
    "mn= np.mean(EEG_resp[rc,stimnum,:],0)\n",
    "st = np.std(EEG_resp[rc,stimnum,:],0)\n",
    "plt.plot(x_ax, mn, color=[0,0,0])\n",
    "plt.fill_between(x_ax, mn-st, mn+st, alpha=0.2, color=[0,0,0])\n",
    "plt.axvspan(0,0.01, color=[1,0,0])\n",
    "plt.xlim([-0.25,2])\n",
    "plt.xlabel('time [s]', fontsize=20)\n",
    "plt.ylabel('uV', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.ylim([-800,800])\n",
    "plt.text(1, -600, 'n: '+str(len(stimnum)), fontsize=15)\n",
    "#plt.savefig('Y:\\eLab\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\EL018\\BrainMapping\\example\\\\'+labels_all[sc]+'_'+labels_all[rc]+'.jpg')\n",
    "# plt.savefig('Y:\\eLab\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\EL018\\BrainMapping\\example\\\\'+labels_all[sc]+'_'+labels_all[rc]+'.svg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "import significance_funcs as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_0 = 1\n",
    "w = 0.25\n",
    "\n",
    "data = con_trial[(con_trial.Stim==sc)&(con_trial.Chan==rc)]\n",
    "stimnum = data.Num.values.astype('int')\n",
    "\n",
    "resp = np.mean(EEG_resp[rc,stimnum,:],0)\n",
    "resp = ff.lp_filter(resp, 45, Fs)\n",
    "resp_LL = LLf.get_LL_all(np.expand_dims(resp,[0,1]), Fs, 0.25)[0][0]\n",
    "\n",
    "plt.plot(x_ax,resp_LL)\n",
    "thr = np.percentile(np.concatenate([resp_LL[int((w / 2) * Fs):int((t_0 - w / 2) * Fs)],\n",
    "                                            resp_LL[int(3 * Fs):int((4 - w / 2) * Fs)]]),\n",
    "                            99)  # LL_resp[0, 0, int((t_0+0.5) * Fs):] = 0 * Fs):] = 0\n",
    "plt.axhline(thr)\n",
    "LL_t = np.array(resp_LL[:int((t_0 + 0.5) * Fs)] > thr) * 1\n",
    "t_resp_all = sf.search_sequence_numpy(LL_t, np.ones((int((w + 0.01) * Fs),)))\n",
    "if len(t_resp_all) > 0:    \n",
    "    t_onset = t_resp_all[0] / Fs - t_0 + w / 2\n",
    "    r = 1\n",
    "    print(t_onset)\n",
    "    if (t_onset < 0.001) | (t_onset > 0.5):\n",
    "        t_onset = 0\n",
    "    plt.axvline(t_onset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-incidence",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_0 = 1\n",
    "w = 0.25 \n",
    "stimchans = np.unique(con_trial.Stim).astype('int')\n",
    "M = np.zeros((len(labels_all),len(labels_all)))\n",
    "for sc in stimchans:\n",
    "    for rc in range(len(labels_all)):\n",
    "        data = con_trial[(con_trial.Stim==sc)&(con_trial.Chan==rc)&(con_trial.Artefact<1)]\n",
    "        stimnum = data.Num.values.astype('int')\n",
    "        if len(stimnum)>0:\n",
    "            resp = np.mean(EEG_resp[rc,stimnum,:],0)\n",
    "            resp = ff.lp_filter(resp, 45, Fs)\n",
    "            resp_LL = LLf.get_LL_all(np.expand_dims(resp,[0,1]), Fs, 0.25)[0][0]\n",
    "            \n",
    "            thr = np.percentile(np.concatenate([resp_LL[int((w / 2) * Fs):int((t_0 - w / 2) * Fs)],\n",
    "                                            resp_LL[int(3 * Fs):int((4 - w / 2) * Fs)]]),\n",
    "                            99)  # LL_resp[0, 0, int((t_0+0.5) * Fs):] = 0 * Fs):] = 0\n",
    "            LL_t = np.array(resp_LL[:int((t_0 + 0.5) * Fs)] > thr) * 1\n",
    "            t_resp_all = sf.search_sequence_numpy(LL_t, np.ones((int((w + 0.02) * Fs),)))\n",
    "\n",
    "            if len(t_resp_all) > 0:\n",
    "                M[sc,rc] = np.nanmax(resp_LL[500:750])\n",
    "        else:\n",
    "            M[sc,rc] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial_sig = con_trial[(con_trial.Sleep < 5) & (con_trial.d > -10)]\n",
    "con_trial_sig = con_trial_sig.reset_index(drop=True)\n",
    "con_trial_sig.loc[con_trial_sig.Sig < 0, 'Sig'] = np.nan\n",
    "con_trial_sig.insert(4, 'LL_sig', np.nan)\n",
    "con_trial_sig.loc[con_trial_sig.Sig == 1, 'LL_sig'] = con_trial_sig.loc[con_trial_sig.Sig == 1, 'LL']\n",
    "con_trial_sig = con_trial_sig.drop(columns='LL')\n",
    "con_trial_sig.insert(4, 'LL', con_trial_sig.LL_sig)\n",
    "con_trial_sig.insert(4, 'Prob', con_trial_sig.Sig)\n",
    "con_trial_sig = con_trial_sig.drop(columns='LL_sig')\n",
    "con_trial_sig = con_trial_sig[(con_trial_sig.Block >=1)]\n",
    "con_trial_sig = con_trial_sig.reset_index(drop=True)\n",
    "# labels:\n",
    "labels_sel = np.delete(labels_clinic, bad_chans, 0)\n",
    "areas_sel = np.delete(labels_region, bad_chans, 0)\n",
    "# # sort\n",
    "# ind = np.argsort(areas_sel)\n",
    "# areas_sel = np.delete(self.labels_region, self.bad_all, 0)\n",
    "# labels_sel = labels_sel[ind]\n",
    "# areas_sel = areas_sel[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sel = np.delete(labels_clinic, bad_chans, 0)\n",
    "areas_sel = np.delete(labels_region, bad_chans, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "summ = con_trial_sig[(con_trial.Artefact==0)]\n",
    "summ = summ.groupby(['Stim', 'Chan'], as_index=False)['Sig'].mean()#summ[summ.Sig_block>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-processor",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.zeros((len(labels_all), len(labels_all))) - 1\n",
    "# M[:, :] = np.nan\n",
    "for sc in np.unique(summ.Stim).astype('int'):\n",
    "    chan = summ.loc[summ.Stim == sc, 'Chan'].values.astype('int')\n",
    "    LL = summ.loc[summ.Stim == sc, 'Sig'].values\n",
    "    M[sc, chan] = LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_resp       = np.delete(np.delete(M, bad_chans, 0), bad_chans, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sig_con = path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\sig_con.csv'\n",
    "\n",
    "sig_con = pd.read_csv(file_sig_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='d', y='t_onset', data=sig_con[sig_con.Sig_CC_LL==1])\n",
    "plt.ylim([0.,0.21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sig_con = path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\sig_con.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_con[sig_con.Sig_CC_LL==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = 'test_clinic'\n",
    "plot_BM_CR_trial_sig(M_resp, labels_sel,areas_sel, ll, 't')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions       = np.unique(labels_region)\n",
    "color_regions = ['#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6',\"#8FB996\"]\n",
    "\n",
    "#v= np.sort(labels_region)\n",
    "#region_border = np.where(np.roll(v,1)!=v)[0]\n",
    "#region_border = np.concatenate([region_border, [len(labels_all)]])\n",
    "#region_num = np.diff(region_border)\n",
    "#labels_sort     = labels_all[np.argsort(labels_region)]\n",
    "#labels_region_sort = np.sort(labels_region)\n",
    "#StimChanIx_sort = np.argsort(labels_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-elite",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stim = np.arange(len(labels_all))\n",
    "non_stim = np.delete(non_stim, StimChanIx, 0)\n",
    "WM_chans = np.where(labels_region == 'WM')[0]\n",
    "#WM_chans = np.where(labels_region == 'Unknown')[0]\n",
    "bad_all = np.unique(np.concatenate([WM_chans, bad_region, bad_chans])).astype('int')\n",
    "bad_all2 = np.unique(np.concatenate([WM_chans, bad_region, bad_chans, non_stim])).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_BM_CR_trial_sig(M, labels,areas, label, t):\n",
    "    cmap_LL = 'hot'\n",
    "    M[np.isnan(M)] = -1\n",
    "    \n",
    "    time        = str(t).zfill(2)+':00'\n",
    "    fig      = plt.figure(figsize=(25,25))\n",
    "    \n",
    "    cmap = copy.copy(plt.cm.get_cmap(cmap_LL))  # cmap = copy.copy(mpl.cm.get_cmap(cmap))\n",
    "    cmap.set_under('black')\n",
    "    cmap.set_bad('black')\n",
    "    M = np.ma.masked_equal(M, 0)\n",
    "            \n",
    "            \n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im = axmatrix.matshow(M, aspect='auto', origin='lower', cmap=cmap, vmin=0, vmax=1) # np.percentile(M, 95)\n",
    "    plt.xlim([-1.5, M.shape[0]-0.5])\n",
    "    plt.ylim([-0.5, M.shape[1]+0.5])\n",
    "    plt.xticks(range(M.shape[1]), labels[:M.shape[1]], rotation=90);\n",
    "    plt.yticks(range(M.shape[0]), labels[:M.shape[0]]);\n",
    "    for i in range(len(labels)):\n",
    "        r         = areas[i]\n",
    "        if i <=M.shape[1]:\n",
    "            axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "        if i <=M.shape[0]:\n",
    "            axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    #axcolor = fig.add_axes([0.04,0.85,0.08,0.08]) # x, y, x_len, y_len\n",
    "    #circle1 = plt.Circle((0.5,0.5), 0.4, color = CR_color[t], alpha = CR_color_a[t])\n",
    "    #plt.text(0.3,0.3, time)\n",
    "    #plt.axis('off')\n",
    "    #axcolor.add_patch(circle1)\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(label+', '+time+ '-- Sig')\n",
    "    #plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/BM_plot/BM_'+label+'.svg')\n",
    "    #Path(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/GIF/').mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig('X:\\\\4 e-Lab\\EvM\\Projects\\EL_experiment\\Analysis\\Patients\\EL020\\BrainMapping\\CR\\BM_figures\\General\\\\'+'BM_clin.jpg')\n",
    "\n",
    "    #plt.close(fig) #plt.show()#\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_sel   = np.delete(labels_h.values, bad_all, 0)\n",
    "areas_sel    = np.delete(labels_region, bad_all, 0)\n",
    "M_resp       = np.delete(np.delete(M, bad_all, 0), bad_all2, 1)\n",
    "\n",
    "# sort\n",
    "ind = np.argsort(areas_sel)\n",
    "M_resp= M_resp[ind,:]\n",
    "M_resp = M_resp[:,ind]\n",
    "labels_sel = labels_sel[ind]\n",
    "areas_sel = areas_sel[ind]\n",
    "ll = 'test_clinic'\n",
    "plot_BM_CR_trial_sig(M_resp, labels_sel,areas_sel, ll, 't')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-craft",
   "metadata": {},
   "outputs": [],
   "source": [
    "M[sc,rc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 2\n",
    "rc = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 40\n",
    "rc = 54\n",
    "ylim = 800\n",
    "# sc_sel = 10\n",
    "# sc = StimChanIx[sc_sel]\n",
    "# sc_sm  = StimChanSM[sc_sel]\n",
    "# stimnum = stimlist.loc[stimlist.ChanP==sc_sm, 'Num']\n",
    "stimnum= con_trial.loc[(con_trial.Stim==sc)&(con_trial.Chan==rc),'Num'].values.astype('int')\n",
    "d = np.round(scipy.spatial.distance.euclidean(coord_all[sc], coord_all[rc]),1)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(labels_clinic[sc]+'('+ labels_all[sc]+')  --- '+ labels_clinic[rc]+'('+ labels_all[rc]+'), d: '+str(d)+'mm', fontsize=20)\n",
    "mn= np.nanmean(EEG_resp[rc,stimnum,:],0)\n",
    "#st = np.std(EEG_resp[rc,stimnum,:],0)\n",
    "for i in range(len(stimnum)):\n",
    "    plt.plot(x_ax, EEG_resp[rc,stimnum[i],:])\n",
    "plt.plot(x_ax, mn, color=[0,0,0], linewidth=4)\n",
    "#plt.fill_between(x_ax, mn-st, mn+st, alpha=0.2)\n",
    "plt.axvspan(0,0.01, color=[1,0,0])\n",
    "plt.xlim([-0.5,1])\n",
    "plt.xlabel('time [s]', fontsize=20)\n",
    "plt.ylabel('uV', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.ylim([-ylim,ylim])\n",
    "plt.show()\n",
    "\n",
    "stimnum= con_trial.loc[(con_trial.Stim==rc)&(con_trial.Chan==sc),'Num'].values.astype('int')\n",
    "d = np.round(scipy.spatial.distance.euclidean(coord_all[sc], coord_all[rc]),1)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.title(labels_clinic[rc]+'('+ labels_all[rc]+')  --- '+ labels_clinic[sc]+'('+ labels_all[sc]+'), d: '+str(d)+'mm', fontsize=20)\n",
    "mn= np.nanmean(EEG_resp[sc,stimnum,:],0)\n",
    "#st = np.std(EEG_resp[rc,stimnum,:],0)\n",
    "for i in range(len(stimnum)):\n",
    "    plt.plot(x_ax, EEG_resp[sc,stimnum[i],:])\n",
    "plt.plot(x_ax, mn, color=[0,0,0], linewidth=4)\n",
    "#plt.fill_between(x_ax, mn-st, mn+st, alpha=0.2)\n",
    "plt.axvspan(0,0.01, color=[1,0,0])\n",
    "plt.xlim([-0.5,1])\n",
    "plt.xlabel('time [s]', fontsize=20)\n",
    "plt.ylabel('uV', fontsize=20)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.ylim([-ylim,ylim])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-transparency",
   "metadata": {},
   "source": [
    "## First versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_BM_CR_trial_sig(M_resp, labels_sel,areas_sel, ll, 't')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-headset",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_resp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_BM_CR_trial_sig(M, labels,areas, label, t):\n",
    "    time        = str(t).zfill(2)+':00'\n",
    "    fig      = plt.figure(figsize=(25,25))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, origin='lower',cmap='hot', vmin=1, vmax= 9)\n",
    "    plt.xlim([-1.5, M.shape[0]-0.5])\n",
    "    plt.ylim([-0.5, M.shape[1]+0.5])\n",
    "    plt.xticks(range(M.shape[1]), labels[:M.shape[1]], rotation=90);\n",
    "    plt.yticks(range(M.shape[0]), labels[:M.shape[0]]);\n",
    "    for i in range(len(labels)):\n",
    "        r         = areas[i]\n",
    "        if i <=M.shape[1]:\n",
    "            axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "        if i <=M.shape[0]:\n",
    "            axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    #axcolor = fig.add_axes([0.04,0.85,0.08,0.08]) # x, y, x_len, y_len\n",
    "    #circle1 = plt.Circle((0.5,0.5), 0.4, color = CR_color[t], alpha = CR_color_a[t])\n",
    "    #plt.text(0.3,0.3, time)\n",
    "    #plt.axis('off')\n",
    "    #axcolor.add_patch(circle1)\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(label+', '+time+ '-- mean LL')\n",
    "    #plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/BM_plot/BM_'+label+'.svg')\n",
    "    #Path(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/GIF/').mkdir(parents=True, exist_ok=True)\n",
    "    #plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/BM_'+label+'.jpg')\n",
    "    #plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/GIF/BM_'+label+'.jpg')\n",
    "    #plt.close(fig) #plt.show()#\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_con = path_patient_analysis + '\\\\' + folder + '\\\\' + cond_folder + '\\\\data\\\\con_trial_all.csv'\n",
    "con_trial    = pd.read_csv(file_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-invitation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc  =6\n",
    "rc = 62#rc+1\n",
    "plot_mean(sc, rc, con_trial[con_trial.Artefact==0],EEG_resp, labels_clinic)\n",
    "plt.ylim([-500,500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b =1\n",
    "y = 'LL'\n",
    "summ = con_trial[(con_trial.Artefact==0)&(con_trial.LL>0)]\n",
    "summ = summ.groupby(['Stim', 'Chan'], as_index=False)[y].mean()#summ[summ.Sig_block>3]\n",
    "#t = np.bincount(con_trial.loc[con_trial.Block==b, 'Hour']).argmax()\n",
    "M = np.zeros((len(labels_all),len(labels_all)))\n",
    "for sc in np.unique(summ.Stim).astype('int'):\n",
    "    chan = summ.loc[summ.Stim==sc, 'Chan'].values.astype('int')\n",
    "    LL   = summ.loc[summ.Stim==sc, y].values\n",
    "    M[sc,chan] = LL\n",
    "M = np.nan_to_num(M)\n",
    "# BM plot\n",
    "labels_sel   = np.delete(labels_all, bad_all, 0)\n",
    "areas_sel    = np.delete(labels_region, bad_all, 0)\n",
    "M_resp       = np.delete(np.delete(M, bad_all, 0), bad_all, 1)\n",
    "\n",
    "# sort\n",
    "#ind = np.argsort(areas_sel)\n",
    "#M_resp= M_resp[ind,:]\n",
    "#M_resp = M_resp[:,ind]\n",
    "#labels_sel = labels_sel[ind]\n",
    "#areas_sel = areas_sel[ind]\n",
    "ll = 'test_clinic'\n",
    "plot_BM_CR_trial_sig(M_resp, labels_sel,areas_sel, ll, 't')\n",
    "#i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LL_funcs as LLf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_folder ='CR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file = path_analysis+'\\\\BrainMapping\\\\' + cond_folder + '\\\\data\\\\con_trial_all.csv'\n",
    "con_trial.to_csv(file, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_resp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc  = 10\n",
    "rc = 3#rc+1\n",
    "plot_mean(sc, rc, con_trial,EEG_resp, labels_clinic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stim = np.arange(len(labels_all))\n",
    "non_stim = np.delete(non_stim, StimChanIx, 0)\n",
    "bad_all = np.unique(np.concatenate([bad_region, bad_chans, non_stim])).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_l = file[-11:-4]\n",
    "file = path_patient + '/Analysis/BrainMapping/' + cond_folder + '/data/con_trial_' + block_l + '.csv'\n",
    "con_trial.to_csv(file, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "chan, trial = np.where(np.max(abs(EEG_resp[:, :, int(0.98 * Fs):int(1.008 * Fs)]), 2) > 2000)\n",
    "for i in range(len(trial)):\n",
    "    con_trial.loc[\n",
    "        (con_trial.Chan == chan[i]) & (con_trial.Num_block == trial[i]), 'LL'] = np.nan\n",
    "con_trial.loc[(con_trial.LL > 40), 'LL'] = np.nan\n",
    "con_trial = con_trial[~ np.isin(con_trial.Chan, bad_region)]\n",
    "con_trial = con_trial[~ np.isin(con_trial.Stim, bad_region)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_BM_CR_trial_sig(M, labels,areas, label, t):\n",
    "    time        = str(t).zfill(2)+':00'\n",
    "    fig      = plt.figure(figsize=(15,15))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, aspect='auto', origin='lower',cmap='hot', vmin=2.7, vmax= 6)\n",
    "    plt.xlim([-1.5, len(labels)-0.5])\n",
    "    plt.ylim([-0.5, len(labels)+0.5])\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90);\n",
    "    plt.yticks(range(len(labels)), labels);\n",
    "    for i in range(len(labels)):\n",
    "        r         = areas[i]\n",
    "        axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "        axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    #axcolor = fig.add_axes([0.04,0.85,0.08,0.08]) # x, y, x_len, y_len\n",
    "    #circle1 = plt.Circle((0.5,0.5), 0.4, color = CR_color[t], alpha = CR_color_a[t])\n",
    "    #plt.text(0.3,0.3, time)\n",
    "    #plt.axis('off')\n",
    "    #axcolor.add_patch(circle1)\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(label+', '+time+ '-- mean LL')\n",
    "    #plt.savefig(path_patient + '/Analysis/BrainMapping/CR/figures/BM_plot/BM_'+label+'.svg')\n",
    "    #Path(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/GIF/').mkdir(parents=True, exist_ok=True)\n",
    "    #plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/BM_'+label+'.jpg')\n",
    "    #plt.savefig(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/figures/BM_plot_trial_sig/GIF/BM_'+label+'.jpg')\n",
    "    #plt.close(fig) #plt.show()#\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean(sc, rc, LL_CCEP,EEG_resp, labels ):\n",
    "    t_0    = 1\n",
    "    lists  = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)&(~np.isnan(LL_CCEP.LL.values))]\n",
    "    \n",
    "    fig   = plt.figure(figsize=(12,7) )\n",
    "    #plt.title(labels_all[Stim_chs]+' -- '+labels_clinic[rc])\n",
    "    #plt.title(labels[sc]+' -- '+labels[rc])\n",
    "    plt.title(labels[sc]+' -- '+labels[rc]+', Dist: '+str(np.round(lists.d.values[0]))+'mm')\n",
    "    \n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    plt.xlabel('time [s]')\n",
    "    #plt.text(-0.37, 200, 'LL: '+str(np.round(np.mean(lists.LLpeak),2))+'uV/ms (of mean)', c=[0,0,0])\n",
    "    \n",
    "    ylim = 200\n",
    "\n",
    "    #stim_spec                = stimlist[(stimlist.condition>0)&(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "    stimNum_all                  = lists.Num.values.astype('int')\n",
    "    for i in range(len(stimNum_all)):\n",
    "        ylim =np.max([ylim, np.max(abs(ff.lp_filter(EEG_resp[rc,stimNum_all[i],Fs:int(1.5*Fs)],45,Fs)))])\n",
    "        plt.plot(x_ax,ff.lp_filter(EEG_resp[rc,stimNum_all[i],:],45,Fs), c=color_elab[0], linewidth=1)\n",
    "    resp_all = ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "    # w_LL =0.1\n",
    "    # resp_LL = LLf.get_LL_all(np.expand_dims(np.expand_dims(resp_all,0),0), 500, w_LL, 1, 0)\n",
    "    # resp_LL =resp_LL[0,0,:]\n",
    "    # start_resp = np.argmax(resp_LL[int(t0*Fs):int((t0+0.5)*Fs)])/Fs-w_LL/2+0.01\n",
    "    #print(start_resp)\n",
    "    plt.plot(x_ax,resp_all, c=[0,0,0], linewidth=3, label='mean, n='+str(len(stimNum_all)))\n",
    "    #plt.plot(x_ax,resp_LL*100, c=[1,0,0], linewidth=3, label='LL')\n",
    "    ## finding peaks\n",
    "    t_0=1\n",
    "    resp_z = ff.lp_filter(np.mean(bf.zscore_CCEP(ff.lp_filter(EEG_resp[rc,stimNum_all,:],45,Fs)),0),45,Fs)\n",
    "    # #std_z = np.std(bf.zscore_CCEP(ff.lp_filter(EEG_resp[rc,stimNum_all,:],45,Fs)),0)\n",
    "    # # plt.plot(x_ax,resp_z*100, c=[1,0,0], linewidth=3, label='mean, n='+str(len(stimNum_all)))\n",
    "    # #start_resp = 0\n",
    "    # #print(np.max(abs(resp_z[int(1.01*Fs):int(1.3*Fs)])))\n",
    "    # if np.max(abs(resp_z[int(1.01*Fs):int(1.3*Fs)])) > 2.5:\n",
    "    #     ## get start resp\n",
    "    #     \n",
    "    #     # peaks_p, properties_all = scipy.signal.find_peaks(\n",
    "    #     #     (resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), height=0.5, prominence=1,\n",
    "    #     #     distance=0.01 * Fs, width=1)  #\n",
    "    #     # peaks_n, properties_all = scipy.signal.find_peaks(\n",
    "    #     #     -(resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), height=0.5, prominence=1,\n",
    "    #     #     distance=0.01 * Fs, width=1)  #\n",
    "    #     # print(np.concatenate([peaks_p, peaks_n]))\n",
    "    #     # if (len(peaks_p)+len(peaks_n))>0:\n",
    "    #     #     #print(np.concatenate([peaks_p, peaks_n]))\n",
    "    #     #     peaks_all =min(np.concatenate([peaks_p, peaks_n]))\n",
    "    #     #     #w = scipy.signal.peak_widths(abs(resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), [peaks_all],rel_height=0.2)[0]\n",
    "    #     #     \n",
    "    #     #     start_resp = (peaks_all) / Fs - 0.02# (peaks_all - w) / Fs - 0.01\n",
    "    #     if start_resp < 0.01:\n",
    "    #         start_resp = 0\n",
    "# \n",
    "    #     pk, peak_s, p = get_peaks_all(resp_z,start_resp)\n",
    "    # \n",
    "    #     plt.plot(peak_s, resp_all[pk.astype('int')], \"^\", color= [1,0,0])\n",
    "    plt.xlim([-0.6,1])\n",
    "    plt.ylim([-np.max([ylim*1.071,300]),np.max([ylim*1.071,300])])\n",
    "    #plt.axvspan(t_0+w_r-1, t_0-1+w_LL, alpha=0.3, color=color_elab[0])\n",
    "    #plt.axvspan(start_resp+0.01,start_resp+0.05, alpha=0.8, color=color_elab[1])\n",
    "    #plt.axvspan(start_resp+0.08, start_resp+0.4, alpha=0.8, color=color_elab[1])\n",
    "    plt.legend()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 3\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.plot(x_ax, EEG_resp[c,103,:],linewidth=7, color=color_elab[0])\n",
    "plt.xticks([-0.5, 0, 0.5])\n",
    "plt.axvline(-0.01, linewidth=5, color=[1,0,0])\n",
    "plt.axvspan(0.01, 0.04, alpha=0.1)\n",
    "plt.axvspan(0.08, 0.25, alpha=0.1)\n",
    "plt.xlim([-0.5, 1])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-birthday",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "fig = plt.figure(figsize=(10,30))\n",
    "n = 6\n",
    "e = 9\n",
    "stimNum = 555\n",
    "gs       = fig.add_gridspec(7,1)\n",
    "for i in range(n):\n",
    "    fig.add_subplot(gs[i,0])\n",
    "    \n",
    "    plt.xticks([])\n",
    "    plt.xlim([-1, 1.5])\n",
    "\n",
    "    plt.ylim([-600,600])\n",
    "    plt.plot(x_ax, EEG_resp[i+e,stimNum,:],linewidth=10, color=color_elab[0])\n",
    "    \n",
    "    plt.axvline(0, linewidth=5, color=[1,0,0])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.xticks([-1, 0, 1])\n",
    "fig.tight_layout() \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load\n",
    "if cc==1:\n",
    "    EEG_resp = np.load(path_patient + '/Analysis/BrainMapping/data/All_resps_all.npy')\n",
    "\n",
    "else:\n",
    "    EEG_resp = np.load(path_patient + '/Analysis/BrainMapping/data/All_resps_'+file[-11:-4]+'.npy')\n",
    "stimlist = pd.read_csv(file)\n",
    "stimlist.StimNum = np.arange(len(stimlist))\n",
    "stimlist = stimlist[(stimlist.condition==0)&(stimlist.currentflow==100)]\n",
    "print('data loaded with '+str(EEG_resp.shape[1])+' stimulations')\n",
    "print(EEG_resp.shape)\n",
    "\n",
    "if os.path.isfile(path_patient + '/Analysis/BrainMapping/data/badchan.csv'):\n",
    "    badchans  = pd.read_csv(path_patient + '/Analysis/BrainMapping/data/badchan.csv')\n",
    "    bad_chans = np.unique(np.array(np.where(badchans.values[:,1:]==1))[0,:])\n",
    "else:\n",
    "    bad_chans = []\n",
    "if len(stimlist)!= EEG_resp.shape[1]:\n",
    "    print(\"WARNING: number of stimulations don't agree!\")\n",
    "    \n",
    "#badchans.to_csv(path_patient + '/Analysis/BrainMapping/data/badchan.csv', index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-architecture",
   "metadata": {},
   "source": [
    "for c in [49, 26,21,18, 9, 10]:\n",
    "    badchans.loc[badchans.Chan==c, '2'] =1\n",
    "badchans.to_csv(path_patient + '/Analysis/BrainMapping/data/badchan.csv', index=False,header=True)\n",
    "badchans = pd.read_csv(path_patient + '/Analysis/BrainMapping/data/badchan.csv')\n",
    "bad_chans = np.unique(np.array(np.where(badchans.values[:,1:]==1))[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls            = pd.read_excel(path_patient + \"/infos/\" + subj + \"_labels.xlsx\", header=0, sheet_name='BP')\n",
    "labels_all, labels_region,labels_clinic,coord_all,StimChans, StimChanSM,StimChansC, StimChanIx, stimlist  = get_Stim_chans(stimlist, lbls)\n",
    "bad_region = np.where((labels_region == 'WM') | (labels_region == 'OUT') | (labels_region == 'Putamen'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_clinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbls            = pd.read_excel(path_patient + \"/infos/\" + subj + \"_labels.xlsx\", header=0, sheet_name='BP')\n",
    "labels_all, labels_region,labels_clinic,coord_all,StimChans, StimChanSM,StimChansC, StimChanIx, stimlist  = get_Stim_chans(stimlist, lbls)\n",
    "bad_region = np.where((labels_region == 'WM') | (labels_region == 'OUT') | (labels_region == 'Putamen'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-lottery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LL_thr(EEG_resp, LL_all, labels_all, path_patient, n_trial=3):\n",
    "    ## get threshoold value for each response channel (99th and 95h)\n",
    "    chan_thr = np.zeros((len(labels_all), 4))\n",
    "    for rc in range(len(labels_all)):\n",
    "        chan_thr[rc,:] = get_sig_thr(rc, LL_all, EEG_resp, n_trial)\n",
    "    data_A = pd.DataFrame(chan_thr, columns=['99', '95', 'std', 'mean'])\n",
    "    file   = path_patient + '/Analysis/BrainMapping/LL/chan_sig_thr_single.csv'\n",
    "    data_A.to_csv(file, index=False,header=True)  # scat_plot = scat_plot.fillna(method='ffill')\n",
    "    print('Data stored: '+file)\n",
    "    return chan_thr\n",
    "def LL_mx(EEG_trial, Fs=500, w=0.25,t0=1.01):\n",
    "    # calculate mean response and get LL (incl peak)\n",
    "    resp           = ff.lp_filter(np.mean(EEG_trial,0),45,Fs)\n",
    "    LL_resp        = LL_funcs.get_LL_all(np.expand_dims(np.expand_dims(resp, axis=0),0), Fs, w, 1, 0)\n",
    "    LL_resp        = LL_resp[0,0]\n",
    "    mx             = np.max(LL_resp[np.int64((t0+w/2)*Fs):np.int64((t0+w)*Fs)])\n",
    "    mx_ix          = np.argmax(LL_resp[np.int64((t0+w/2)*Fs):np.int64((t0+w)*Fs)])\n",
    "    return mx, mx_ix, LL_resp\n",
    "\n",
    "def get_sig_thr(rc, LL_CCEP, EEG_resp, t_num, Fs=500,fig_path='no'):\n",
    "    # t_num = number of trials included for mean calculation, IO =3\n",
    "    BL_times       = np.concatenate([np.arange(0, 0.5, 0.01),np.arange(1.6, 2,0.01)])  # times wihtout stimulation, 0-0.5s, 1.6 - 2.5\n",
    "    n              = 300 # number of surrogates\n",
    "    LL_surr        = np.zeros((n, 1))\n",
    "    list_surr      = LL_CCEP[(LL_CCEP['d']>8)&(LL_CCEP['Chan']==rc)&~(LL_CCEP['Stim']==rc)&~np.isnan(LL_CCEP.LL.values)] # take BL when rc is not stimulating and not during noise\n",
    "    list_surr      = list_surr[~np.isnan(list_surr.LL.values)]\n",
    "    stimNum        = list_surr.Num.values.astype('int')\n",
    "    thr            = np.zeros(4,)\n",
    "    if len(stimNum)>0:\n",
    "        for k in range(n):\n",
    "            t0               = np.random.choice(np.round(BL_times,2))\n",
    "            stimNum_choice   = np.random.choice(stimNum, t_num)\n",
    "            EEG_trial        = EEG_resp[rc,stimNum_choice,np.int64((t0)*Fs):np.int64((t0+0.4)*Fs)]#np.flip(EEG_resp[rc,stimNum,:],1)\n",
    "            LL_surr[k,0],_,_ = LL_mx(EEG_trial, t0=0)\n",
    "\n",
    "        thr[0] = np.percentile(LL_surr[:,0],99)\n",
    "        thr[1] = np.percentile(LL_surr[:,0],95)\n",
    "        thr[2] = np.nanstd(LL_surr[:,0])\n",
    "        thr[3] = np.nanmean(LL_surr[:,0]) \n",
    "        if fig_path != 'no':\n",
    "            fig = plt.figure(figsize=(5,5))\n",
    "            plt.title('surrogates - '+labels_all[rc])\n",
    "            plt.hist(LL_surr[:,0])\n",
    "            plt.axvline(thr[0], c= [1,0,0], label='99%')\n",
    "            plt.axvline(thr[1], c= [1,0,0], label='90%')\n",
    "            plt.axvline(np.mean(LL_surr[:,0])+np.std(LL_surr[:,0]), c= [0,0,0], label='mean +std')\n",
    "            plt.xlabel('LL [250ms]')\n",
    "            plt.xlim([0,np.max([2,1.1*max(LL_surr[:,0])]) ])\n",
    "            plt.legend()\n",
    "            plt.savefig(fig_path)\n",
    "            plt.close(fig)    # close the figure window\n",
    "    return thr\n",
    "\n",
    "def get_SigCon_BM(LL_CCEP, EEG_resp, labels_all,chan_thr, Fs=500):\n",
    "    M_resp      = np.zeros((len(labels_all), len(labels_all),3))-1\n",
    "    #(LL_CCEP['Condition'].isin(cond))\n",
    "    for rc in tqdm.tqdm(range(len(labels_all))): # for each response channel\n",
    "        for sc in range(len(labels_all)): # for each stim channel\n",
    "            lists          = LL_CCEP[(LL_CCEP['Chan']==rc) & (LL_CCEP['Stim']==sc)]\n",
    "            lists          = lists[~np.isnan(lists.LL.values)]\n",
    "            stimNum_all    = lists.Num.values.astype('int')\n",
    "            if len(stimNum_all)>0:\n",
    "                EEG_trial      = EEG_resp[rc,stimNum_all,:]\n",
    "                mx,_,_         = LL_mx(EEG_trial)\n",
    "\n",
    "                if  mx>chan_thr[rc, 0]:\n",
    "                    M_resp[sc,rc,0] = mx\n",
    "                    M_resp[sc,rc,1] = 1\n",
    "                    M_resp[sc,rc,2] = (mx-chan_thr[rc,3])/chan_thr[rc, 2]\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = 1\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'LLpeak'] = mx\n",
    "                else:\n",
    "                    M_resp[sc,rc,:] = 0\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = 0\n",
    "                    LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'LLpeak'] = mx\n",
    "            else:\n",
    "                M_resp[sc,rc,:] = -1\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'RespC'] = -1\n",
    "                LL_CCEP.loc[(LL_CCEP.Chan ==rc)&(LL_CCEP.Stim==sc), 'LLpeak'] = -1\n",
    "\n",
    "    np.save(path_patient + '/Analysis/BrainMapping/LL/M_resp.npy', M_resp)\n",
    "       \n",
    "    LL_CCEP.to_csv(path_patient + '/Analysis/BrainMapping/LL/LL_all_single.csv', index=False,header=True)  # scat_plot = scat_plot.fillna(method='ffill')\n",
    "    return LL_CCEP, M_resp\n",
    "\n",
    "def plot_BM(M, labels,areas, t='BL', area = 0):\n",
    "    fig      = pylab.figure(figsize=(15,15))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, aspect='auto', origin='lower',cmap='hot', vmin=5, vmax= np.max([15,np.percentile(M,95)]))\n",
    "    plt.xlim([-1.5, len(labels)-0.5])\n",
    "    plt.ylim([-0.5, len(labels)+0.5])\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90);\n",
    "    plt.yticks(range(len(labels)), labels);\n",
    "    if area>0:\n",
    "        for i in range(len(labels)):\n",
    "            r = areas[i]\n",
    "            axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "            axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(t+ '-- LL z-score')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/BM_'+t+'.svg')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/BM_plot/BM_'+t+'.jpg')\n",
    "    plt.show()\n",
    "def plot_N_map(M, labels,areas, t='BL', area = 0):\n",
    "    fig      = pylab.figure(figsize=(15,15))\n",
    "    axmatrix = fig.add_axes([0.15,0.15,0.7,0.7]) # x, y, (start posiion), lenx, leny\n",
    "    im       = axmatrix.matshow(M, aspect='auto', origin='lower',cmap='seismic', vmin =-0.2, vmax=0.2)\n",
    "    plt.xlim([-1.5, len(labels)-0.5])\n",
    "    plt.ylim([-0.5, len(labels)+0.5])\n",
    "    plt.xticks(range(len(labels)), labels, rotation=90);\n",
    "    plt.yticks(range(len(labels)), labels);\n",
    "    if area>0:\n",
    "        for i in range(len(labels)):\n",
    "            r = areas[i]\n",
    "            axmatrix.add_patch(Rectangle((i-0.5,len(labels)-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "            axmatrix.add_patch(Rectangle((-1.5,i-0.5), 1, 1, alpha=1, facecolor= color_regions[np.where(regions==r)[0][0]]))\n",
    "    # Plot colorbar.\n",
    "    axcolor = fig.add_axes([0.9,0.15,0.01,0.7]) # x, y, x_len, y_len\n",
    "    plt.colorbar(im, cax=axcolor)\n",
    "    plt.title(t+ '-- LL z-score')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/N_map_plot/Nmap_'+t+'.svg')\n",
    "    plt.savefig(path_patient + '/Analysis/BrainMapping/LL/figures/N_map_plot/Nmap_'+t+'.jpg')\n",
    "    plt.show()\n",
    "def get_N_map(LL_CCEP, EEG_resp, t_0=1, Fs=500):\n",
    "    M_resp      = np.zeros((len(labels_all), len(labels_all),3))-1\n",
    "    M_resp[:,:,:] = np.nan\n",
    "    \n",
    "    for rc in tqdm.tqdm(range(len(labels_all))): # for each response channel\n",
    "        for sc in range(len(labels_all)): # for each stim channel\n",
    "            lists          = LL_CCEP[(LL_CCEP['Chan']==rc) & (LL_CCEP['Stim']==sc)]\n",
    "            lists          = lists[~np.isnan(lists.LL.values)]\n",
    "            stimNum_all    = lists.Num.values.astype('int')\n",
    "            if len(stimNum_all)>0:\n",
    "                resp_all = ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "                resp_z = ff.lp_filter(np.mean(bf.zscore_CCEP(EEG_resp[rc,stimNum_all,:]),0),45,Fs)\n",
    "                if np.max(abs(resp_z[int(1.01*Fs):int(1.3*Fs)])) > 6:\n",
    "                    ## get start resp\n",
    "                    start_resp = 0\n",
    "                    peaks_p, properties_all = scipy.signal.find_peaks(\n",
    "                        (resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), height=1, prominence=1,\n",
    "                        distance=0.01 * Fs, width=1)  #\n",
    "                    peaks_n, properties_all = scipy.signal.find_peaks(\n",
    "                        -(resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), height=1, prominence=1,\n",
    "                        distance=0.01 * Fs, width=1)  #\n",
    "\n",
    "                    if (len(peaks_p)+len(peaks_n))>0:\n",
    "                        peaks_all =min(np.concatenate([peaks_p, peaks_n]))\n",
    "                        #w = scipy.signal.peak_widths(abs(resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), [peaks_all],rel_height=0.2)[0]\n",
    "\n",
    "                        start_resp = (peaks_all) / Fs - 0.02# (peaks_all - w) / Fs - 0.01\n",
    "                        if start_resp < 0.01:\n",
    "                            start_resp = 0\n",
    "\n",
    "                        pk, peak_s, p = get_peaks_all(resp_z, start_resp)\n",
    "\n",
    "                        M_resp[sc,rc,0] = peak_s[0]\n",
    "                        M_resp[sc,rc,1] = p\n",
    "                        M_resp[sc,rc,2] =  peak_s[0]*p\n",
    "\n",
    "    np.save(path_patient + '/Analysis/BrainMapping/LL/N_map.npy', M_resp)\n",
    "    return M_resp\n",
    "\n",
    "def get_peaks(LL_CCEP, EEG_resp, N_map, t_0=1, Fs=500):\n",
    "    new_lab = ['pN1', 'pN2', 'sN1', 'sN2', 'tN1', 'tN2']\n",
    "    for l in new_lab:\n",
    "        if l not in LL_CCEP:\n",
    "            LL_CCEP.insert(6, l, np.nan)\n",
    "    data = LL_CCEP[~(np.isnan(LL_CCEP.LL.values))&(LL_CCEP.RespC==1)]  # [~(np.isnan(LL_CCEP.LL.values))]\n",
    "\n",
    "    for sc in np.unique(data.Stim).astype('int'):\n",
    "        for rc in np.unique(data.loc[data.Stim == sc, 'Chan']).astype('int'):\n",
    "            StimNum = data.loc[(data.Stim == sc) & (data.Chan == rc), 'Num'].values.astype('int')\n",
    "            \n",
    "            \n",
    "            tN1        = N_map[sc, rc, 0]\n",
    "            p          = N_map[sc, rc, 1]\n",
    "            \n",
    "            if abs(p)==1:\n",
    "                for i in range(len(StimNum)):\n",
    "                    resp_all   = ff.lp_filter(EEG_resp[rc,StimNum[i],:],45,Fs)\n",
    "                    peaks         = get_peaks_trial(resp_all, tN1, p, t_0, Fs)\n",
    "                    slope = pk_lin_fit(resp_all, peaks, fig=0, n_peaks=2, t_0=1, Fs=500)\n",
    "\n",
    "                    LL_CCEP.loc[\n",
    "                        (LL_CCEP.Stim == sc) & (LL_CCEP.Chan == rc) & (LL_CCEP.Num == StimNum[i]), 'pN1'] = abs(\n",
    "                        peaks[1, 1] - peaks[0, 1])\n",
    "                    LL_CCEP.loc[\n",
    "                        (LL_CCEP.Stim == sc) & (LL_CCEP.Chan == rc) & (LL_CCEP.Num == StimNum[i]), 'pN2'] = abs(\n",
    "                        peaks[1, 1] - peaks[2, 1])\n",
    "                    LL_CCEP.loc[\n",
    "                        (LL_CCEP.Stim == sc) & (LL_CCEP.Chan == rc) & (LL_CCEP.Num == StimNum[i]), 'tN1'] = peaks[0, 0]\n",
    "                    LL_CCEP.loc[\n",
    "                        (LL_CCEP.Stim == sc) & (LL_CCEP.Chan == rc) & (LL_CCEP.Num == StimNum[i]), 'tN2'] = peaks[2, 0]\n",
    "                    LL_CCEP.loc[\n",
    "                        (LL_CCEP.Stim == sc) & (LL_CCEP.Chan == rc) & (LL_CCEP.Num == StimNum[i]), ['sN1',\n",
    "                                                                                                    'sN2']] = slope\n",
    "                                # LL_CCEP.loc[(LL_CCEP.Stim == sc)&(LL_CCEP.Chan == rc)&(LL_CCEP.Num == StimNum[i]), 'sN2'] = abs(peaks[1,1]-peaks[2,1])\n",
    "                            # LL_CCEP.loc[(LL_CCEP.Stim == sc)&(LL_CCEP.Chan == rc)&(LL_CCEP.Num == StimNum[i]), 'sP2'] = abs(peaks[3,1]-peaks[2,1])\n",
    "                        # for l in ['N1', 'N2']:\n",
    "                        #     m = np.mean(LL_CCEP.loc[(LL_CCEP.Condition == 1)&(LL_CCEP.Stim == sc)&(LL_CCEP.Chan == rc), l])\n",
    "                        #     LL_CCEP.loc[(LL_CCEP.Stim == sc)&(LL_CCEP.Chan == rc), 'n'+l] = LL_CCEP.loc[(LL_CCEP.Stim == sc)&(LL_CCEP.Chan == rc), l]/m\n",
    "    LL_CCEP.to_csv(path_patient + '/Analysis/BrainMapping/LL/LL_all_single.csv', index=False,header=True)  # scat_plot = scat_plot.fillna(method='ffill')\n",
    "    \n",
    "    return LL_CCEP\n",
    "def pk_lin_fit(resp, pk, fig=0, n_peaks=2, t_0=1, Fs=500):\n",
    "    slope = np.zeros((n_peaks,))\n",
    "    for i in range(n_peaks):\n",
    "        if ~np.isnan(pk[i, 0]) & ~np.isnan(pk[i + 1, 0]):\n",
    "            if pk[i, 0] < pk[i + 1, 0]:\n",
    "                x = np.linspace(pk[i, 0] * Fs, pk[i + 1, 0] * Fs, int((pk[i + 1, 0] * Fs - pk[i, 0] * Fs)),\n",
    "                                endpoint=False)\n",
    "                # print(x+t_0*Fs)\n",
    "                y = resp[(x + t_0 * Fs).astype('int')]\n",
    "                x_s = x / Fs\n",
    "                coef = np.polyfit(x, y, 1)\n",
    "                slope[i] = abs(coef[0] / Fs * 1000)  # in uV/ms\n",
    "                if fig:\n",
    "                    poly1d_fn = np.poly1d(coef)\n",
    "                    plt.plot(x_s, poly1d_fn(x), '--k')\n",
    "    return slope\n",
    "def plot_mean(sc, rc, LL_CCEP,EEG_resp, labels ):\n",
    "    t_0    = 1\n",
    "    lists  = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)&(~np.isnan(LL_CCEP.zLL.values))]\n",
    "    \n",
    "    fig   = plt.figure(figsize=(12,7) )\n",
    "    #plt.title(labels_all[Stim_chs]+' -- '+labels_clinic[rc])\n",
    "    #plt.title(labels[sc]+' -- '+labels[rc])\n",
    "    plt.title(labels[sc]+' -- '+labels[rc]+', Dist: '+str(np.round(lists.d.values[0]))+'mm')\n",
    "    \n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    plt.xlabel('time [s]')\n",
    "    plt.text(-0.37, 200, 'LL: '+str(np.round(np.mean(lists.LLpeak),2))+'uV/ms (of mean)', c=[0,0,0])\n",
    "    \n",
    "    ylim = 200\n",
    "\n",
    "    #stim_spec                = stimlist[(stimlist.condition>0)&(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "    stimNum_all                  = lists.Num.values.astype('int')\n",
    "    for i in range(len(stimNum_all)):\n",
    "        ylim =np.max([ylim, np.max(abs(ff.lp_filter(EEG_resp[rc,stimNum_all[i],Fs:int(1.5*Fs)],45,Fs)))])\n",
    "        plt.plot(x_ax,ff.lp_filter(EEG_resp[rc,stimNum_all[i],:],45,Fs), c=color_elab[0], linewidth=1)\n",
    "    resp_all = ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "    plt.plot(x_ax,resp_all, c=[0,0,0], linewidth=3, label='mean, n='+str(len(stimNum_all)))\n",
    "    ## finding peaks\n",
    "    t_0=1\n",
    "    resp_z = ff.lp_filter(np.mean(bf.zscore_CCEP(ff.lp_filter(EEG_resp[rc,stimNum_all,:],45,Fs)),0),45,Fs)\n",
    "    #std_z = np.std(bf.zscore_CCEP(ff.lp_filter(EEG_resp[rc,stimNum_all,:],45,Fs)),0)\n",
    "    # plt.plot(x_ax,resp_z*100, c=[1,0,0], linewidth=3, label='mean, n='+str(len(stimNum_all)))\n",
    "    start_resp = 0\n",
    "    if np.max(abs(resp_z[int(1.01*Fs):int(1.3*Fs)])) > 3:\n",
    "        ## get start resp\n",
    "        \n",
    "        peaks_p, properties_all = scipy.signal.find_peaks(\n",
    "            (resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), height=0.5, prominence=1,\n",
    "            distance=0.01 * Fs, width=1)  #\n",
    "        peaks_n, properties_all = scipy.signal.find_peaks(\n",
    "            -(resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), height=0.5, prominence=1,\n",
    "            distance=0.01 * Fs, width=1)  #\n",
    "        print(np.concatenate([peaks_p, peaks_n]))\n",
    "        if (len(peaks_p)+len(peaks_n))>0:\n",
    "            #print(np.concatenate([peaks_p, peaks_n]))\n",
    "            peaks_all =min(np.concatenate([peaks_p, peaks_n]))\n",
    "            #w = scipy.signal.peak_widths(abs(resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), [peaks_all],rel_height=0.2)[0]\n",
    "            \n",
    "            start_resp = (peaks_all) / Fs - 0.02# (peaks_all - w) / Fs - 0.01\n",
    "            if start_resp < 0.01:\n",
    "                start_resp = 0\n",
    "\n",
    "        pk, peak_s, p = get_peaks_all(resp_z,start_resp)\n",
    "    \n",
    "        plt.plot(peak_s, resp_all[pk.astype('int')], \"^\", color= [1,0,0])\n",
    "    plt.xlim([-0.6,1])\n",
    "    plt.ylim([-np.max([ylim*1.071,300]),np.max([ylim*1.071,300])])\n",
    "    #plt.axvspan(t_0+w_r-1, t_0-1+w_LL, alpha=0.3, color=color_elab[0])\n",
    "    plt.axvspan(start_resp+0.01,start_resp+0.05, alpha=0.8, color=color_elab[1])\n",
    "    plt.axvspan(start_resp+0.08, start_resp+0.4, alpha=0.8, color=color_elab[1])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def plot_trial(sc, rc, n, LL_CCEP,EEG_resp,N_map, labels ):\n",
    "    t_0    = 1\n",
    "    lists  = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)&(~np.isnan(LL_CCEP.zLL.values))]\n",
    "    \n",
    "    fig   = plt.figure(figsize=(12,7) )\n",
    "    #plt.title(labels_all[Stim_chs]+' -- '+labels_clinic[rc])\n",
    "    #plt.title(labels[sc]+' -- '+labels[rc])\n",
    "    plt.title(labels[sc]+' -- '+labels[rc]+', Dist: '+str(np.round(lists.d.values[0]))+'mm')\n",
    "    \n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    plt.xlabel('time [s]')\n",
    "    plt.text(-0.37, 200, 'LL: '+str(np.round(np.mean(lists.LLpeak),2))+'uV/ms (of mean)', c=[0,0,0])\n",
    "    \n",
    "    \n",
    "\n",
    "    #stim_spec                = stimlist[(stimlist.condition>0)&(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "    stimNum                  = lists.Num.values.astype('int')[n]\n",
    "    \n",
    "    resp_all   = ff.lp_filter(EEG_resp[rc,stimNum,:],45,Fs)\n",
    "    ylim = np.max(abs(resp_all))\n",
    "    \n",
    "    plt.plot(x_ax,resp_all, c=[0,0,0], linewidth=3)\n",
    "    ## finding peaks\n",
    "    tN1 = N_map[sc, rc, 0]\n",
    "    p = N_map[sc, rc, 1]\n",
    "    pk = get_peaks_trial(resp_all, tN1, p, t_0=1, Fs=500)\n",
    "    plt.xlim([-0.6,1])\n",
    "    plt.ylim([-np.max([ylim*1.071,300]),np.max([ylim*1.071,300])])\n",
    "    plt.plot(pk[0:3,0],pk[0:3,1], '^')\n",
    "    plt.show()\n",
    "        \n",
    "        \n",
    "def get_peaks_trial(resp, tN1, p=1, t_0=1, Fs=500):\n",
    "    # p = polarity, how to change that N1 and N2 are local maxima\n",
    "    # peak_req, requirement where peak N1, P1 are 2x array\n",
    "\n",
    "    x = p * bf.zscore_CCEP(resp) # in correct polarity\n",
    "    x1 = int((t_0) * Fs)\n",
    "    x2 = int((t_0 + 1.5) * Fs)\n",
    "    y = x[x1:x2]\n",
    "    pk = np.zeros((4, 2))\n",
    "    pro_min = 0.05\n",
    "    # 1. \"N peaks (N1, N2)\"\n",
    "    peaks_all, properties_all = scipy.signal.find_peaks(y, prominence=pro_min, distance=0.03 * Fs)  #\n",
    "    if len(peaks_all) > 0:\n",
    "        w      =  0.01 * Fs\n",
    "        req_N1 = (peaks_all > 0.012 * Fs) &(peaks_all > 0.012 * Fs) & (peaks_all > tN1 * Fs - w) & (peaks_all < tN1 * Fs + w)\n",
    "        if req_N1.any():\n",
    "            peak       = peaks_all[req_N1]\n",
    "            properties = properties_all\n",
    "            for item in properties.items():\n",
    "                properties[item[0]] = properties[item[0]][req_N1]\n",
    "            if len(peak) > 1:\n",
    "                ix = np.argsort(properties[\"prominences\"])[-1]\n",
    "                peak = peak[ix]\n",
    "                for item in properties.items():\n",
    "                    properties[item[0]] = properties[item[0]][ix]\n",
    "            pk[0, 0] = peak[0] / Fs\n",
    "            pk[0, 1] = resp[peak[0] + x1]\n",
    "\n",
    "            \n",
    "            #w      =  0.01 * Fs\n",
    "            peaks_all, properties_all = scipy.signal.find_peaks(y, prominence=pro_min, distance=0.03 * Fs)  #\n",
    "            req_N2 = (peaks_all > (pk[0, 0]+0.02) * Fs)&(peaks_all < (pk[0, 0]+0.4) * Fs)\n",
    "\n",
    "            if req_N2.any():\n",
    "                peak       = peaks_all[req_N2]\n",
    "                properties = properties_all\n",
    "                for item in properties.items():\n",
    "                    properties[item[0]] = properties[item[0]][req_N2]\n",
    "                pk[2, 0] = peak[0] / Fs\n",
    "                pk[2, 1] = resp[peak[0] + x1]\n",
    "\n",
    "                if np.sum(pk[0:3, 0])>0:\n",
    "                    peak = np.argmax(-y[int((pk[0, 0]+0.01)*Fs):int((pk[2, 0]-0.01)*Fs)])+int((pk[0, 0]+0.01)*Fs)\n",
    "                    pk[1, 0] = peak / Fs\n",
    "                    pk[1, 1] = resp[peak + x1]\n",
    "    else:\n",
    "        pk[:, :] = np.nan\n",
    "\n",
    "    return pk\n",
    "def get_peaks_all(resp_all, start_resp, t_0=1, Fs=500):\n",
    "    # intended for mean responses, where polarity of N-peaks is unknown\n",
    "    \n",
    "    pk_all = np.zeros((7,2))\n",
    "    i = 0\n",
    "    for k in [-1,1]:\n",
    "        # selected highest peaks\n",
    "        #pk, properties_all      = scipy.signal.find_peaks(k*resp_all, height=1, prominence=0.002,distance=0.03*Fs, width=1)#\n",
    "        #pro_min                 = np.sort(properties_all['prominences'])[-np.min([len(pk),10])]\n",
    "        pro_min = 0.5\n",
    "        h = 0.001\n",
    "        pk, properties_all      = scipy.signal.find_peaks(k*resp_all, prominence=pro_min,distance=0.03*Fs, width=1)#\n",
    "        #print(properties_all)\n",
    "        # print(pk/Fs)\n",
    "        req_N1                  = (pk> (t_0+start_resp+0.011)*Fs)&(pk< (t_0+start_resp+0.06)*Fs)\n",
    "        req_N2                  = (pk> (t_0+start_resp+0.07)*Fs)&(pk< (t_0+start_resp+0.4)*Fs)\n",
    "\n",
    "        if any(req_N1)&any(req_N2): \n",
    "            j        = 0\n",
    "            for req in [req_N1, req_N2]:\n",
    "                pk, properties      = scipy.signal.find_peaks(k*resp_all, prominence=pro_min,distance=0.03*Fs, width=1)#\n",
    "                pk_N       = pk[req]\n",
    "                for item in properties.items():\n",
    "                    properties[item[0]] = properties[item[0]][req]\n",
    "                if len(pk_N)>1:\n",
    "                    if j == 0:\n",
    "                        #ix   = np.argsort(properties[\"prominences\"])[-1]\n",
    "                        ix   = 0#np.argsort(properties[\"widths\"])[0]\n",
    "                    else:\n",
    "                        \n",
    "                        ix   = 0#np.argsort(properties[\"prominences\"])[-1]\n",
    "                    pk_N = np.array([pk_N[ix]])\n",
    "                    for item in properties.items():\n",
    "                        properties[item[0]] = properties[item[0]][ix]\n",
    "\n",
    "                pk_all[j,i] = pk_N\n",
    "                pk_all[4,i] = pk_all[4,i]+properties['prominences']\n",
    "                if j ==0:\n",
    "                    #print(scipy.signal.peak_widths(k*resp_all, pk_N, rel_height=1))\n",
    "                    pk_all[5,i] = scipy.signal.peak_widths(k*resp_all, pk_N, rel_height=1)[0]\n",
    "                    #pk_all[5,i] = properties['widths']\n",
    "                    #peak_widths(x, peaks, rel_height=1)\n",
    "                    \n",
    "                j = 2\n",
    "            # pk, properties      = scipy.signal.find_peaks(-k*resp_all[0:int((t_0+start_resp+0.4)*Fs)], prominence=0.005,distance=0.03*Fs, width=1)#\n",
    "            # pro_min             = np.sort(properties['prominences'])[-np.min([len(pk),5])]\n",
    "            pk, properties      = scipy.signal.find_peaks(-k*resp_all, prominence=pro_min,distance=0.03*Fs, width=1)#\n",
    "            req_P1              = (pk> pk_all[0,i]+0.008*Fs)&(pk< pk_all[2,i]-0.008*Fs)\n",
    "            if any(req_P1):\n",
    "                pk_P       = pk[req_P1]\n",
    "                for item in properties.items():\n",
    "                    properties[item[0]] = properties[item[0]][req_P1]\n",
    "                if len(pk_P)>1:\n",
    "                    ix   = np.argsort(properties[\"prominences\"])[-1]\n",
    "                    pk_P = pk_P[ix]\n",
    "                #pk_all[1,i] = pk_P\n",
    "                #resp_fil = ff.lp_filter(resp_all, 15, Fs)\n",
    "                #pk, properties      = scipy.signal.find_peaks(-k*resp_fil, prominence=0.005,distance=0.03*Fs, width=1)#\n",
    "                #req_P1              = (pk> pk_all[2,i]+0.015*Fs)&(pk< pk_all[2,i]+1*Fs)\n",
    "                #pk_P                = pk[req_P1]\n",
    "                #for item in properties.items():\n",
    "                #    properties[item[0]] = properties[item[0]][req_P1]\n",
    "                #if len(pk_P)>1:\n",
    "#\n",
    "                #    ix   = np.argsort(properties[\"prominences\"])[-1]\n",
    "                #    pk_P = pk_P[ix]\n",
    "                \n",
    "            else:\n",
    "                pk_P = np.argmax(-k*resp_all[int(pk_all[0,i]+0.008*Fs):int(pk_all[2,i]-0.008*Fs)])+int(pk_all[0,i]+0.008*Fs)\n",
    "            pk_all[1,i] = pk_P\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            pk_all[4,i] = 0\n",
    "            pk_all[5,i] = 10000\n",
    "            pk_all[6,i] = 0\n",
    "            #print(str(k)+' - polarity does not fulfill N peak requirement')\n",
    "        i = i+1\n",
    "    pk_all = pk_all.astype('int')  \n",
    "    # for i in range(2):\n",
    "    #     pk_all[6,i] = abs(resp_all[pk_all[1,i]]-resp_all[pk_all[0,i]])+abs(resp_all[pk_all[1,i]]-resp_all[pk_all[2,i]])\n",
    "    resp_all[int(Fs)] = 0\n",
    "    resp_all[0] = 0\n",
    "    if abs(resp_all[pk_all[0,0]]) >abs(resp_all[pk_all[0,1]]):\n",
    "    #if abs(resp_std[pk_all[0,1]]) >abs(resp_std[pk_all[0,0]]):\n",
    "    #pk_all[6,0]>pk_all[6,1]:#pk_all[5,0]<pk_all[5,1]:#pk_all[4,1]<pk_all[4,0]\n",
    "        pk   = pk_all[0:4,0]\n",
    "        p    = -1\n",
    "    elif abs(resp_all[pk_all[0,0]]) < abs(resp_all[pk_all[0,1]]): #pk_all[6,0]<pk_all[6,1]: \n",
    "    #elif abs(resp_std[pk_all[0,1]]) <abs(resp_std[pk_all[0,0]]):\n",
    "        pk  = pk_all[0:4,1]\n",
    "        p   = 1\n",
    "    else:\n",
    "        pk = np.zeros((4,1))\n",
    "        p = 0\n",
    "\n",
    "    peak_s = (pk-t_0*Fs)/Fs\n",
    "\n",
    "    return pk,peak_s, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-julian",
   "metadata": {},
   "source": [
    "## LL and Significant responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial, trial_sig = BMf.LL_BM_connection(EEG_resp, stimlist, bad_chans, coord_all, labels_clinic, StimChanSM, StimChanIx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-castle",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = 53\n",
    "rc = 51\n",
    "plot_mean(sc,rc, con_trial,EEG_resp, labels_clinic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-liechtenstein",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial[con_trial.Sig_trial_LL==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "CR_color = pd.read_excel(\"T:\\EL_experiment\\Patients\\\\\" +'all'+\"\\Analysis\\BrainMapping\\CR_color.xlsx\", header=0)\n",
    "CR_color_a = CR_color.a.values\n",
    "CR_color = CR_color.c.values\n",
    "CR_color = np.zeros((24,3))\n",
    "CR_color[6:18,:] =np.array([253, 184, 19 ])/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial = LL_CCEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "b =1\n",
    "y = 'LLpeak'\n",
    "summ = con_trial[(con_trial.RespC==1)& (con_trial.LL>0)]\n",
    "summ = summ.groupby(['Stim', 'Chan'], as_index=False)[y].mean()#summ[summ.Sig_block>3]\n",
    "#t = np.bincount(con_trial.loc[con_trial.Block==b, 'Hour']).argmax()\n",
    "M = np.zeros((len(labels_all),len(labels_all)))\n",
    "for sc in np.unique(summ.Stim).astype('int'):\n",
    "    chan =summ.loc[summ.Stim==sc, 'Chan'].values.astype('int')\n",
    "    LL   = summ.loc[summ.Stim==sc, y].values\n",
    "    M[sc,chan] = LL\n",
    "M = np.nan_to_num(M)\n",
    "# BM plot\n",
    "labels_sel   = np.delete(labels_clinic, bad_all, 0)\n",
    "areas_sel    = np.delete(labels_region, bad_all, 0)\n",
    "M_resp       = np.delete(np.delete(M, bad_all, 0), bad_all, 1)\n",
    "\n",
    "# sort\n",
    "#ind = np.argsort(areas_sel)\n",
    "#M_resp= M_resp[ind,:]\n",
    "#M_resp = M_resp[:,ind]\n",
    "#labels_sel = labels_sel[ind]\n",
    "#areas_sel = areas_sel[ind]\n",
    "ll = 'test_clinic'\n",
    "plot_BM_CR_trial_sig(M_resp, labels_sel,areas_sel, ll, 't')\n",
    "i = i+1\n",
    "#np.save(path_patient + '/Analysis/' + folder + '/' + cond_folder +'/data/BM_all_trial_sig.npy', M_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "LL_CCEP.to_csv(path_patient + '/Analysis/BrainMapping/LL/con_trial_single.csv', index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-dylan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-treaty",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labels_sel   = np.delete(labels_clinic, bad_all, 0)\n",
    "\n",
    "areas_sel    = np.delete(labels_region, bad_all, 0)\n",
    "labels_L_sel = np.delete(labels_L, bad_all, 0)\n",
    "M            = np.delete(np.delete(M_resp[:,:,2], bad_all, 0), bad_all, 1)\n",
    "\n",
    "plot_BM(M, labels_sel, areas_sel, 'single_raw',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-hollow",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc= 13\n",
    "sc = 11\n",
    "lists  = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)]\n",
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean(sc,rc, con_trial,EEG_resp, labels_clinic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean(sc, rc, LL_CCEP,EEG_resp, labels ):\n",
    "    t_0    = 1\n",
    "    lists  = LL_CCEP[(LL_CCEP['Chan']==rc)&(LL_CCEP['Stim']==sc)&(~np.isnan(LL_CCEP.LL.values))]\n",
    "    \n",
    "    fig   = plt.figure(figsize=(12,7) )\n",
    "    #plt.title(labels_all[Stim_chs]+' -- '+labels_clinic[rc])\n",
    "    #plt.title(labels[sc]+' -- '+labels[rc])\n",
    "    plt.title(labels[sc]+' -- '+labels[rc]+', Dist: '+str(np.round(lists.d.values[0]))+'mm')\n",
    "    \n",
    "    plt.axvline(0, c=[0,0,0])\n",
    "    plt.xlabel('time [s]')\n",
    "    #plt.text(-0.37, 200, 'LL: '+str(np.round(np.mean(lists.LLpeak),2))+'uV/ms (of mean)', c=[0,0,0])\n",
    "    \n",
    "    ylim = 200\n",
    "\n",
    "    #stim_spec                = stimlist[(stimlist.condition>0)&(stimlist.ChanP==ChanP)&(stimlist.IPI_ms ==0)&(stimlist.noise ==0)]#&(stimlist.noise ==0)\n",
    "    stimNum_all                  = lists.Num.values.astype('int')\n",
    "    for i in range(len(stimNum_all)):\n",
    "        ylim =np.max([ylim, np.max(abs(ff.lp_filter(EEG_resp[rc,stimNum_all[i],Fs:int(1.5*Fs)],45,Fs)))])\n",
    "        plt.plot(x_ax,ff.lp_filter(EEG_resp[rc,stimNum_all[i],:],45,Fs), c=color_elab[0], linewidth=1)\n",
    "    resp_all = ff.lp_filter(np.mean(EEG_resp[rc,stimNum_all,:],0),45,Fs)\n",
    "    # w_LL =0.1\n",
    "    # resp_LL = LLf.get_LL_all(np.expand_dims(np.expand_dims(resp_all,0),0), 500, w_LL, 1, 0)\n",
    "    # resp_LL =resp_LL[0,0,:]\n",
    "    # start_resp = np.argmax(resp_LL[int(t0*Fs):int((t0+0.5)*Fs)])/Fs-w_LL/2+0.01\n",
    "    #print(start_resp)\n",
    "    plt.plot(x_ax,resp_all, c=[0,0,0], linewidth=3, label='mean, n='+str(len(stimNum_all)))\n",
    "    #plt.plot(x_ax,resp_LL*100, c=[1,0,0], linewidth=3, label='LL')\n",
    "    ## finding peaks\n",
    "    t_0=1\n",
    "    resp_z = ff.lp_filter(np.mean(bf.zscore_CCEP(ff.lp_filter(EEG_resp[rc,stimNum_all,:],45,Fs)),0),45,Fs)\n",
    "    # #std_z = np.std(bf.zscore_CCEP(ff.lp_filter(EEG_resp[rc,stimNum_all,:],45,Fs)),0)\n",
    "    # # plt.plot(x_ax,resp_z*100, c=[1,0,0], linewidth=3, label='mean, n='+str(len(stimNum_all)))\n",
    "    # #start_resp = 0\n",
    "    # #print(np.max(abs(resp_z[int(1.01*Fs):int(1.3*Fs)])))\n",
    "    # if np.max(abs(resp_z[int(1.01*Fs):int(1.3*Fs)])) > 2.5:\n",
    "    #     ## get start resp\n",
    "    #     \n",
    "    #     # peaks_p, properties_all = scipy.signal.find_peaks(\n",
    "    #     #     (resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), height=0.5, prominence=1,\n",
    "    #     #     distance=0.01 * Fs, width=1)  #\n",
    "    #     # peaks_n, properties_all = scipy.signal.find_peaks(\n",
    "    #     #     -(resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), height=0.5, prominence=1,\n",
    "    #     #     distance=0.01 * Fs, width=1)  #\n",
    "    #     # print(np.concatenate([peaks_p, peaks_n]))\n",
    "    #     # if (len(peaks_p)+len(peaks_n))>0:\n",
    "    #     #     #print(np.concatenate([peaks_p, peaks_n]))\n",
    "    #     #     peaks_all =min(np.concatenate([peaks_p, peaks_n]))\n",
    "    #     #     #w = scipy.signal.peak_widths(abs(resp_z[int(t_0 * Fs):int((t_0 + 0.5) * Fs)]), [peaks_all],rel_height=0.2)[0]\n",
    "    #     #     \n",
    "    #     #     start_resp = (peaks_all) / Fs - 0.02# (peaks_all - w) / Fs - 0.01\n",
    "    #     if start_resp < 0.01:\n",
    "    #         start_resp = 0\n",
    "# \n",
    "    #     pk, peak_s, p = get_peaks_all(resp_z,start_resp)\n",
    "    # \n",
    "    #     plt.plot(peak_s, resp_all[pk.astype('int')], \"^\", color= [1,0,0])\n",
    "    plt.xlim([-0.6,1])\n",
    "    plt.ylim([-np.max([ylim*1.071,300]),np.max([ylim*1.071,300])])\n",
    "    #plt.axvspan(t_0+w_r-1, t_0-1+w_LL, alpha=0.3, color=color_elab[0])\n",
    "    #plt.axvspan(start_resp+0.01,start_resp+0.05, alpha=0.8, color=color_elab[1])\n",
    "    #plt.axvspan(start_resp+0.08, start_resp+0.4, alpha=0.8, color=color_elab[1])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LL_funcs as LLf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_sel   = np.delete(labels_clinic, bad_all, 0)\n",
    "labels_sel   = np.delete(labels_all, bad_all, 0)\n",
    "areas_sel    = np.delete(labels_region, bad_all, 0)\n",
    "labels_L_sel = np.delete(labels_L, bad_all, 0)\n",
    "M            = np.delete(np.delete(M_resp[:,:,2], bad_all, 0), bad_all, 1)\n",
    "# sort\n",
    "# sort\n",
    "ind = np.argsort(areas_sel)\n",
    "M = M[ind,:]\n",
    "M = M[:,ind]\n",
    "labels_sel = labels_sel[ind]\n",
    "areas_sel = areas_sel[ind]\n",
    "\n",
    "plot_BM(M, labels_sel, areas_sel, 'single',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_sel   = np.delete(labels_clinic, bad_region, 0)\n",
    "labels_sel   = np.delete(labels_all, bad_all, 0)\n",
    "areas_sel    = np.delete(labels_region, bad_all, 0)\n",
    "labels_L_sel = np.delete(labels_L, bad_all, 0)\n",
    "M            = np.delete(np.delete(N_map[:,:,2], bad_all, 0), bad_all, 1)\n",
    "# sort\n",
    "# sort\n",
    "ind = np.argsort(areas_sel)\n",
    "M = M[ind,:]\n",
    "M = M[:,ind]\n",
    "labels_sel = labels_sel[ind]\n",
    "areas_sel = areas_sel[ind]\n",
    "\n",
    "plot_N_map(M, labels_sel,areas_sel, t='BL', area = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-accountability",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "b = sns.scatterplot(x=\"d\", y='zLL', hue='sig_trial', data=LL_CCEP)\n",
    "plt.xlim([9.5,100])\n",
    "plt.xlabel('distance [mm]',fontsize=16)\n",
    "#plt.xlabel('N1 [\\u0394 \\u03BCV]')\n",
    "plt.ylabel('LL [\\u0394 \\u03BCV /ms]',fontsize=16) \n",
    "b.tick_params(labelsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "b = sns.scatterplot(x=\"pN1\", y='pN2', hue='d', data=LL_CCEP[(LL_CCEP.d>7.5)&(LL_CCEP.pN1<3000)])\n",
    "#plt.xlim([9.5,90])\n",
    "plt.xlabel('N1  [\\u0394 \\u03BCV]',fontsize=16) \n",
    "#plt.xlabel('N1 [\\u0394 \\u03BCV]')\n",
    "plt.ylabel('N2  [\\u0394 \\u03BCV]',fontsize=16) \n",
    "b.tick_params(labelsize=12)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "b = sns.scatterplot(x=\"LL\", y='pN1', hue='d', data=LL_CCEP[(LL_CCEP.d>7.5)&(LL_CCEP.pN1<3000)])\n",
    "#plt.xlim([9.5,90])\n",
    "plt.xlabel('LL  [\\u0394 \\u03BCV /ms]',fontsize=16) \n",
    "#plt.xlabel('N1 [\\u0394 \\u03BCV]')\n",
    "plt.ylabel('N1  [\\u0394 \\u03BCV]',fontsize=16) \n",
    "b.tick_params(labelsize=12)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
